{"meta":{"exported_on":1507519779653,"version":"1.12.1"},"data":{"migrations":[{"id":1,"name":"1-create-tables.js","version":"init","currentVersion":"1.2"},{"id":2,"name":"2-create-fixtures.js","version":"init","currentVersion":"1.2"},{"id":3,"name":"1-post-excerpt.js","version":"1.3","currentVersion":"1.4"},{"id":4,"name":"1-codeinjection-post.js","version":"1.4","currentVersion":"1.4"},{"id":5,"name":"1-og-twitter-post.js","version":"1.5","currentVersion":"1.5"}],"posts":[{"id":"5980610f8b6b9f5294dd27be","uuid":"3e94c4e5-ddd9-49b5-894d-4108808c178e","title":"手机号加密","slug":"bo-ke","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"### 说明\\n手机号是数字组成，故可以把字符串看成long类型\\n加密原理：位的异或运算\\n\\n例如 A^B=C;那么 C^B=A\\n\\n为了精简传输，故可以把10进制转换成64进制传输，另外改动一下对应的映射即可简单加密\\n\\n\\n### 定义\\n10进制转换成64进制 对应的索引字符如下 一共64个字符\\n\\n```\\n'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\\n'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\\n'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\\n'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',\\n'0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '-', '_'\\n```\\n例如13位的手机号`18611522617`就变成了`5jHIIE` 缩短很多\\n### java 实现\\n```java\\n    private static final char[] BASE_MASK_CHARS = {\\n            'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\\n            'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\\n            'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\\n            'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',\\n            '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '-', '_'\\n    };\\n    private static final int BASE_MASK_LENGTH = BASE_MASK_CHARS.length;\\n    private static final int BASE_MASK_BIT_LENGTH = 6;\\n\\n    private static final Map<Integer, Integer> BASE_MASK_INDEX;\\n\\n    static {\\n        BASE_MASK_INDEX = new HashMap<>(BASE_MASK_LENGTH);\\n        for (int i = 0; i < BASE_MASK_LENGTH; i++) {\\n            BASE_MASK_INDEX.put((int) BASE_MASK_CHARS[i], i);\\n        }\\n    }\\n\\n\\n    /**\\n     * 把手机号当成10进制转换成64进制\\n     *\\n     * @param mobile\\n     * @return\\n     */\\n    public static String getEndMobile(String mobile) {\\n        long number = Long.valueOf(mobile);\\n        StringBuilder buf = new StringBuilder();\\n        while (number > 0) {\\n            int index = (int) (number % BASE_MASK_LENGTH);\\n            buf.append(BASE_MASK_CHARS[index]);\\n            number = number >> BASE_MASK_BIT_LENGTH;\\n\\n        }\\n        return buf.toString();\\n\\n    }\\n\\n    /**\\n     * 解密64位的手机号变成10进制\\n     *\\n     * @param s\\n     * @return\\n     */\\n    public static long getDecMobile(String s) {\\n        long result = 0L;\\n        char[] mobiles = s.toCharArray();\\n        for (int pos = mobiles.length - 1; pos >= 0; pos--) {\\n            int v = (int) mobiles[pos];\\n            int index = BASE_MASK_INDEX.get(v);\\n            result = (result << BASE_MASK_BIT_LENGTH) + index;\\n        }\\n        return result;\\n    }\\n\\n\\n    /**\\n     * 使用两次异或还原的特效进行简单的加密\\n     *\\n     * @return\\n     */\\n    public static byte[] mask(byte[] mobile, byte[] mask) {\\n        int maskLength = mask.length;\\n        for (int index = 0; index < mobile.length; index++) {\\n            byte c = mobile[index];\\n            //mask可能和mobile长度不一致，故对mask索引运行 mod  ，进而对mask重复使用\\n            mobile[index] = (byte) (c ^ mask[index % maskLength]);\\n        }\\n        return mobile;\\n    }\\n\\n\\n    public static void main(String args[]) {\\n\\n\\n        String endMobile = getEndMobile(\\\"18612345678\\\");\\n        System.out.println(\\\"手机号10进制转换成16进制如下：\\\\t\\\" + endMobile);\\n\\n        byte[] mobile = endMobile.getBytes();\\n        byte[] mask = \\\"12355678\\\".getBytes();\\n        String encodeMobileInfo;\\n\\n        {   //这部分是服务端处理\\n            //进行一次加密\\n            mobile = mask(mobile, mask);\\n            //进行一次Base64 urlEncoder 并使用withoutPadding 把多于的填充去掉\\n            encodeMobileInfo = Base64.getUrlEncoder().withoutPadding().encodeToString(mobile);\\n            System.out.println(\\\"加密16进制手机号数据:\\\\t\\\" + encodeMobileInfo);\\n        }\\n\\n        {   //客户端处理\\n            //客户端获取数据  先base64解密，然后再进行一次异或操作即可\\n            mobile = mask(Base64.getUrlDecoder().decode(encodeMobileInfo), mask);\\n            System.out.println(\\\"解密获取手机号:\\\\t\\\" + getDecMobile(new String(mobile)));\\n        }\\n        System.exit(0);\\n    }\\n\\n\\n```\\n输出结果\\n```\\n手机号10进制转换成16进制如下：\\tOtdYVR\\n加密16进制手机号数据:\\tfkZXbGNk\\n解密获取手机号:\\t18612345678\\n```\"}]],\"sections\":[[10,0]]}","html":"<div class=\"kg-card-markdown\"><h3 id=\"\">说明</h3>\n<p>手机号是数字组成，故可以把字符串看成long类型<br>\n加密原理：位的异或运算</p>\n<p>例如 A^B=C;那么 C^B=A</p>\n<p>为了精简传输，故可以把10进制转换成64进制传输，另外改动一下对应的映射即可简单加密</p>\n<h3 id=\"\">定义</h3>\n<p>10进制转换成64进制 对应的索引字符如下 一共64个字符</p>\n<pre><code>'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',\n'0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '-', '_'\n</code></pre>\n<p>例如13位的手机号<code>18611522617</code>就变成了<code>5jHIIE</code> 缩短很多</p>\n<h3 id=\"java\">java 实现</h3>\n<pre><code class=\"language-java\">    private static final char[] BASE_MASK_CHARS = {\n            'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n            'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n            'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n            'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',\n            '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '-', '_'\n    };\n    private static final int BASE_MASK_LENGTH = BASE_MASK_CHARS.length;\n    private static final int BASE_MASK_BIT_LENGTH = 6;\n\n    private static final Map&lt;Integer, Integer&gt; BASE_MASK_INDEX;\n\n    static {\n        BASE_MASK_INDEX = new HashMap&lt;&gt;(BASE_MASK_LENGTH);\n        for (int i = 0; i &lt; BASE_MASK_LENGTH; i++) {\n            BASE_MASK_INDEX.put((int) BASE_MASK_CHARS[i], i);\n        }\n    }\n\n\n    /**\n     * 把手机号当成10进制转换成64进制\n     *\n     * @param mobile\n     * @return\n     */\n    public static String getEndMobile(String mobile) {\n        long number = Long.valueOf(mobile);\n        StringBuilder buf = new StringBuilder();\n        while (number &gt; 0) {\n            int index = (int) (number % BASE_MASK_LENGTH);\n            buf.append(BASE_MASK_CHARS[index]);\n            number = number &gt;&gt; BASE_MASK_BIT_LENGTH;\n\n        }\n        return buf.toString();\n\n    }\n\n    /**\n     * 解密64位的手机号变成10进制\n     *\n     * @param s\n     * @return\n     */\n    public static long getDecMobile(String s) {\n        long result = 0L;\n        char[] mobiles = s.toCharArray();\n        for (int pos = mobiles.length - 1; pos &gt;= 0; pos--) {\n            int v = (int) mobiles[pos];\n            int index = BASE_MASK_INDEX.get(v);\n            result = (result &lt;&lt; BASE_MASK_BIT_LENGTH) + index;\n        }\n        return result;\n    }\n\n\n    /**\n     * 使用两次异或还原的特效进行简单的加密\n     *\n     * @return\n     */\n    public static byte[] mask(byte[] mobile, byte[] mask) {\n        int maskLength = mask.length;\n        for (int index = 0; index &lt; mobile.length; index++) {\n            byte c = mobile[index];\n            //mask可能和mobile长度不一致，故对mask索引运行 mod  ，进而对mask重复使用\n            mobile[index] = (byte) (c ^ mask[index % maskLength]);\n        }\n        return mobile;\n    }\n\n\n    public static void main(String args[]) {\n\n\n        String endMobile = getEndMobile(&quot;18612345678&quot;);\n        System.out.println(&quot;手机号10进制转换成16进制如下：\\t&quot; + endMobile);\n\n        byte[] mobile = endMobile.getBytes();\n        byte[] mask = &quot;12355678&quot;.getBytes();\n        String encodeMobileInfo;\n\n        {   //这部分是服务端处理\n            //进行一次加密\n            mobile = mask(mobile, mask);\n            //进行一次Base64 urlEncoder 并使用withoutPadding 把多于的填充去掉\n            encodeMobileInfo = Base64.getUrlEncoder().withoutPadding().encodeToString(mobile);\n            System.out.println(&quot;加密16进制手机号数据:\\t&quot; + encodeMobileInfo);\n        }\n\n        {   //客户端处理\n            //客户端获取数据  先base64解密，然后再进行一次异或操作即可\n            mobile = mask(Base64.getUrlDecoder().decode(encodeMobileInfo), mask);\n            System.out.println(&quot;解密获取手机号:\\t&quot; + getDecMobile(new String(mobile)));\n        }\n        System.exit(0);\n    }\n\n\n</code></pre>\n<p>输出结果</p>\n<pre><code>手机号10进制转换成16进制如下：\tOtdYVR\n加密16进制手机号数据:\tfkZXbGNk\n解密获取手机号:\t18612345678\n</code></pre>\n</div>","amp":null,"plaintext":"说明\n手机号是数字组成，故可以把字符串看成long类型\n加密原理：位的异或运算\n\n例如 A^B=C;那么 C^B=A\n\n为了精简传输，故可以把10进制转换成64进制传输，另外改动一下对应的映射即可简单加密\n\n定义\n10进制转换成64进制 对应的索引字符如下 一共64个字符\n\n'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',\n'0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '-', '_'\n\n\n例如13位的手机号18611522617就变成了5jHIIE  缩短很多\n\njava 实现\n    private static final char[] BASE_MASK_CHARS = {\n            'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n            'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n            'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n            'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',\n            '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '-', '_'\n    };\n    private static final int BASE_MASK_LENGTH = BASE_MASK_CHARS.length;\n    private static final int BASE_MASK_BIT_LENGTH = 6;\n\n    private static final Map<Integer, Integer> BASE_MASK_INDEX;\n\n    static {\n        BASE_MASK_INDEX = new HashMap<>(BASE_MASK_LENGTH);\n        for (int i = 0; i < BASE_MASK_LENGTH; i++) {\n            BASE_MASK_INDEX.put((int) BASE_MASK_CHARS[i], i);\n        }\n    }\n\n\n    /**\n     * 把手机号当成10进制转换成64进制\n     *\n     * @param mobile\n     * @return\n     */\n    public static String getEndMobile(String mobile) {\n        long number = Long.valueOf(mobile);\n        StringBuilder buf = new StringBuilder();\n        while (number > 0) {\n            int index = (int) (number % BASE_MASK_LENGTH);\n            buf.append(BASE_MASK_CHARS[index]);\n            number = number >> BASE_MASK_BIT_LENGTH;\n\n        }\n        return buf.toString();\n\n    }\n\n    /**\n     * 解密64位的手机号变成10进制\n     *\n     * @param s\n     * @return\n     */\n    public static long getDecMobile(String s) {\n        long result = 0L;\n        char[] mobiles = s.toCharArray();\n        for (int pos = mobiles.length - 1; pos >= 0; pos--) {\n            int v = (int) mobiles[pos];\n            int index = BASE_MASK_INDEX.get(v);\n            result = (result << BASE_MASK_BIT_LENGTH) + index;\n        }\n        return result;\n    }\n\n\n    /**\n     * 使用两次异或还原的特效进行简单的加密\n     *\n     * @return\n     */\n    public static byte[] mask(byte[] mobile, byte[] mask) {\n        int maskLength = mask.length;\n        for (int index = 0; index < mobile.length; index++) {\n            byte c = mobile[index];\n            //mask可能和mobile长度不一致，故对mask索引运行 mod  ，进而对mask重复使用\n            mobile[index] = (byte) (c ^ mask[index % maskLength]);\n        }\n        return mobile;\n    }\n\n\n    public static void main(String args[]) {\n\n\n        String endMobile = getEndMobile(\"18612345678\");\n        System.out.println(\"手机号10进制转换成16进制如下：\\t\" + endMobile);\n\n        byte[] mobile = endMobile.getBytes();\n        byte[] mask = \"12355678\".getBytes();\n        String encodeMobileInfo;\n\n        {   //这部分是服务端处理\n            //进行一次加密\n            mobile = mask(mobile, mask);\n            //进行一次Base64 urlEncoder 并使用withoutPadding 把多于的填充去掉\n            encodeMobileInfo = Base64.getUrlEncoder().withoutPadding().encodeToString(mobile);\n            System.out.println(\"加密16进制手机号数据:\\t\" + encodeMobileInfo);\n        }\n\n        {   //客户端处理\n            //客户端获取数据  先base64解密，然后再进行一次异或操作即可\n            mobile = mask(Base64.getUrlDecoder().decode(encodeMobileInfo), mask);\n            System.out.println(\"解密获取手机号:\\t\" + getDecMobile(new String(mobile)));\n        }\n        System.exit(0);\n    }\n\n\n\n\n输出结果\n\n手机号10进制转换成16进制如下：\tOtdYVR\n加密16进制手机号数据:\tfkZXbGNk\n解密获取手机号:\t18612345678","feature_image":"/content/images/2017/08/77714153da4847db8330bea19d7d1fdb.png","featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2017-08-01 11:07:59","created_by":"1","updated_at":"2017-08-01 11:33:41","updated_by":"1","published_at":"2017-08-01 11:08:21","published_by":"1","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null},{"id":"59806b3a43d7fc53ddfd277a","uuid":"9e84a56f-cd2b-4955-8d36-7eaf769e263b","title":"mysql 相关","slug":"mysql-gu-zhang-xiu-fu","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"## 1. 主从同步出错处理\\n### 背景\\n写入 table 的时候，因为程序bug，写入从库里面去了，下面解决的方法只适用于了：从库里面主动插入了一条新数据\\n\\n###解决步骤\\n1，查看错误log\\n```\\nshow slave status;\\n```\\n找出出错的position，定位table\\n2，定位多插入的那一条数据，备份后并删除它\\n3，如果id是自增的话，需要把id还原\\n```\\nuse db;//切换对应的数据库\\nshow table status where name ='table'\\\\G;//查看当前的信息\\n\\nmysql> show table status where name ='table'\\\\G;\\n*************************** 1. row ***************************\\n           Name: table\\n         Engine: InnoDB\\n        Version: 10\\n     Row_format: Compressed\\n           Rows: 52898364\\n Avg_row_length: 55\\n    Data_length: 2953576448\\nMax_data_length: 0\\n   Index_length: 0\\n      Data_free: 3932160\\n Auto_increment: 47447481\\n    Create_time: 2016-07-22 11:38:00\\n    Update_time: NULL\\n     Check_time: NULL\\n      Collation: utf8mb4_general_ci\\n       Checksum: NULL\\n Create_options: row_format=COMPRESSED KEY_BLOCK_SIZE=4\\n        Comment: \\n1 row in set (0.00 sec)\\n```\\n可以查询当前的`Auto_increment`值\\n\\n4，修改当前的`Auto_increment`值\\n```\\nalter table chat_msg AUTO_INCREMENT=xxxxx;\\n```\\n5，打开从库备份\\n```\\nstart slave ;\\n```\\n开启后检查是否running\\n```\\nshow  slave status\\\\G;\\n```\\n\\n## 2,检查mysql状态几个命令\\n\\n    \\n```mysql\\nshow slave status\\\\G;\\nshow slave hosts\\\\G;\\nshow processlist\\\\G;\\n```\\n\\n## 3, 删除多余的binlong\\n\\n#### 背景：\\n没有设置自动生成binlog的情况，手动清除没用的binlog\\n\\n去从库看看\\n```\\nshow slave status;\\n```\\n\\n然后去主库\\n```\\nshow binary logs;##\\nshow master status;#查看同步状态，看同步到那个binlog \\npurge binary logs to 'mysql-bin.000410';#删除mysql-bin.000410以前的binlog 但不包含它\\n```\\n\\n\\n\\n\\n\\n\"}]],\"sections\":[[10,0]]}","html":"<div class=\"kg-card-markdown\"><h2 id=\"1\">1. 主从同步出错处理</h2>\n<h3 id=\"\">背景</h3>\n<p>写入 table 的时候，因为程序bug，写入从库里面去了，下面解决的方法只适用于了：从库里面主动插入了一条新数据</p>\n<h3 id=\"\">解决步骤</h3>\n<p>1，查看错误log</p>\n<pre><code>show slave status;\n</code></pre>\n<p>找出出错的position，定位table<br>\n2，定位多插入的那一条数据，备份后并删除它<br>\n3，如果id是自增的话，需要把id还原</p>\n<pre><code>use db;//切换对应的数据库\nshow table status where name ='table'\\G;//查看当前的信息\n\nmysql&gt; show table status where name ='table'\\G;\n*************************** 1. row ***************************\n           Name: table\n         Engine: InnoDB\n        Version: 10\n     Row_format: Compressed\n           Rows: 52898364\n Avg_row_length: 55\n    Data_length: 2953576448\nMax_data_length: 0\n   Index_length: 0\n      Data_free: 3932160\n Auto_increment: 47447481\n    Create_time: 2016-07-22 11:38:00\n    Update_time: NULL\n     Check_time: NULL\n      Collation: utf8mb4_general_ci\n       Checksum: NULL\n Create_options: row_format=COMPRESSED KEY_BLOCK_SIZE=4\n        Comment: \n1 row in set (0.00 sec)\n</code></pre>\n<p>可以查询当前的<code>Auto_increment</code>值</p>\n<p>4，修改当前的<code>Auto_increment</code>值</p>\n<pre><code>alter table chat_msg AUTO_INCREMENT=xxxxx;\n</code></pre>\n<p>5，打开从库备份</p>\n<pre><code>start slave ;\n</code></pre>\n<p>开启后检查是否running</p>\n<pre><code>show  slave status\\G;\n</code></pre>\n<h2 id=\"2mysql\">2,检查mysql状态几个命令</h2>\n<pre><code class=\"language-mysql\">show slave status\\G;\nshow slave hosts\\G;\nshow processlist\\G;\n</code></pre>\n<h2 id=\"3binlong\">3, 删除多余的binlong</h2>\n<h4 id=\"\">背景：</h4>\n<p>没有设置自动生成binlog的情况，手动清除没用的binlog</p>\n<p>去从库看看</p>\n<pre><code>show slave status;\n</code></pre>\n<p>然后去主库</p>\n<pre><code>show binary logs;##\nshow master status;#查看同步状态，看同步到那个binlog \npurge binary logs to 'mysql-bin.000410';#删除mysql-bin.000410以前的binlog 但不包含它\n</code></pre>\n</div>","amp":null,"plaintext":"http://gan.d.diandian.com/","feature_image":"/content/images/2017/08/158ff09efbefe604ce3517b62506c804.png","featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2017-08-01 11:51:22","created_by":"1","updated_at":"2017-08-02 02:25:45","updated_by":"1","published_at":"2017-08-02 02:22:06","published_by":"1","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null},{"id":"598138a5d62a9854962c940a","uuid":"9c9c1ce2-9909-474f-a493-c4795e72e3b8","title":"安装face_recognition","slug":"centosan-zhuang","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"## centos 安装\\nface_recognition是一个非常不错的人脸识别项目  https://github.com/ageitgey/face_recognition\\n其实依赖关键是 [`dlib`](http://dlib.net/) 他是一个机器学习的c++库  \\n\\n主要是用python3下运行\\n```\\nyum install python34\\nyum install python34-devel\\npip3 install cmake\\nyum install boost-devel \\nyum install make\\npip3 install dlib \\n```\\n\\n```\\n#yum install cmake\\nyum install boost-python\\nyum install python34-pip\\npip3 install face_recognition\\n```\\n## macOS安装\\n2017年08月安装 一定需要python3.4版本\\n`pip3 install face_recognition`\"}]],\"sections\":[[10,0]]}","html":"<div class=\"kg-card-markdown\"><h2 id=\"centos\">centos 安装</h2>\n<p>face_recognition是一个非常不错的人脸识别项目  <a href=\"https://github.com/ageitgey/face_recognition\">https://github.com/ageitgey/face_recognition</a><br>\n其实依赖关键是 <a href=\"http://dlib.net/\"><code>dlib</code></a> 他是一个机器学习的c++库</p>\n<p>主要是用python3下运行</p>\n<pre><code>yum install python34\nyum install python34-devel\npip3 install cmake\nyum install boost-devel \nyum install make\npip3 install dlib \n</code></pre>\n<pre><code>#yum install cmake\nyum install boost-python\nyum install python34-pip\npip3 install face_recognition\n</code></pre>\n<h2 id=\"macos\">macOS安装</h2>\n<p>2017年08月安装 一定需要python3.4版本<br>\n<code>pip3 install face_recognition</code></p>\n</div>","amp":null,"plaintext":"centos 安装\nface_recognition是一个非常不错的人脸识别项目 https://github.com/ageitgey/face_recognition\n其实依赖关键是 dlib [http://dlib.net/]  他是一个机器学习的c++库\n\n主要是用python3下运行\n\nyum install python34\nyum install python34-devel\npip3 install cmake\nyum install boost-devel \nyum install make\npip3 install dlib \n\n\n#yum install cmake\nyum install boost-python\nyum install python34-pip\npip3 install face_recognition\n\n\nmacOS安装\n2017年08月安装 一定需要python3.4版本\npip3 install face_recognition","feature_image":null,"featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2017-08-02 02:27:49","created_by":"1","updated_at":"2017-08-23 03:41:18","updated_by":"1","published_at":"2017-08-02 02:31:38","published_by":"1","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null},{"id":"59813996d62a9854962c940b","uuid":"707bf5fe-fe74-4b9c-b8e7-2cb508bfb530","title":"tensorflow 物体分类","slug":"wu-ti-shi-bie","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"这是一个官方例子，可以根据图片识别物体\\n\\n另外根据百度翻译对应的中文，但是有的翻译不准确，需要优化\\n\\n官方例子 https://www.tensorflow.org/tutorials/image_recognition\\n个人修改项目 https://github.com/hai046/tensorflowDemo/blob/master/README.md\\n\\n\\n![](https://www.tensorflow.org/images/AlexClassification.png)\"}]],\"sections\":[[10,0]]}","html":"<div class=\"kg-card-markdown\"><p>这是一个官方例子，可以根据图片识别物体</p>\n<p>另外根据百度翻译对应的中文，但是有的翻译不准确，需要优化</p>\n<p>官方例子 <a href=\"https://www.tensorflow.org/tutorials/image_recognition\">https://www.tensorflow.org/tutorials/image_recognition</a><br>\n个人修改项目 <a href=\"https://github.com/hai046/tensorflowDemo/blob/master/README.md\">https://github.com/hai046/tensorflowDemo/blob/master/README.md</a></p>\n<p><img src=\"https://www.tensorflow.org/images/AlexClassification.png\" alt=\"\"></p>\n</div>","amp":null,"plaintext":"这是一个官方例子，可以根据图片识别物体\n\n另外根据百度翻译对应的中文，但是有的翻译不准确，需要优化\n\n官方例子 https://www.tensorflow.org/tutorials/image_recognition\n个人修改项目 https://github.com/hai046/tensorflowDemo/blob/master/README.md","feature_image":null,"featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2017-08-02 02:31:50","created_by":"1","updated_at":"2017-08-03 02:30:02","updated_by":"1","published_at":"2017-08-02 02:37:55","published_by":"1","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null},{"id":"5982b8d9616dac5789b9fa21","uuid":"b4110755-546d-4c58-88a8-4721f6b2e023","title":"MySQL utf8mb4  字符集","slug":"mysql","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"||utf8|utf8mb4\\n|-|-|-|\\n|长度|最大3byte|最大4byte|\\n|历史|一直在|5.5.3版本后增加\\n|兼容|N/S|完全兼容utf8\\n|emoji|一般不兼容，emoji一般是4个byte长度会出现编码异常|可以兼容|\\n\"}]],\"sections\":[[10,0]]}","html":"<div class=\"kg-card-markdown\"><table>\n<thead>\n<tr>\n<th></th>\n<th>utf8</th>\n<th>utf8mb4</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>长度</td>\n<td>最大3byte</td>\n<td>最大4byte</td>\n</tr>\n<tr>\n<td>历史</td>\n<td>一直在</td>\n<td>5.5.3版本后增加</td>\n</tr>\n<tr>\n<td>兼容</td>\n<td>N/S</td>\n<td>完全兼容utf8</td>\n</tr>\n<tr>\n<td>emoji</td>\n<td>一般不兼容，emoji一般是4个byte长度会出现编码异常</td>\n<td>可以兼容</td>\n</tr>\n</tbody>\n</table>\n</div>","amp":null,"plaintext":"utf8utf8mb4长度最大3byte最大4byte历史一直在5.5.3版本后增加兼容N/S完全兼容utf8emoji\n一般不兼容，emoji一般是4个byte长度会出现编码异常可以兼容","feature_image":"/content/images/2017/08/f54311c5c36a5c96139288448a4f5e1a.jpg","featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2017-08-03 05:47:05","created_by":"1","updated_at":"2017-08-03 06:03:37","updated_by":"1","published_at":"2017-08-03 05:57:45","published_by":"1","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null},{"id":"5982c1c1616dac5789b9fa25","uuid":"fc76aa78-dc3d-4d75-97ae-3e7404c079b2","title":"过滤掉json里为null的json","slug":"guo-lu-diao-jsonwei-nullde-json","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"## python里面过滤\\n\\n\\n```python2\\n#python2 下使用\\ndef del_none(d):\\n   \\n    for key, value in d.items():\\n        if value is None:\\n            del d[key]\\n        elif isinstance(value, dict):\\n            del_none(value)\\n    return d  \\n\\n#python3  下使用\\ndef del_none(d):\\n    for key, value in d.copy().items():\\n        if value is None or value == '':\\n            del d[key]\\n        elif isinstance(value, dict):\\n            del_none(value)\\n    return d\\n\\n...............\\n\\nresult_dic = {\\n    'meta': {\\n        'metaCode': 'Success',\\n        'cost': cost,\\n        'timestamp': end,\\n        'postname': 'python'\\n\\n  },\\n    'data': {\\n        'image': image,\\n        'title': title\\n    }\\n}\\njson.dumps(del_none(result_dic))\\n```\\n\\n## golang里面过滤掉为null的字段\\n\\n定义`omitempty`即可\\n```go \\ntype imageInfo struct {\\n  Width           int `json:\\\"width,omitempty\\\"`\\n  Height          int `json:\\\"height,omitempty\\\"`\\n  Author          int `json:\\\"author,omitempty\\\"`\\n  Size            int64 `json:\\\"size,omitempty\\\"`\\n  Format          string `json:\\\"format,omitempty\\\"`\\n  Ua              string `json:\\\"ua,omitempty\\\"`\\n  DecoderPlatform string `json:\\\"DecoderPlatform,omitempty\\\"`\\n}\\n\\n```\\n\\n## java 过滤掉不用null字段\\ntoo simple to skip\\n\\n\"}]],\"sections\":[[10,0]]}","html":"<div class=\"kg-card-markdown\"><h2 id=\"python\">python里面过滤</h2>\n<pre><code class=\"language-python2\">#python2 下使用\ndef del_none(d):\n   \n    for key, value in d.items():\n        if value is None:\n            del d[key]\n        elif isinstance(value, dict):\n            del_none(value)\n    return d  \n\n#python3  下使用\ndef del_none(d):\n    for key, value in d.copy().items():\n        if value is None or value == '':\n            del d[key]\n        elif isinstance(value, dict):\n            del_none(value)\n    return d\n\n...............\n\nresult_dic = {\n    'meta': {\n        'metaCode': 'Success',\n        'cost': cost,\n        'timestamp': end,\n        'postname': 'python'\n\n  },\n    'data': {\n        'image': image,\n        'title': title\n    }\n}\njson.dumps(del_none(result_dic))\n</code></pre>\n<h2 id=\"golangnull\">golang里面过滤掉为null的字段</h2>\n<p>定义<code>omitempty</code>即可</p>\n<pre><code class=\"language-go\">type imageInfo struct {\n  Width           int `json:&quot;width,omitempty&quot;`\n  Height          int `json:&quot;height,omitempty&quot;`\n  Author          int `json:&quot;author,omitempty&quot;`\n  Size            int64 `json:&quot;size,omitempty&quot;`\n  Format          string `json:&quot;format,omitempty&quot;`\n  Ua              string `json:&quot;ua,omitempty&quot;`\n  DecoderPlatform string `json:&quot;DecoderPlatform,omitempty&quot;`\n}\n\n</code></pre>\n<h2 id=\"javanull\">java 过滤掉不用null字段</h2>\n<p>too simple to skip</p>\n</div>","amp":null,"plaintext":"python里面过滤\n#python2 下使用\ndef del_none(d):\n   \n    for key, value in d.items():\n        if value is None:\n            del d[key]\n        elif isinstance(value, dict):\n            del_none(value)\n    return d  \n\n#python3  下使用\ndef del_none(d):\n    for key, value in d.copy().items():\n        if value is None or value == '':\n            del d[key]\n        elif isinstance(value, dict):\n            del_none(value)\n    return d\n\n...............\n\nresult_dic = {\n    'meta': {\n        'metaCode': 'Success',\n        'cost': cost,\n        'timestamp': end,\n        'postname': 'python'\n\n  },\n    'data': {\n        'image': image,\n        'title': title\n    }\n}\njson.dumps(del_none(result_dic))\n\n\ngolang里面过滤掉为null的字段\n定义omitempty即可\n\ntype imageInfo struct {\n  Width           int `json:\"width,omitempty\"`\n  Height          int `json:\"height,omitempty\"`\n  Author          int `json:\"author,omitempty\"`\n  Size            int64 `json:\"size,omitempty\"`\n  Format          string `json:\"format,omitempty\"`\n  Ua              string `json:\"ua,omitempty\"`\n  DecoderPlatform string `json:\"DecoderPlatform,omitempty\"`\n}\n\n\n\njava 过滤掉不用null字段\ntoo simple to skip","feature_image":null,"featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2017-08-03 06:25:05","created_by":"1","updated_at":"2017-08-03 06:27:52","updated_by":"1","published_at":"2017-08-03 06:27:49","published_by":"1","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null},{"id":"5982cb8b616dac5789b9fa2c","uuid":"6ab99913-5a8c-4cc5-9320-249343dc1cf4","title":"thrift golang server实现","slug":"thrift-golang","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"## 背景\\nhttps://thrift.apache.org/ 例子里面只有golang client的实现，没有具体的server的实现，这里通过查看java的实现进而推出来了golang server端的实现\\n\\n\\n\\n```golang\\nfunc RunServer() {\\n    .....#忽略前面addr神马的初始化\\n\\tlog.Println(\\\"enable video upload server addr\\\", addr)\\n\\ttransport, err := thrift.NewTServerSocket(addr)\\n\\n\\tlog.Println(\\\"NewTServerSocket  addr\\\", addr)\\n\\n    //这里需要和对应的语言method name params等等要一一对应上\\n\\thandler := &UploadVideoHandler{}\\n\\n\\tprocessor := NewUploadVideoProcessor(handler)\\n\\t\\n    //这里TransportFactory ProtocolFactory 都要一一对对应上，否则不通\\n\\tserver := thrift.NewTSimpleServer4(processor, transport,\\n\\t\\tthrift.NewTFramedTransportFactory(thrift.NewTTransportFactory()),\\n\\t\\tthrift.NewTCompactProtocolFactory())\\n\\n\\tlog.Println(\\\"Starting the simple server... on \\\", addr)\\n\\tserver.Serve()\\n}\\n\\ntype UploadVideoHandler struct{}\\n#服务端具体实现\\nfunc (p *UploadVideoHandler) Write(buffer []byte) (string, error) {\\n\\n\\t_, video_uuid, _, err := UploadVideo(buffer, 0, true, \\\"\\\", \\\"\\\")\\n\\n\\treturn video_uuid, err\\n}\\n\\n\\n```\"}]],\"sections\":[[10,0]]}","html":"<div class=\"kg-card-markdown\"><h2 id=\"\">背景</h2>\n<p><a href=\"https://thrift.apache.org/\">https://thrift.apache.org/</a> 例子里面只有golang client的实现，没有具体的server的实现，这里通过查看java的实现进而推出来了golang server端的实现</p>\n<pre><code class=\"language-golang\">func RunServer() {\n    .....#忽略前面addr神马的初始化\n\tlog.Println(&quot;enable video upload server addr&quot;, addr)\n\ttransport, err := thrift.NewTServerSocket(addr)\n\n\tlog.Println(&quot;NewTServerSocket  addr&quot;, addr)\n\n    //这里需要和对应的语言method name params等等要一一对应上\n\thandler := &amp;UploadVideoHandler{}\n\n\tprocessor := NewUploadVideoProcessor(handler)\n\t\n    //这里TransportFactory ProtocolFactory 都要一一对对应上，否则不通\n\tserver := thrift.NewTSimpleServer4(processor, transport,\n\t\tthrift.NewTFramedTransportFactory(thrift.NewTTransportFactory()),\n\t\tthrift.NewTCompactProtocolFactory())\n\n\tlog.Println(&quot;Starting the simple server... on &quot;, addr)\n\tserver.Serve()\n}\n\ntype UploadVideoHandler struct{}\n#服务端具体实现\nfunc (p *UploadVideoHandler) Write(buffer []byte) (string, error) {\n\n\t_, video_uuid, _, err := UploadVideo(buffer, 0, true, &quot;&quot;, &quot;&quot;)\n\n\treturn video_uuid, err\n}\n\n\n</code></pre>\n</div>","amp":null,"plaintext":"背景\nhttps://thrift.apache.org/  例子里面只有golang\nclient的实现，没有具体的server的实现，这里通过查看java的实现进而推出来了golang server端的实现\n\nfunc RunServer() {\n    .....#忽略前面addr神马的初始化\n\tlog.Println(\"enable video upload server addr\", addr)\n\ttransport, err := thrift.NewTServerSocket(addr)\n\n\tlog.Println(\"NewTServerSocket  addr\", addr)\n\n    //这里需要和对应的语言method name params等等要一一对应上\n\thandler := &UploadVideoHandler{}\n\n\tprocessor := NewUploadVideoProcessor(handler)\n\t\n    //这里TransportFactory ProtocolFactory 都要一一对对应上，否则不通\n\tserver := thrift.NewTSimpleServer4(processor, transport,\n\t\tthrift.NewTFramedTransportFactory(thrift.NewTTransportFactory()),\n\t\tthrift.NewTCompactProtocolFactory())\n\n\tlog.Println(\"Starting the simple server... on \", addr)\n\tserver.Serve()\n}\n\ntype UploadVideoHandler struct{}\n#服务端具体实现\nfunc (p *UploadVideoHandler) Write(buffer []byte) (string, error) {\n\n\t_, video_uuid, _, err := UploadVideo(buffer, 0, true, \"\", \"\")\n\n\treturn video_uuid, err\n}","feature_image":null,"featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2017-08-03 07:06:51","created_by":"1","updated_at":"2017-08-03 07:14:13","updated_by":"1","published_at":"2017-08-03 07:13:30","published_by":"1","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null},{"id":"5982cded616dac5789b9fa30","uuid":"a723da42-8adb-404d-a83d-46de87deefb9","title":"fix golang gif 解密器兼容","slug":"fix_golang_gif","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"## 背景\\n最近发现`go1.8.1`版本在处理用户传过来 faceU 的gif图片会报\\n`frame bounds larger than image bounds`\\n\\n也就是gif里面帧大约外边大小\\n\\n`gif/render.go`实现\\n```\\nfunc (d *decoder) newImageFromDescriptor() (*image.Paletted, error) {\\n\\tif err := readFull(d.r, d.tmp[:9]); err != nil {\\n\\t\\treturn nil, fmt.Errorf(\\\"gif: can't read image descriptor: %s\\\", err)\\n\\t}\\n\\tleft := int(d.tmp[0]) + int(d.tmp[1])<<8\\n\\ttop := int(d.tmp[2]) + int(d.tmp[3])<<8\\n\\twidth := int(d.tmp[4]) + int(d.tmp[5])<<8\\n\\theight := int(d.tmp[6]) + int(d.tmp[7])<<8\\n\\td.imageFields = d.tmp[8]\\n\\n\\t// The GIF89a spec, Section 20 (Image Descriptor) says:\\n\\t// \\\"Each image must fit within the boundaries of the Logical\\n\\t// Screen, as defined in the Logical Screen Descriptor.\\\"\\n\\tbounds := image.Rect(left, top, left+width, top+height)\\n\\tif bounds != bounds.Intersect(image.Rect(0, 0, d.width, d.height)) {\\n\\t\\treturn nil, errors.New(\\\"gif: frame bounds larger than image bounds\\\")\\n\\t}\\n\\treturn image.NewPaletted(bounds, nil), nil\\n}\\n```\\n做了很详细很精确的判断，里面的每一帧都不能大于外边框\\n\\n抱怨一下：\\n虽然规范是定义很清楚，但是很多人是不严格遵守，大部分显示gif的软件也不严格检查这样的偏差，还能看，所以我就收到反馈，为何别人都能显示，就你的不行，肯定是你的问题，fuck！\\n\\n虽然很愤怒但是还是含泪修改，虽然golang官方已经收到issues但是但是最新版还是不能兼容\\n故自己动手修改了一下放在自己工厂目录， 自己引用\\n\\njiemo_gif/reader.go\\n```\\nfunc (d *decoder) newImageFromDescriptor() (*image.Paletted, error) {\\n\\tif err := readFull(d.r, d.tmp[:9]); err != nil {\\n\\t\\treturn nil, fmt.Errorf(\\\"gif: can't read image descriptor: %s\\\", err)\\n\\t}\\n\\tleft := int(d.tmp[0]) + int(d.tmp[1])<<8\\n\\ttop := int(d.tmp[2]) + int(d.tmp[3])<<8\\n\\twidth := int(d.tmp[4]) + int(d.tmp[5])<<8\\n\\theight := int(d.tmp[6]) + int(d.tmp[7])<<8\\n\\td.imageFields = d.tmp[8]\\n\\n    //这里兼容一下，不过我只能容忍每一帧大于1px，我是有底线的！\\n\\tif left+width-1 > d.width || top+height-1 > d.height {\\n\\t\\treturn nil, errors.New(\\\"haio46 Fix  gif: frame bounds larger than image bounds\\\")\\n\\t}\\n\\treturn image.NewPaletted(image.Rectangle{\\n\\t\\tMin: image.Point{left, top},\\n\\t\\tMax: image.Point{left + width, top + height},\\n\\t}, nil), nil\\n}\\n\\n```\\n\"}]],\"sections\":[[10,0]]}","html":"<div class=\"kg-card-markdown\"><h2 id=\"\">背景</h2>\n<p>最近发现<code>go1.8.1</code>版本在处理用户传过来 faceU 的gif图片会报<br>\n<code>frame bounds larger than image bounds</code></p>\n<p>也就是gif里面帧大约外边大小</p>\n<p><code>gif/render.go</code>实现</p>\n<pre><code>func (d *decoder) newImageFromDescriptor() (*image.Paletted, error) {\n\tif err := readFull(d.r, d.tmp[:9]); err != nil {\n\t\treturn nil, fmt.Errorf(&quot;gif: can't read image descriptor: %s&quot;, err)\n\t}\n\tleft := int(d.tmp[0]) + int(d.tmp[1])&lt;&lt;8\n\ttop := int(d.tmp[2]) + int(d.tmp[3])&lt;&lt;8\n\twidth := int(d.tmp[4]) + int(d.tmp[5])&lt;&lt;8\n\theight := int(d.tmp[6]) + int(d.tmp[7])&lt;&lt;8\n\td.imageFields = d.tmp[8]\n\n\t// The GIF89a spec, Section 20 (Image Descriptor) says:\n\t// &quot;Each image must fit within the boundaries of the Logical\n\t// Screen, as defined in the Logical Screen Descriptor.&quot;\n\tbounds := image.Rect(left, top, left+width, top+height)\n\tif bounds != bounds.Intersect(image.Rect(0, 0, d.width, d.height)) {\n\t\treturn nil, errors.New(&quot;gif: frame bounds larger than image bounds&quot;)\n\t}\n\treturn image.NewPaletted(bounds, nil), nil\n}\n</code></pre>\n<p>做了很详细很精确的判断，里面的每一帧都不能大于外边框</p>\n<p>抱怨一下：<br>\n虽然规范是定义很清楚，但是很多人是不严格遵守，大部分显示gif的软件也不严格检查这样的偏差，还能看，所以我就收到反馈，为何别人都能显示，就你的不行，肯定是你的问题，fuck！</p>\n<p>虽然很愤怒但是还是含泪修改，虽然golang官方已经收到issues但是但是最新版还是不能兼容<br>\n故自己动手修改了一下放在自己工厂目录， 自己引用</p>\n<p>jiemo_gif/reader.go</p>\n<pre><code>func (d *decoder) newImageFromDescriptor() (*image.Paletted, error) {\n\tif err := readFull(d.r, d.tmp[:9]); err != nil {\n\t\treturn nil, fmt.Errorf(&quot;gif: can't read image descriptor: %s&quot;, err)\n\t}\n\tleft := int(d.tmp[0]) + int(d.tmp[1])&lt;&lt;8\n\ttop := int(d.tmp[2]) + int(d.tmp[3])&lt;&lt;8\n\twidth := int(d.tmp[4]) + int(d.tmp[5])&lt;&lt;8\n\theight := int(d.tmp[6]) + int(d.tmp[7])&lt;&lt;8\n\td.imageFields = d.tmp[8]\n\n    //这里兼容一下，不过我只能容忍每一帧大于1px，我是有底线的！\n\tif left+width-1 &gt; d.width || top+height-1 &gt; d.height {\n\t\treturn nil, errors.New(&quot;haio46 Fix  gif: frame bounds larger than image bounds&quot;)\n\t}\n\treturn image.NewPaletted(image.Rectangle{\n\t\tMin: image.Point{left, top},\n\t\tMax: image.Point{left + width, top + height},\n\t}, nil), nil\n}\n\n</code></pre>\n</div>","amp":null,"plaintext":"背景\n最近发现go1.8.1版本在处理用户传过来 faceU 的gif图片会报\nframe bounds larger than image bounds\n\n也就是gif里面帧大约外边大小\n\ngif/render.go实现\n\nfunc (d *decoder) newImageFromDescriptor() (*image.Paletted, error) {\n\tif err := readFull(d.r, d.tmp[:9]); err != nil {\n\t\treturn nil, fmt.Errorf(\"gif: can't read image descriptor: %s\", err)\n\t}\n\tleft := int(d.tmp[0]) + int(d.tmp[1])<<8\n\ttop := int(d.tmp[2]) + int(d.tmp[3])<<8\n\twidth := int(d.tmp[4]) + int(d.tmp[5])<<8\n\theight := int(d.tmp[6]) + int(d.tmp[7])<<8\n\td.imageFields = d.tmp[8]\n\n\t// The GIF89a spec, Section 20 (Image Descriptor) says:\n\t// \"Each image must fit within the boundaries of the Logical\n\t// Screen, as defined in the Logical Screen Descriptor.\"\n\tbounds := image.Rect(left, top, left+width, top+height)\n\tif bounds != bounds.Intersect(image.Rect(0, 0, d.width, d.height)) {\n\t\treturn nil, errors.New(\"gif: frame bounds larger than image bounds\")\n\t}\n\treturn image.NewPaletted(bounds, nil), nil\n}\n\n\n做了很详细很精确的判断，里面的每一帧都不能大于外边框\n\n抱怨一下：\n虽然规范是定义很清楚，但是很多人是不严格遵守，大部分显示gif的软件也不严格检查这样的偏差，还能看，所以我就收到反馈，为何别人都能显示，就你的不行，肯定是你的问题，fuck！\n\n虽然很愤怒但是还是含泪修改，虽然golang官方已经收到issues但是但是最新版还是不能兼容\n故自己动手修改了一下放在自己工厂目录， 自己引用\n\njiemo_gif/reader.go\n\nfunc (d *decoder) newImageFromDescriptor() (*image.Paletted, error) {\n\tif err := readFull(d.r, d.tmp[:9]); err != nil {\n\t\treturn nil, fmt.Errorf(\"gif: can't read image descriptor: %s\", err)\n\t}\n\tleft := int(d.tmp[0]) + int(d.tmp[1])<<8\n\ttop := int(d.tmp[2]) + int(d.tmp[3])<<8\n\twidth := int(d.tmp[4]) + int(d.tmp[5])<<8\n\theight := int(d.tmp[6]) + int(d.tmp[7])<<8\n\td.imageFields = d.tmp[8]\n\n    //这里兼容一下，不过我只能容忍每一帧大于1px，我是有底线的！\n\tif left+width-1 > d.width || top+height-1 > d.height {\n\t\treturn nil, errors.New(\"haio46 Fix  gif: frame bounds larger than image bounds\")\n\t}\n\treturn image.NewPaletted(image.Rectangle{\n\t\tMin: image.Point{left, top},\n\t\tMax: image.Point{left + width, top + height},\n\t}, nil), nil\n}","feature_image":"/content/images/2017/08/timg-1.gif","featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2017-08-03 07:17:01","created_by":"1","updated_at":"2017-08-03 07:51:09","updated_by":"1","published_at":"2017-08-03 07:30:05","published_by":"1","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null},{"id":"5982dcd9616dac5789b9fa36","uuid":"521a63db-12c0-44a1-8fa7-eb428a0f5358","title":"tensorflow 项目相关","slug":"tu-pian-chu-li-xiang-mu-shou-ji","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"## 背景\\n手机图片处理相关的项目，先收集慢慢研究\\n|序号|项目|说明|\\n|-|-|-|\\n|1|[face_recognition](https://github.com/ageitgey/face_recognition)|人脸识别和比对，比较人脸直接的差距,描绘人脸坐标|\\n|2|[image_recognition](https://www.tensorflow.org/tutorials/image_recognition)|识别图片里面物体  使用tensorflow|\\n3|[primitive](https://github.com/fogleman/primitive)|可以把图片处理成一定风格，例如像手绘  使用golang\\n4|[have-fun-with-machine-learning](https://github.com/humphd/have-fun-with-machine-learning)|机器学习与神经网络图像分类的初级指南，使用Caffe|\\n5|[label_image](https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/examples/label_image/README.md)|识别图片分裂，比项目2`image_recognition`的识别率高\\n6![age-gender-estimation](https://github.com/yu4u/age-gender-estimation)|性别年级识别\\n\\n## 备注\\n`tensorflow`是目前最火的机器学习项目\\n目前里面有一个demo可以实现对不同分类的训练和识别`retrain.py` `label_image.py`\"}]],\"sections\":[[10,0]]}","html":"<div class=\"kg-card-markdown\"><h2 id=\"\">背景</h2>\n<p>手机图片处理相关的项目，先收集慢慢研究</p>\n<table>\n<thead>\n<tr>\n<th>序号</th>\n<th>项目</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td><a href=\"https://github.com/ageitgey/face_recognition\">face_recognition</a></td>\n<td>人脸识别和比对，比较人脸直接的差距,描绘人脸坐标</td>\n</tr>\n<tr>\n<td>2</td>\n<td><a href=\"https://www.tensorflow.org/tutorials/image_recognition\">image_recognition</a></td>\n<td>识别图片里面物体  使用tensorflow</td>\n</tr>\n<tr>\n<td>3</td>\n<td><a href=\"https://github.com/fogleman/primitive\">primitive</a></td>\n<td>可以把图片处理成一定风格，例如像手绘  使用golang</td>\n</tr>\n<tr>\n<td>4</td>\n<td><a href=\"https://github.com/humphd/have-fun-with-machine-learning\">have-fun-with-machine-learning</a></td>\n<td>机器学习与神经网络图像分类的初级指南，使用Caffe</td>\n</tr>\n<tr>\n<td>5</td>\n<td><a href=\"https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/examples/label_image/README.md\">label_image</a></td>\n<td>识别图片分裂，比项目2<code>image_recognition</code>的识别率高</td>\n</tr>\n<tr>\n<td>6<img src=\"https://github.com/yu4u/age-gender-estimation\" alt=\"age-gender-estimation\"></td>\n<td>性别年级识别</td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"\">备注</h2>\n<p><code>tensorflow</code>是目前最火的机器学习项目<br>\n目前里面有一个demo可以实现对不同分类的训练和识别<code>retrain.py</code> <code>label_image.py</code></p>\n</div>","amp":null,"plaintext":"背景\n手机图片处理相关的项目，先收集慢慢研究\n\n序号项目说明1face_recognition [https://github.com/ageitgey/face_recognition]\n人脸识别和比对，比较人脸直接的差距,描绘人脸坐标2image_recognition\n[https://www.tensorflow.org/tutorials/image_recognition]识别图片里面物体 使用tensorflow3\nprimitive [https://github.com/fogleman/primitive]可以把图片处理成一定风格，例如像手绘 使用golang4\nhave-fun-with-machine-learning\n[https://github.com/humphd/have-fun-with-machine-learning]\n机器学习与神经网络图像分类的初级指南，使用Caffe5label_image\n[https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/examples/label_image/README.md]\n识别图片分裂，比项目2image_recognition的识别率高6性别年级识别备注\ntensorflow是目前最火的机器学习项目\n目前里面有一个demo可以实现对不同分类的训练和识别retrain.py  label_image.py","feature_image":null,"featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2017-08-03 08:20:41","created_by":"1","updated_at":"2017-08-14 09:50:48","updated_by":"1","published_at":"2017-08-03 08:30:03","published_by":"1","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null},{"id":"598d16ee5eddf6628687dabc","uuid":"b5311240-65c4-4de9-a45d-0ef67d23b796","title":"颜值打分","slug":"yan-zhi-da-fen","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"### 介绍\\n利用tensorflow学习检索识别图片，创建6个分类\\n```\\n                {'shuaige': '帅哥',\\n                'chounan': '丑男',\\n                'meinv': '美女',\\n                'chounv': '丑女',\\n                'xinggan': '性感美女',\\n                'dachangtui': '长腿美女'\\n                }\\n```\\n这里创建训练模型很重要，你选择的每个分类图片也很关键 可以查看训练图片选择标准 [creating_a_set_of_training_images](https://www.tensorflow.org/tutorials/image_retraining#creating_a_set_of_training_images),总之图片越多越好，你要表达的物体越突出越好，场景变化越多越好\\n\\n哈哈哈  说一下我选的图片是从百度搜索下载的【chrome插件一键下载】，然后挑选我自己的审美标准，有意思的是，通过我选择的样本识别`鹿晗`是`性感美女`的 哈哈哈【鹿晗粉丝不要到我】,所以说样本的选取很重要，你可以控制对应类别的效果。这里你把鹿晗的图片添加到帅哥类别去就好了 \\n\\n### 分析原理\\n我在建立模型的时候规定\\n\\n女生包括：美女、丑女、性感美女、长腿美女\\n男生包括：帅哥、丑男\\n其实可以规定：女生颜值好=美女+性感美女+长腿美女，颜值不好=丑女，然后计算即可。男生计算亦然\\n\\n### 效果\\n|图片|结果|\\n|-|-|\\n|<img width=\\\"320\\\"  src=\\\"http://img.tupianzj.com/uploads/allimg/151228/9-15122R02H0.jpg\\\" />|性感女生<br> \\t颜值=100.00<br> 性感美女[0.96357]<br>长腿美女[0.03571]<br>美女[0.00063]<br>帅哥[0.00007]<br>丑男[0.00001]|\\n|<img width=\\\"320\\\"  src=\\\"https://b-ssl.duitang.com/uploads/item/201403/29/20140329133232_EsQtf.thumb.700_0.jpeg\\\"/>|应该是女生 颜值=95.90<br> 性感美女[0.96357]<br>长腿美女[0.03571]<br>美女[0.00063]<br>帅哥[0.00007]<br>丑男[0.00001]|\\n|<img width=\\\"320\\\"  src=\\\"http://pic2016.ytqmx.com:82/2016/0516/19/1.jpg!960.jpg\\\" />|应该是男生 颜值=94.67<br>帅哥[0.70277]<br>美女[0.19696]<br>丑男[0.03956]<br>丑女[0.03245]<br>性感美女[0.02657]|\\n\\n\\n### 相关链接\\n[image_retraining  doc](https://www.tensorflow.org/tutorials/image_retraining)\\n[image_retraining code](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/label_image)[本例子就是通过它修改而来]\"}]],\"sections\":[[10,0]]}","html":"<div class=\"kg-card-markdown\"><h3 id=\"\">介绍</h3>\n<p>利用tensorflow学习检索识别图片，创建6个分类</p>\n<pre><code>                {'shuaige': '帅哥',\n                'chounan': '丑男',\n                'meinv': '美女',\n                'chounv': '丑女',\n                'xinggan': '性感美女',\n                'dachangtui': '长腿美女'\n                }\n</code></pre>\n<p>这里创建训练模型很重要，你选择的每个分类图片也很关键 可以查看训练图片选择标准 <a href=\"https://www.tensorflow.org/tutorials/image_retraining#creating_a_set_of_training_images\">creating_a_set_of_training_images</a>,总之图片越多越好，你要表达的物体越突出越好，场景变化越多越好</p>\n<p>哈哈哈  说一下我选的图片是从百度搜索下载的【chrome插件一键下载】，然后挑选我自己的审美标准，有意思的是，通过我选择的样本识别<code>鹿晗</code>是<code>性感美女</code>的 哈哈哈【鹿晗粉丝不要到我】,所以说样本的选取很重要，你可以控制对应类别的效果。这里你把鹿晗的图片添加到帅哥类别去就好了</p>\n<h3 id=\"\">分析原理</h3>\n<p>我在建立模型的时候规定</p>\n<p>女生包括：美女、丑女、性感美女、长腿美女<br>\n男生包括：帅哥、丑男<br>\n其实可以规定：女生颜值好=美女+性感美女+长腿美女，颜值不好=丑女，然后计算即可。男生计算亦然</p>\n<h3 id=\"\">效果</h3>\n<table>\n<thead>\n<tr>\n<th>图片</th>\n<th>结果</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><img width=\"320\"  src=\"http://img.tupianzj.com/uploads/allimg/151228/9-15122R02H0.jpg\" /></td>\n<td>性感女生<br> \t颜值=100.00<br> 性感美女[0.96357]<br>长腿美女[0.03571]<br>美女[0.00063]<br>帅哥[0.00007]<br>丑男[0.00001]</td>\n</tr>\n<tr>\n<td><img width=\"320\"  src=\"https://b-ssl.duitang.com/uploads/item/201403/29/20140329133232_EsQtf.thumb.700_0.jpeg\"/></td>\n<td>应该是女生 颜值=95.90<br> 性感美女[0.96357]<br>长腿美女[0.03571]<br>美女[0.00063]<br>帅哥[0.00007]<br>丑男[0.00001]</td>\n</tr>\n<tr>\n<td><img width=\"320\"  src=\"http://pic2016.ytqmx.com:82/2016/0516/19/1.jpg!960.jpg\" /></td>\n<td>应该是男生 颜值=94.67<br>帅哥[0.70277]<br>美女[0.19696]<br>丑男[0.03956]<br>丑女[0.03245]<br>性感美女[0.02657]</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"\">相关链接</h3>\n<p><a href=\"https://www.tensorflow.org/tutorials/image_retraining\">image_retraining  doc</a><br>\n<a href=\"https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/label_image\">image_retraining code</a>[本例子就是通过它修改而来]</p>\n</div>","amp":null,"plaintext":"介绍\n利用tensorflow学习检索识别图片，创建6个分类\n\n                {'shuaige': '帅哥',\n                'chounan': '丑男',\n                'meinv': '美女',\n                'chounv': '丑女',\n                'xinggan': '性感美女',\n                'dachangtui': '长腿美女'\n                }\n\n\n这里创建训练模型很重要，你选择的每个分类图片也很关键 可以查看训练图片选择标准 creating_a_set_of_training_images\n,总之图片越多越好，你要表达的物体越突出越好，场景变化越多越好\n\n哈哈哈 说一下我选的图片是从百度搜索下载的【chrome插件一键下载】，然后挑选我自己的审美标准，有意思的是，通过我选择的样本识别鹿晗是性感美女的\n哈哈哈【鹿晗粉丝不要到我】,所以说样本的选取很重要，你可以控制对应类别的效果。这里你把鹿晗的图片添加到帅哥类别去就好了\n\n分析原理\n我在建立模型的时候规定\n\n女生包括：美女、丑女、性感美女、长腿美女\n男生包括：帅哥、丑男\n其实可以规定：女生颜值好=美女+性感美女+长腿美女，颜值不好=丑女，然后计算即可。男生计算亦然\n\n效果\n图片结果应该是性感女生 \t颜值=88.20\n性感美女[0.90954]\n长腿美女[0.05739]\n美女[0.02789]\n丑女[0.00373]\n丑男[0.00130]性感女生\n颜值=100.00\n性感美女[0.96357]\n长腿美女[0.03571]\n美女[0.00063]\n帅哥[0.00007]\n丑男[0.00001]应该是女生 颜值=95.90\n性感美女[0.96357]\n长腿美女[0.03571]\n美女[0.00063]\n帅哥[0.00007]\n丑男[0.00001]应该是男生 颜值=94.67\n帅哥[0.70277]\n美女[0.19696]\n丑男[0.03956]\n丑女[0.03245]\n性感美女[0.02657]","feature_image":null,"featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2017-08-11 02:31:10","created_by":"1","updated_at":"2017-08-11 07:21:21","updated_by":"1","published_at":"2017-08-11 02:54:50","published_by":"1","custom_excerpt":null,"codeinjection_head":"","codeinjection_foot":"","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null},{"id":"599170605eddf6628687dac2","uuid":"77cb44d8-7e78-42bf-bd10-f54e15076525","title":"python  安装问题汇总","slug":"python","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"\\n1. 安装opencv3出现版本冲突\\n`Error: opencv3: Does not support building both Python 2 and 3 wrappers`\\n```\\nbrew install opencv3 --with-contrib --with-python3 --without-python\\n```\\n安装玩提示\\n```\\nFor compilers to find this software you may need to set:\\n    LDFLAGS:  -L/usr/local/opt/opencv3/lib\\n    CPPFLAGS: -I/usr/local/opt/opencv3/include\\nFor pkg-config to find this software you may need to set:\\n    PKG_CONFIG_PATH: /usr/local/opt/opencv3/lib/pkgconfig\\n```\\n\\n我的mac路径python pkg路径：`/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages`\\n\\n\\n所以需要把opencv3依赖导入\\n但是前面要记住，so库的名字必须是`cv2.so`我的机子上名字是`cv2.cpython-36m-darwin.so`\\n```sh\\n/usr/local/opt/opencv3/lib/python3.6/site-packages \\n-r--r--r--  1 haizhu  admin   4.3M  8 15 11:00 cv2.cpython-36m-darwin.so\\n```\\n然后`mv cv2.cpython-36m-darwin.so  cv2.so`\\n\\n`\\necho /usr/local/opt/opencv3/lib/python3.6/site-packages >>/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/opencv3.pth\\n`\\n2. \\n\"}]],\"sections\":[[10,0]]}","html":"<div class=\"kg-card-markdown\"><ol>\n<li>安装opencv3出现版本冲突<br>\n<code>Error: opencv3: Does not support building both Python 2 and 3 wrappers</code></li>\n</ol>\n<pre><code>brew install opencv3 --with-contrib --with-python3 --without-python\n</code></pre>\n<p>安装玩提示</p>\n<pre><code>For compilers to find this software you may need to set:\n    LDFLAGS:  -L/usr/local/opt/opencv3/lib\n    CPPFLAGS: -I/usr/local/opt/opencv3/include\nFor pkg-config to find this software you may need to set:\n    PKG_CONFIG_PATH: /usr/local/opt/opencv3/lib/pkgconfig\n</code></pre>\n<p>我的mac路径python pkg路径：<code>/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages</code></p>\n<p>所以需要把opencv3依赖导入<br>\n但是前面要记住，so库的名字必须是<code>cv2.so</code>我的机子上名字是<code>cv2.cpython-36m-darwin.so</code></p>\n<pre><code class=\"language-sh\">/usr/local/opt/opencv3/lib/python3.6/site-packages \n-r--r--r--  1 haizhu  admin   4.3M  8 15 11:00 cv2.cpython-36m-darwin.so\n</code></pre>\n<p>然后<code>mv cv2.cpython-36m-darwin.so cv2.so</code></p>\n<p><code>echo /usr/local/opt/opencv3/lib/python3.6/site-packages &gt;&gt;/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/opencv3.pth</code><br>\n2.</p>\n</div>","amp":null,"plaintext":"1. 安装opencv3出现版本冲突\n    Error: opencv3: Does not support building both Python 2 and 3 wrappers\n\nbrew install opencv3 --with-contrib --with-python3 --without-python\n\n\n安装玩提示\n\nFor compilers to find this software you may need to set:\n    LDFLAGS:  -L/usr/local/opt/opencv3/lib\n    CPPFLAGS: -I/usr/local/opt/opencv3/include\nFor pkg-config to find this software you may need to set:\n    PKG_CONFIG_PATH: /usr/local/opt/opencv3/lib/pkgconfig\n\n\n我的mac路径python pkg路径：\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages\n\n所以需要把opencv3依赖导入\n但是前面要记住，so库的名字必须是cv2.so我的机子上名字是cv2.cpython-36m-darwin.so\n\n/usr/local/opt/opencv3/lib/python3.6/site-packages \n-r--r--r--  1 haizhu  admin   4.3M  8 15 11:00 cv2.cpython-36m-darwin.so\n\n\n然后mv cv2.cpython-36m-darwin.so cv2.so\n\necho /usr/local/opt/opencv3/lib/python3.6/site-packages\n>>/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/opencv3.pth\n2.","feature_image":null,"featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2017-08-14 09:41:52","created_by":"1","updated_at":"2017-08-15 03:13:27","updated_by":"1","published_at":"2017-08-14 09:49:35","published_by":"1","custom_excerpt":null,"codeinjection_head":"","codeinjection_foot":"","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null},{"id":"5993b236f36c876ae083d898","uuid":"e0dccb99-2333-4292-9344-f0a6d5a4fd70","title":"numpy 学习笔记","slug":"numpy-xue-xi-bi-ji","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"## 说明\\n- 根据 http://old.sebug.net/paper/books/scipydoc/numpy_intro.html 学习而来，这里是自己敲写练习笔记，并写注释以及标明例子和实际情况的不同\\n- 我使用的是python3控制台，table有提示 并且有些地方和python2不同\\n###  定义\\nNumPy提供了两种基本的对象：ndarray（N-dimensional array object）和 ufunc（universal function object）。ndarray(下文统一称之为数组)是存储单一数据类型的多维数组，而ufunc则是能够对数组进行处理的函数\\n### np数据类型\\n```\\nData type\\tDescription\\nbool_\\tBoolean (True or False) stored as a byte\\nint_\\tDefault integer type (same as C long; normally either int64 or int32)\\nintc\\tIdentical to C int (normally int32 or int64)\\nintp\\tInteger used for indexing (same as C ssize_t; normally either int32 or int64)\\nint8\\tByte (-128 to 127)\\nint16\\tInteger (-32768 to 32767)\\nint32\\tInteger (-2147483648 to 2147483647)\\nint64\\tInteger (-9223372036854775808 to 9223372036854775807)\\nuint8\\tUnsigned integer (0 to 255)\\nuint16\\tUnsigned integer (0 to 65535)\\nuint32\\tUnsigned integer (0 to 4294967295)\\nuint64\\tUnsigned integer (0 to 18446744073709551615)\\nfloat_\\tShorthand for float64.\\nfloat16\\tHalf precision float: sign bit, 5 bits exponent, 10 bits mantissa\\nfloat32\\tSingle precision float: sign bit, 8 bits exponent, 23 bits mantissa\\nfloat64\\tDouble precision float: sign bit, 11 bits exponent, 52 bits mantissa\\ncomplex_\\tShorthand for complex128.\\ncomplex64\\tComplex number, represented by two 32-bit floats (real and imaginary components)\\ncomplex128\\tComplex number, represented by two 64-bit floats (real and imaginary components)\\n\\n```\\n\\n### 初始化数组\\n\\n\\n```python\\n>>> import numpy as np\\n>>> a=np.array([1,2,3,4])\\n>>> b=np.array([5,6,7,8])\\n>>> c=np.array([[1,2,3,4],[4,5,6,7],[7,8,9,0]])\\n>>> b\\narray([5, 6, 7, 8])\\n>>> c\\narray([[1, 2, 3, 4],\\n       [4, 5, 6, 7],\\n       [7, 8, 9, 0]])\\n>>> c.s  #哈哈哈这就是python3的提升，不错\\nc.searchsorted( c.setflags(     c.size          c.squeeze(      c.strides       c.swapaxes(    \\nc.setfield(     c.shape         c.sort(         c.std(          c.sum(         \\n>>> c.shape ##显示是3行4类2维数组\\n(3, 4)\\n>>> c.shape=2,-1  #修改成2行数组，-1自己计算列数\\n>>> c.shape\\n(2, 6)\\n>>> \\n>>> c.shape=5,-1  #如果总元素的个数不能整除，会提示不能更改数组大小提示\\nTraceback (most recent call last):\\n  File \\\"<stdin>\\\", line 1, in <module>\\nValueError: cannot reshape array of size 12 into shape (5,newaxis)\\n>>> \\n\\n\\n\\n>>> d=a.reshape((2,2)) #reshape是重新创建一个新的数组赋值给d，a按保持不变\\n>>> d\\narray([[1, 2],\\n       [3, 4]])\\n>>> a\\narray([1, 2, 3, 4])\\n>>> \\n\\n##但是他们之间的 \\\"内存是共享\\\"的，修改其中一个值，另外的也会随着改变\\n>>> a[1]=10\\n>>> d #修改a，b也变化了\\narray([[ 1, 10],\\n       [ 3,  4]])\\n>>> a \\narray([ 1, 10,  3,  4])\\n>>> a.dtype  ##我是mac 64位系统,和教程是不一样的\\ndtype('int64')\\n\\n\\n>>> np.array([[1,3],[3,4]],dtype=np.float)#指定float类型\\narray([[ 1.,  3.],\\n       [ 3.,  4.]])\\n\\n\\n>>> \\n>>> \\n>>> np.arange(0,1,1)#定义[0,1)数组，步长是1\\narray([0])\\n>>> np.arange(0,1,0.1)#定义[0,1)数组，步长是0.1\\narray([ 0. ,  0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9])\\n>>> np.arange(0,10,1)\\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\\n>>> \\n>>> \\n>>> np.linspace(0,10,10)  ## 定义个0到10之间数组，一共10个元素\\narray([  0.        ,   1.11111111,   2.22222222,   3.33333333,\\n         4.44444444,   5.55555556,   6.66666667,   7.77777778,\\n         8.88888889,  10.        ])\\n>>> np.linspace(0,10,9)\\narray([  0.  ,   1.25,   2.5 ,   3.75,   5.  ,   6.25,   7.5 ,   8.75,  10.  ])\\n>>> np.linspace(0,10,11)\\narray([  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.])\\n>>> \\n\\n\\n>>>  \\n>>> np.logspace(0,2,20)  #0到2，通过等比创建20个元素\\narray([   1.        ,    1.27427499,    1.62377674,    2.06913808,\\n          2.6366509 ,    3.35981829,    4.2813324 ,    5.45559478,\\n          6.95192796,    8.8586679 ,   11.28837892,   14.38449888,\\n         18.32980711,   23.35721469,   29.76351442,   37.92690191,\\n         48.32930239,   61.58482111,   78.47599704,  100.        ])\\n>>> np.logspace(0,10,2) #0到2，通过等比创建2个元素\\narray([  1.00000000e+00,   1.00000000e+10])\\n>>> \\n\\n>>> \\n>>> s='1111'\\n>>> np.fromstring(s, dtype=np.int8)  #把string变成int8\\narray([49, 49, 49, 49], dtype=int8)\\n>>> \\n>>> \\n\\n\\n\\n>>> def func(i):\\n...     return i%4+1\\n... \\n>>> np.fromfunction(func,(10,)) #注意这里是（10，）会认为是数组，(10)会err\\narray([ 1.,  2.,  3.,  4.,  1.,  2.,  3.,  4.,  1.,  2.])\\n>>> \\n>>> def func(i):\\n...     return i, i%4+1\\n... \\n>>> np.fromfunction(func,(10,))\\n(array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.]), array([ 1.,  2.,  3.,  4.,  1.,  2.,  3.,  4.,  1.,  2.]))\\n>>> \\n>>> \\n>>>\\n>>> a = np.arange(10)\\n>>> a\\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\\n>>> a[3:5]\\narray([3, 4])\\n>>> a[3:5]\\narray([3, 4])\\n>>> a[3:5]#第[3,5)元素，包括第3个元素，不包括5\\narray([3, 4])\\n>>> a\\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\\n>>> a\\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\\n>>> a[3:5]\\narray([3, 4])\\n>>> a[2:4] = 100,101  #修改a[2]=100,a[3]=101\\n>>> a\\narray([  0,   1, 100, 101,   4,   5,   6,   7,   8,   9])\\n\\na[:-1]#表示到倒数第1个元素，但是不包括   和redis有一点点差别\\narray([  0,   1, 100, 101,   4,   5,   6,   7,   8])\\n\\n\\n\\n>>> a[::2]  #  %2==0取出来\\narray([  0, 100,   4,   6,   8])\\n>>> a[1:-1:2] # 限制了一个范围\\narray([  1, 101,   5,   7])\\n>>> a[1:-1]\\narray([  1, 100, 101,   4,   5,   6,   7,   8])\\n>>> \\n\\n\\n>>> \\n>>> \\n>>> x = np.arange(10,1,-1)\\n>>> x\\narray([10,  9,  8,  7,  6,  5,  4,  3,  2])\\n>>> x[[3, 3, 1, 8]]  #靠，还可使用数组小标取\\narray([7, 7, 9, 2])\\n>>> \\n\\n\\n\\n>>> x = np.arange(10,1,-1)\\n>>> x\\narray([10,  9,  8,  7,  6,  5,  4,  3,  2])\\n>>> x[[3, 3, 1, 8]]\\narray([7, 7, 9, 2])\\n>>> b = x[np.array([3,3,-3,8])]   #索引还能为负\\n>>> b\\narray([7, 7, 4, 2])\\n>>> x\\narray([10,  9,  8,  7,  6,  5,  4,  3,  2])\\n>>> x[-1]  倒数第一个元素\\n2\\n>>>  \\n>>> \\n>>> x[[3,5,1]] = -1, -2, -3 # 整数序列下标也可以用来修改元素的值\\n>>> x\\narray([10, -3,  8, -1,  6, -2,  4,  3,  2])\\n>>> \\n\\n\\n\\n>>> x=np.random.rand(10)\\n>>> x\\narray([ 0.64988185,  0.82156594,  0.50822433,  0.70013378,  0.78289356,\\n        0.17419819,  0.11904243,  0.89411913,  0.21694376,  0.19730514])\\n>>> \\n>>> x>0.5  # 是每一个比较  666666\\narray([ True,  True,  True,  True,  True, False, False,  True, False, False], dtype=bool)\\n>>>  x[x>0.5] # 只有元素大于0.5的才返回  666\\narray([ 0.64988185,  0.82156594,  0.50822433,  0.70013378,  0.78289356,\\n        0.89411913])\\n>>> \\n```\\n\\n### 多维数组\\n```\\n>>> np.arange(0,60,10)\\narray([ 0, 10, 20, 30, 40, 50])\\n>>> np.arange(0,60,10).reshape(-1,1)\\narray([[ 0],\\n       [10],\\n       [20],\\n       [30],\\n       [40],\\n       [50]])\\n>>> np.arange(0,6)\\narray([0, 1, 2, 3, 4, 5])\\n>>> np.arange(0,60,10).reshape(-1,1)+np.arange(0,6)#不同维度数组相加\\narray([[ 0,  1,  2,  3,  4,  5],\\n       [10, 11, 12, 13, 14, 15],\\n       [20, 21, 22, 23, 24, 25],\\n       [30, 31, 32, 33, 34, 35],\\n       [40, 41, 42, 43, 44, 45],\\n       [50, 51, 52, 53, 54, 55]])\\n\\n>>>\\n```\\n### 自定义结构类型\\n\\n```\\n>>> persontype = np.dtype({\\n    'names':['name', 'age', 'weight'],\\n    'formats':['S32','i', 'f']})\\n>>> a = np.array([(\\\"Zhang\\\",32,75.5),(\\\"Wang\\\",24,65.2)],\\n    dtype=persontype)\\n>>> a\\narray([(b'Zhang', 32,  75.5       ), (b'Wang', 24,  65.19999695)],\\n      dtype=[('name', 'S32'), ('age', '<i4'), ('weight', '<f4')])\\n>>> a[0]['name']\\nb'Zhang'\\n>>> a[0]['age']\\n32\\n\\n```\\n\\nformats定义：\\n- S32 : 32个字节的字符串类型，由于结构中的每个元素的大小必须固定，因此需要指定字符串的长度\\n- i : 32bit的整数类型，相当于np.int32\\n- f : 32bit的单精度浮点数类型，相当于np.float32\\n\\n 类型描述：\\n- | : 忽视字节顺序\\n- < : 低位字节在前\\n- \\\\> : 高位字节在前\\n\\n```\\n>>> b=a[:][\\\"age\\\"]#获取所有数组的'age'\\n>>> b\\narray([32, 24], dtype=int32)\\n>>> a[0]\\n(b'Zhang', 32,  75.5)\\n>>> b[0]=1 #修改器年级  因为内存共享所以会相互影响\\n>>> a[0]\\n(b'Zhang', 1,  75.5)\\n```\\n\\n### 内存结构\\n![](http://old.sebug.net/paper/books/scipydoc/_images/numpy_memory_struct.png)\\n\\n```\\n>>> c = np.array([[0,1,2],[3,4,5],[6,7,8]], dtype=np.float32, order=\\\"F\\\")\\n>>> c.strides\\n(4, 12)  # 4表示一维增加1时候，需要4字节，12表第二维增加一需要增加12字节\\n```\\n\\n元素在数据存储区中的排列格式有两种：C语言格式和Fortan语言格式。在C语言中，多维数组的第0轴是最上位的，即第0轴的下标增加1时，元素的地址增加的字节数最多；而Fortan语言的多维数组的第0轴是最下位的，即第0轴的下标增加1时，地址只增加一个元素的字节数。在NumPy中，元素在内存中的排列缺省是以C语言格式存储的，如果你希望改为Fortan格式的话，只需要给数组传递order=\\\"F\\\"参数：\\n```\\n>>> c = np.array([[0,1,2],[3,4,5],[6,7,8]], dtype=np.float32, order=\\\"F\\\")\\n>>> c.strides\\n(4, 12)\\n```\\n\\n### ufunc 运算\\n定义说明[ufunc](http://old.sebug.net/paper/books/scipydoc/numpy_intro.html#) \\n>ufunc是universal function的缩写，它是一种能对数组的每个元素进行操作的函数。NumPy内置的许多ufunc函数都是在C语言级别实现的，因此它们的计算速度非常快\\n\\n\\n```\\n\\nimport time\\nimport math\\nimport numpy as np\\n\\nx = [i * 0.001 for i in range(1000000)]\\nstart = time.clock()\\nfor i, t in enumerate(x):\\n    x[i] = math.sin(t)\\n\\nprint (\\\"math.sin:\\\", time.clock() - start)\\n\\nx = [i * 0.001 for i in range(1000000)]\\nx = np.array(x)\\nstart = time.clock()\\nnp.sin(x,x)\\nprint (\\\"numpy.sin:\\\", time.clock() - start)\\n\\n```\\n\\nmath.sin: 0.35176099999999977\\nnumpy.sin: 0.01918600000000037\\n\\n注意`对数组计算 np快很多，但是对当个元素计算math则更快一些`\\n\\n另外 注意  正常功能函数 例如\\n`np.sin(params,params2)` `np.add(p1,p2,p3)`  最后一个参数表示`指定计算结果所要写入的数组`\\n```\\n>>> a = np.arange(0,4)\\n>>> a\\narray([0, 1, 2, 3])\\n>>> b = np.arange(1,5)\\n>>> b\\narray([1, 2, 3, 4])\\n>>> np.add(a,b)\\narray([1, 3, 5, 7])\\n>>> np.add(a,b,a)\\narray([1, 3, 5, 7])\\n>>> a\\narray([1, 3, 5, 7])\\n```\\n### broadcosting处理\\n当我们使用ufunc函数对两个数组进行计算时，ufunc函数会对这两个数组的对应元素进行计算，因此它要求这两个数组有相同的大小(shape相同)。如果两个数组的shape不同的话，会进行如下的广播(broadcasting)处理：\\n\\n1. 让所有输入数组都向其中shape最长的数组看齐，shape中不足的部分都通过在前面加1补齐\\n2. 输出数组的shape是输入数组shape的各个轴上的最大值\\n3. 如果输入数组的某个轴和输出数组的对应轴的长度相同或者其长度为1时，这个数组能够用来计算，否则出错\\n4. 当输入数组的某个轴的长度为1时，沿着此轴运算时都用此轴上的第一组值\\n\\n```\\n>>> \\n>>> a = np.arange(0, 60, 10).reshape(-1, 1)\\n>>> a\\narray([[ 0],\\n       [10],\\n       [20],\\n       [30],\\n       [40],\\n       [50]])\\n>>> a.shape\\n(6, 1)\\n>>> b = np.arange(0, 5)\\n>>> b\\narray([0, 1, 2, 3, 4])\\n>>> c=a+b  # a和b所有的元素相加\\n>>> c\\narray([[ 0,  1,  2,  3,  4],\\n       [10, 11, 12, 13, 14],\\n       [20, 21, 22, 23, 24],\\n       [30, 31, 32, 33, 34],\\n       [40, 41, 42, 43, 44],\\n       [50, 51, 52, 53, 54]])\\n>>>\\n\\n```\\n\\n\\n```\\n>>> a = a.repeat(5, axis=1)\\n>>> a\\narray([[ 0,  0,  0,  0,  0],\\n       [10, 10, 10, 10, 10],\\n       [20, 20, 20, 20, 20],\\n       [30, 30, 30, 30, 30],\\n       [40, 40, 40, 40, 40],\\n       [50, 50, 50, 50, 50]])\\n>>> \\n>>> b = np.arange(0, 5)\\n>>> b.shape=1,5\\n>>> b\\narray([[0, 1, 2, 3, 4]])\\n>>> b = b.repeat(6,axis=0)\\n>>> b\\narray([[0, 1, 2, 3, 4],\\n       [0, 1, 2, 3, 4],\\n       [0, 1, 2, 3, 4],\\n       [0, 1, 2, 3, 4],\\n       [0, 1, 2, 3, 4],\\n       [0, 1, 2, 3, 4]])\\n>>> a\\narray([[ 0,  0,  0,  0,  0],\\n       [10, 10, 10, 10, 10],\\n       [20, 20, 20, 20, 20],\\n       [30, 30, 30, 30, 30],\\n       [40, 40, 40, 40, 40],\\n       [50, 50, 50, 50, 50]])\\n>>> \\n\\n```\\n`np.ogrid`如下功能\\n- 开始值:结束值:步长，和np.arange(开始值, 结束值, 步长)类似\\n\\n- 开始值:结束值:长度j，当第三个参数为虚数时，它表示返回的数组的长度，和np.linspace(开始值, 结束值, 长度)类似：\\n```\\n>>> x, y = np.ogrid[0:12:3, 0:12:3j]\\n>>> x\\narray([[ 0.],\\n       [ 3.],\\n       [ 6.],\\n       [ 9.]])\\n>>> y\\narray([[  0.,   6.,  12.]])\\n>>> \\n````\\n\\n\"}]],\"sections\":[[10,0]]}","html":"<div class=\"kg-card-markdown\"><h2 id=\"\">说明</h2>\n<ul>\n<li>根据 <a href=\"http://old.sebug.net/paper/books/scipydoc/numpy_intro.html\">http://old.sebug.net/paper/books/scipydoc/numpy_intro.html</a> 学习而来，这里是自己敲写练习笔记，并写注释以及标明例子和实际情况的不同</li>\n<li>我使用的是python3控制台，table有提示 并且有些地方和python2不同</li>\n</ul>\n<h3 id=\"\">定义</h3>\n<p>NumPy提供了两种基本的对象：ndarray（N-dimensional array object）和 ufunc（universal function object）。ndarray(下文统一称之为数组)是存储单一数据类型的多维数组，而ufunc则是能够对数组进行处理的函数</p>\n<h3 id=\"np\">np数据类型</h3>\n<pre><code>Data type\tDescription\nbool_\tBoolean (True or False) stored as a byte\nint_\tDefault integer type (same as C long; normally either int64 or int32)\nintc\tIdentical to C int (normally int32 or int64)\nintp\tInteger used for indexing (same as C ssize_t; normally either int32 or int64)\nint8\tByte (-128 to 127)\nint16\tInteger (-32768 to 32767)\nint32\tInteger (-2147483648 to 2147483647)\nint64\tInteger (-9223372036854775808 to 9223372036854775807)\nuint8\tUnsigned integer (0 to 255)\nuint16\tUnsigned integer (0 to 65535)\nuint32\tUnsigned integer (0 to 4294967295)\nuint64\tUnsigned integer (0 to 18446744073709551615)\nfloat_\tShorthand for float64.\nfloat16\tHalf precision float: sign bit, 5 bits exponent, 10 bits mantissa\nfloat32\tSingle precision float: sign bit, 8 bits exponent, 23 bits mantissa\nfloat64\tDouble precision float: sign bit, 11 bits exponent, 52 bits mantissa\ncomplex_\tShorthand for complex128.\ncomplex64\tComplex number, represented by two 32-bit floats (real and imaginary components)\ncomplex128\tComplex number, represented by two 64-bit floats (real and imaginary components)\n\n</code></pre>\n<h3 id=\"\">初始化数组</h3>\n<pre><code class=\"language-python\">&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; a=np.array([1,2,3,4])\n&gt;&gt;&gt; b=np.array([5,6,7,8])\n&gt;&gt;&gt; c=np.array([[1,2,3,4],[4,5,6,7],[7,8,9,0]])\n&gt;&gt;&gt; b\narray([5, 6, 7, 8])\n&gt;&gt;&gt; c\narray([[1, 2, 3, 4],\n       [4, 5, 6, 7],\n       [7, 8, 9, 0]])\n&gt;&gt;&gt; c.s  #哈哈哈这就是python3的提升，不错\nc.searchsorted( c.setflags(     c.size          c.squeeze(      c.strides       c.swapaxes(    \nc.setfield(     c.shape         c.sort(         c.std(          c.sum(         \n&gt;&gt;&gt; c.shape ##显示是3行4类2维数组\n(3, 4)\n&gt;&gt;&gt; c.shape=2,-1  #修改成2行数组，-1自己计算列数\n&gt;&gt;&gt; c.shape\n(2, 6)\n&gt;&gt;&gt; \n&gt;&gt;&gt; c.shape=5,-1  #如果总元素的个数不能整除，会提示不能更改数组大小提示\nTraceback (most recent call last):\n  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;\nValueError: cannot reshape array of size 12 into shape (5,newaxis)\n&gt;&gt;&gt; \n\n\n\n&gt;&gt;&gt; d=a.reshape((2,2)) #reshape是重新创建一个新的数组赋值给d，a按保持不变\n&gt;&gt;&gt; d\narray([[1, 2],\n       [3, 4]])\n&gt;&gt;&gt; a\narray([1, 2, 3, 4])\n&gt;&gt;&gt; \n\n##但是他们之间的 &quot;内存是共享&quot;的，修改其中一个值，另外的也会随着改变\n&gt;&gt;&gt; a[1]=10\n&gt;&gt;&gt; d #修改a，b也变化了\narray([[ 1, 10],\n       [ 3,  4]])\n&gt;&gt;&gt; a \narray([ 1, 10,  3,  4])\n&gt;&gt;&gt; a.dtype  ##我是mac 64位系统,和教程是不一样的\ndtype('int64')\n\n\n&gt;&gt;&gt; np.array([[1,3],[3,4]],dtype=np.float)#指定float类型\narray([[ 1.,  3.],\n       [ 3.,  4.]])\n\n\n&gt;&gt;&gt; \n&gt;&gt;&gt; \n&gt;&gt;&gt; np.arange(0,1,1)#定义[0,1)数组，步长是1\narray([0])\n&gt;&gt;&gt; np.arange(0,1,0.1)#定义[0,1)数组，步长是0.1\narray([ 0. ,  0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9])\n&gt;&gt;&gt; np.arange(0,10,1)\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n&gt;&gt;&gt; \n&gt;&gt;&gt; \n&gt;&gt;&gt; np.linspace(0,10,10)  ## 定义个0到10之间数组，一共10个元素\narray([  0.        ,   1.11111111,   2.22222222,   3.33333333,\n         4.44444444,   5.55555556,   6.66666667,   7.77777778,\n         8.88888889,  10.        ])\n&gt;&gt;&gt; np.linspace(0,10,9)\narray([  0.  ,   1.25,   2.5 ,   3.75,   5.  ,   6.25,   7.5 ,   8.75,  10.  ])\n&gt;&gt;&gt; np.linspace(0,10,11)\narray([  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.])\n&gt;&gt;&gt; \n\n\n&gt;&gt;&gt;  \n&gt;&gt;&gt; np.logspace(0,2,20)  #0到2，通过等比创建20个元素\narray([   1.        ,    1.27427499,    1.62377674,    2.06913808,\n          2.6366509 ,    3.35981829,    4.2813324 ,    5.45559478,\n          6.95192796,    8.8586679 ,   11.28837892,   14.38449888,\n         18.32980711,   23.35721469,   29.76351442,   37.92690191,\n         48.32930239,   61.58482111,   78.47599704,  100.        ])\n&gt;&gt;&gt; np.logspace(0,10,2) #0到2，通过等比创建2个元素\narray([  1.00000000e+00,   1.00000000e+10])\n&gt;&gt;&gt; \n\n&gt;&gt;&gt; \n&gt;&gt;&gt; s='1111'\n&gt;&gt;&gt; np.fromstring(s, dtype=np.int8)  #把string变成int8\narray([49, 49, 49, 49], dtype=int8)\n&gt;&gt;&gt; \n&gt;&gt;&gt; \n\n\n\n&gt;&gt;&gt; def func(i):\n...     return i%4+1\n... \n&gt;&gt;&gt; np.fromfunction(func,(10,)) #注意这里是（10，）会认为是数组，(10)会err\narray([ 1.,  2.,  3.,  4.,  1.,  2.,  3.,  4.,  1.,  2.])\n&gt;&gt;&gt; \n&gt;&gt;&gt; def func(i):\n...     return i, i%4+1\n... \n&gt;&gt;&gt; np.fromfunction(func,(10,))\n(array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.]), array([ 1.,  2.,  3.,  4.,  1.,  2.,  3.,  4.,  1.,  2.]))\n&gt;&gt;&gt; \n&gt;&gt;&gt; \n&gt;&gt;&gt;\n&gt;&gt;&gt; a = np.arange(10)\n&gt;&gt;&gt; a\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n&gt;&gt;&gt; a[3:5]\narray([3, 4])\n&gt;&gt;&gt; a[3:5]\narray([3, 4])\n&gt;&gt;&gt; a[3:5]#第[3,5)元素，包括第3个元素，不包括5\narray([3, 4])\n&gt;&gt;&gt; a\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n&gt;&gt;&gt; a\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n&gt;&gt;&gt; a[3:5]\narray([3, 4])\n&gt;&gt;&gt; a[2:4] = 100,101  #修改a[2]=100,a[3]=101\n&gt;&gt;&gt; a\narray([  0,   1, 100, 101,   4,   5,   6,   7,   8,   9])\n\na[:-1]#表示到倒数第1个元素，但是不包括   和redis有一点点差别\narray([  0,   1, 100, 101,   4,   5,   6,   7,   8])\n\n\n\n&gt;&gt;&gt; a[::2]  #  %2==0取出来\narray([  0, 100,   4,   6,   8])\n&gt;&gt;&gt; a[1:-1:2] # 限制了一个范围\narray([  1, 101,   5,   7])\n&gt;&gt;&gt; a[1:-1]\narray([  1, 100, 101,   4,   5,   6,   7,   8])\n&gt;&gt;&gt; \n\n\n&gt;&gt;&gt; \n&gt;&gt;&gt; \n&gt;&gt;&gt; x = np.arange(10,1,-1)\n&gt;&gt;&gt; x\narray([10,  9,  8,  7,  6,  5,  4,  3,  2])\n&gt;&gt;&gt; x[[3, 3, 1, 8]]  #靠，还可使用数组小标取\narray([7, 7, 9, 2])\n&gt;&gt;&gt; \n\n\n\n&gt;&gt;&gt; x = np.arange(10,1,-1)\n&gt;&gt;&gt; x\narray([10,  9,  8,  7,  6,  5,  4,  3,  2])\n&gt;&gt;&gt; x[[3, 3, 1, 8]]\narray([7, 7, 9, 2])\n&gt;&gt;&gt; b = x[np.array([3,3,-3,8])]   #索引还能为负\n&gt;&gt;&gt; b\narray([7, 7, 4, 2])\n&gt;&gt;&gt; x\narray([10,  9,  8,  7,  6,  5,  4,  3,  2])\n&gt;&gt;&gt; x[-1]  倒数第一个元素\n2\n&gt;&gt;&gt;  \n&gt;&gt;&gt; \n&gt;&gt;&gt; x[[3,5,1]] = -1, -2, -3 # 整数序列下标也可以用来修改元素的值\n&gt;&gt;&gt; x\narray([10, -3,  8, -1,  6, -2,  4,  3,  2])\n&gt;&gt;&gt; \n\n\n\n&gt;&gt;&gt; x=np.random.rand(10)\n&gt;&gt;&gt; x\narray([ 0.64988185,  0.82156594,  0.50822433,  0.70013378,  0.78289356,\n        0.17419819,  0.11904243,  0.89411913,  0.21694376,  0.19730514])\n&gt;&gt;&gt; \n&gt;&gt;&gt; x&gt;0.5  # 是每一个比较  666666\narray([ True,  True,  True,  True,  True, False, False,  True, False, False], dtype=bool)\n&gt;&gt;&gt;  x[x&gt;0.5] # 只有元素大于0.5的才返回  666\narray([ 0.64988185,  0.82156594,  0.50822433,  0.70013378,  0.78289356,\n        0.89411913])\n&gt;&gt;&gt; \n</code></pre>\n<h3 id=\"\">多维数组</h3>\n<pre><code>&gt;&gt;&gt; np.arange(0,60,10)\narray([ 0, 10, 20, 30, 40, 50])\n&gt;&gt;&gt; np.arange(0,60,10).reshape(-1,1)\narray([[ 0],\n       [10],\n       [20],\n       [30],\n       [40],\n       [50]])\n&gt;&gt;&gt; np.arange(0,6)\narray([0, 1, 2, 3, 4, 5])\n&gt;&gt;&gt; np.arange(0,60,10).reshape(-1,1)+np.arange(0,6)#不同维度数组相加\narray([[ 0,  1,  2,  3,  4,  5],\n       [10, 11, 12, 13, 14, 15],\n       [20, 21, 22, 23, 24, 25],\n       [30, 31, 32, 33, 34, 35],\n       [40, 41, 42, 43, 44, 45],\n       [50, 51, 52, 53, 54, 55]])\n\n&gt;&gt;&gt;\n</code></pre>\n<h3 id=\"\">自定义结构类型</h3>\n<pre><code>&gt;&gt;&gt; persontype = np.dtype({\n    'names':['name', 'age', 'weight'],\n    'formats':['S32','i', 'f']})\n&gt;&gt;&gt; a = np.array([(&quot;Zhang&quot;,32,75.5),(&quot;Wang&quot;,24,65.2)],\n    dtype=persontype)\n&gt;&gt;&gt; a\narray([(b'Zhang', 32,  75.5       ), (b'Wang', 24,  65.19999695)],\n      dtype=[('name', 'S32'), ('age', '&lt;i4'), ('weight', '&lt;f4')])\n&gt;&gt;&gt; a[0]['name']\nb'Zhang'\n&gt;&gt;&gt; a[0]['age']\n32\n\n</code></pre>\n<p>formats定义：</p>\n<ul>\n<li>S32 : 32个字节的字符串类型，由于结构中的每个元素的大小必须固定，因此需要指定字符串的长度</li>\n<li>i : 32bit的整数类型，相当于np.int32</li>\n<li>f : 32bit的单精度浮点数类型，相当于np.float32</li>\n</ul>\n<p>类型描述：</p>\n<ul>\n<li>| : 忽视字节顺序</li>\n<li>&lt; : 低位字节在前</li>\n<li>&gt; : 高位字节在前</li>\n</ul>\n<pre><code>&gt;&gt;&gt; b=a[:][&quot;age&quot;]#获取所有数组的'age'\n&gt;&gt;&gt; b\narray([32, 24], dtype=int32)\n&gt;&gt;&gt; a[0]\n(b'Zhang', 32,  75.5)\n&gt;&gt;&gt; b[0]=1 #修改器年级  因为内存共享所以会相互影响\n&gt;&gt;&gt; a[0]\n(b'Zhang', 1,  75.5)\n</code></pre>\n<h3 id=\"\">内存结构</h3>\n<p><img src=\"http://old.sebug.net/paper/books/scipydoc/_images/numpy_memory_struct.png\" alt=\"\"></p>\n<pre><code>&gt;&gt;&gt; c = np.array([[0,1,2],[3,4,5],[6,7,8]], dtype=np.float32, order=&quot;F&quot;)\n&gt;&gt;&gt; c.strides\n(4, 12)  # 4表示一维增加1时候，需要4字节，12表第二维增加一需要增加12字节\n</code></pre>\n<p>元素在数据存储区中的排列格式有两种：C语言格式和Fortan语言格式。在C语言中，多维数组的第0轴是最上位的，即第0轴的下标增加1时，元素的地址增加的字节数最多；而Fortan语言的多维数组的第0轴是最下位的，即第0轴的下标增加1时，地址只增加一个元素的字节数。在NumPy中，元素在内存中的排列缺省是以C语言格式存储的，如果你希望改为Fortan格式的话，只需要给数组传递order=&quot;F&quot;参数：</p>\n<pre><code>&gt;&gt;&gt; c = np.array([[0,1,2],[3,4,5],[6,7,8]], dtype=np.float32, order=&quot;F&quot;)\n&gt;&gt;&gt; c.strides\n(4, 12)\n</code></pre>\n<h3 id=\"ufunc\">ufunc 运算</h3>\n<p>定义说明<a href=\"http://old.sebug.net/paper/books/scipydoc/numpy_intro.html#\">ufunc</a></p>\n<blockquote>\n<p>ufunc是universal function的缩写，它是一种能对数组的每个元素进行操作的函数。NumPy内置的许多ufunc函数都是在C语言级别实现的，因此它们的计算速度非常快</p>\n</blockquote>\n<pre><code>\nimport time\nimport math\nimport numpy as np\n\nx = [i * 0.001 for i in range(1000000)]\nstart = time.clock()\nfor i, t in enumerate(x):\n    x[i] = math.sin(t)\n\nprint (&quot;math.sin:&quot;, time.clock() - start)\n\nx = [i * 0.001 for i in range(1000000)]\nx = np.array(x)\nstart = time.clock()\nnp.sin(x,x)\nprint (&quot;numpy.sin:&quot;, time.clock() - start)\n\n</code></pre>\n<p>math.sin: 0.35176099999999977<br>\nnumpy.sin: 0.01918600000000037</p>\n<p>注意<code>对数组计算 np快很多，但是对当个元素计算math则更快一些</code></p>\n<p>另外 注意  正常功能函数 例如<br>\n<code>np.sin(params,params2)</code> <code>np.add(p1,p2,p3)</code>  最后一个参数表示<code>指定计算结果所要写入的数组</code></p>\n<pre><code>&gt;&gt;&gt; a = np.arange(0,4)\n&gt;&gt;&gt; a\narray([0, 1, 2, 3])\n&gt;&gt;&gt; b = np.arange(1,5)\n&gt;&gt;&gt; b\narray([1, 2, 3, 4])\n&gt;&gt;&gt; np.add(a,b)\narray([1, 3, 5, 7])\n&gt;&gt;&gt; np.add(a,b,a)\narray([1, 3, 5, 7])\n&gt;&gt;&gt; a\narray([1, 3, 5, 7])\n</code></pre>\n<h3 id=\"broadcosting\">broadcosting处理</h3>\n<p>当我们使用ufunc函数对两个数组进行计算时，ufunc函数会对这两个数组的对应元素进行计算，因此它要求这两个数组有相同的大小(shape相同)。如果两个数组的shape不同的话，会进行如下的广播(broadcasting)处理：</p>\n<ol>\n<li>让所有输入数组都向其中shape最长的数组看齐，shape中不足的部分都通过在前面加1补齐</li>\n<li>输出数组的shape是输入数组shape的各个轴上的最大值</li>\n<li>如果输入数组的某个轴和输出数组的对应轴的长度相同或者其长度为1时，这个数组能够用来计算，否则出错</li>\n<li>当输入数组的某个轴的长度为1时，沿着此轴运算时都用此轴上的第一组值</li>\n</ol>\n<pre><code>&gt;&gt;&gt; \n&gt;&gt;&gt; a = np.arange(0, 60, 10).reshape(-1, 1)\n&gt;&gt;&gt; a\narray([[ 0],\n       [10],\n       [20],\n       [30],\n       [40],\n       [50]])\n&gt;&gt;&gt; a.shape\n(6, 1)\n&gt;&gt;&gt; b = np.arange(0, 5)\n&gt;&gt;&gt; b\narray([0, 1, 2, 3, 4])\n&gt;&gt;&gt; c=a+b  # a和b所有的元素相加\n&gt;&gt;&gt; c\narray([[ 0,  1,  2,  3,  4],\n       [10, 11, 12, 13, 14],\n       [20, 21, 22, 23, 24],\n       [30, 31, 32, 33, 34],\n       [40, 41, 42, 43, 44],\n       [50, 51, 52, 53, 54]])\n&gt;&gt;&gt;\n\n</code></pre>\n<pre><code>&gt;&gt;&gt; a = a.repeat(5, axis=1)\n&gt;&gt;&gt; a\narray([[ 0,  0,  0,  0,  0],\n       [10, 10, 10, 10, 10],\n       [20, 20, 20, 20, 20],\n       [30, 30, 30, 30, 30],\n       [40, 40, 40, 40, 40],\n       [50, 50, 50, 50, 50]])\n&gt;&gt;&gt; \n&gt;&gt;&gt; b = np.arange(0, 5)\n&gt;&gt;&gt; b.shape=1,5\n&gt;&gt;&gt; b\narray([[0, 1, 2, 3, 4]])\n&gt;&gt;&gt; b = b.repeat(6,axis=0)\n&gt;&gt;&gt; b\narray([[0, 1, 2, 3, 4],\n       [0, 1, 2, 3, 4],\n       [0, 1, 2, 3, 4],\n       [0, 1, 2, 3, 4],\n       [0, 1, 2, 3, 4],\n       [0, 1, 2, 3, 4]])\n&gt;&gt;&gt; a\narray([[ 0,  0,  0,  0,  0],\n       [10, 10, 10, 10, 10],\n       [20, 20, 20, 20, 20],\n       [30, 30, 30, 30, 30],\n       [40, 40, 40, 40, 40],\n       [50, 50, 50, 50, 50]])\n&gt;&gt;&gt; \n\n</code></pre>\n<p><code>np.ogrid</code>如下功能</p>\n<ul>\n<li>\n<p>开始值:结束值:步长，和np.arange(开始值, 结束值, 步长)类似</p>\n</li>\n<li>\n<p>开始值:结束值:长度j，当第三个参数为虚数时，它表示返回的数组的长度，和np.linspace(开始值, 结束值, 长度)类似：</p>\n</li>\n</ul>\n<pre><code>&gt;&gt;&gt; x, y = np.ogrid[0:12:3, 0:12:3j]\n&gt;&gt;&gt; x\narray([[ 0.],\n       [ 3.],\n       [ 6.],\n       [ 9.]])\n&gt;&gt;&gt; y\narray([[  0.,   6.,  12.]])\n&gt;&gt;&gt; \n</code></pre>\n</div>","amp":null,"plaintext":"说明\n * 根据 http://old.sebug.net/paper/books/scipydoc/numpy_intro.html  学习而来，这里做笔记，写注释\n * 我使用的是python3控制台，因为也可table提示 哈哈\n\n定义\nNumPy提供了两种基本的对象：ndarray（N-dimensional array object）和 ufunc（universal function\nobject）。ndarray(下文统一称之为数组)是存储单一数据类型的多维数组，而ufunc则是能够对数组进行处理的函数\n\nnp数据类型\nData type\tDescription\nbool_\tBoolean (True or False) stored as a byte\nint_\tDefault integer type (same as C long; normally either int64 or int32)\nintc\tIdentical to C int (normally int32 or int64)\nintp\tInteger used for indexing (same as C ssize_t; normally either int32 or int64)\nint8\tByte (-128 to 127)\nint16\tInteger (-32768 to 32767)\nint32\tInteger (-2147483648 to 2147483647)\nint64\tInteger (-9223372036854775808 to 9223372036854775807)\nuint8\tUnsigned integer (0 to 255)\nuint16\tUnsigned integer (0 to 65535)\nuint32\tUnsigned integer (0 to 4294967295)\nuint64\tUnsigned integer (0 to 18446744073709551615)\nfloat_\tShorthand for float64.\nfloat16\tHalf precision float: sign bit, 5 bits exponent, 10 bits mantissa\nfloat32\tSingle precision float: sign bit, 8 bits exponent, 23 bits mantissa\nfloat64\tDouble precision float: sign bit, 11 bits exponent, 52 bits mantissa\ncomplex_\tShorthand for complex128.\ncomplex64\tComplex number, represented by two 32-bit floats (real and imaginary components)\ncomplex128\tComplex number, represented by two 64-bit floats (real and imaginary components)\n\n\n\n初始化数组\n>>> import numpy as np\n>>> a=np.array([1,2,3,4])\n>>> b=np.array([5,6,7,8])\n>>> c=np.array([[1,2,3,4],[4,5,6,7],[7,8,9,0]])\n>>> b\narray([5, 6, 7, 8])\n>>> c\narray([[1, 2, 3, 4],\n       [4, 5, 6, 7],\n       [7, 8, 9, 0]])\n>>> c.s  #哈哈哈这就是python3的提升，不错\nc.searchsorted( c.setflags(     c.size          c.squeeze(      c.strides       c.swapaxes(    \nc.setfield(     c.shape         c.sort(         c.std(          c.sum(         \n>>> c.shape ##显示是3行4类2维数组\n(3, 4)\n>>> c.shape=2,-1  #修改成2行数组，-1自己计算列数\n>>> c.shape\n(2, 6)\n>>> \n>>> c.shape=5,-1  #如果总元素的个数不能整除，会提示不能更改数组大小提示\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nValueError: cannot reshape array of size 12 into shape (5,newaxis)\n>>> \n\n\n\n>>> d=a.reshape((2,2)) #reshape是重新创建一个新的数组赋值给d，a按保持不变\n>>> d\narray([[1, 2],\n       [3, 4]])\n>>> a\narray([1, 2, 3, 4])\n>>> \n\n##但是他们之间的 \"内存是共享\"的，修改其中一个值，另外的也会随着改变\n>>> a[1]=10\n>>> d #修改a，b也变化了\narray([[ 1, 10],\n       [ 3,  4]])\n>>> a \narray([ 1, 10,  3,  4])\n>>> a.dtype  ##我是mac 64位系统,和教程是不一样的\ndtype('int64')\n\n\n>>> np.array([[1,3],[3,4]],dtype=np.float)#指定float类型\narray([[ 1.,  3.],\n       [ 3.,  4.]])\n\n\n>>> \n>>> \n>>> np.arange(0,1,1)#定义[0,1)数组，步长是1\narray([0])\n>>> np.arange(0,1,0.1)#定义[0,1)数组，步长是0.1\narray([ 0. ,  0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9])\n>>> np.arange(0,10,1)\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n>>> \n>>> \n>>> np.linspace(0,10,10)  ## 定义个0到10之间数组，一共10个元素\narray([  0.        ,   1.11111111,   2.22222222,   3.33333333,\n         4.44444444,   5.55555556,   6.66666667,   7.77777778,\n         8.88888889,  10.        ])\n>>> np.linspace(0,10,9)\narray([  0.  ,   1.25,   2.5 ,   3.75,   5.  ,   6.25,   7.5 ,   8.75,  10.  ])\n>>> np.linspace(0,10,11)\narray([  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.])\n>>> \n\n\n>>>  \n>>> np.logspace(0,2,20)  #0到2，通过等比创建20个元素\narray([   1.        ,    1.27427499,    1.62377674,    2.06913808,\n          2.6366509 ,    3.35981829,    4.2813324 ,    5.45559478,\n          6.95192796,    8.8586679 ,   11.28837892,   14.38449888,\n         18.32980711,   23.35721469,   29.76351442,   37.92690191,\n         48.32930239,   61.58482111,   78.47599704,  100.        ])\n>>> np.logspace(0,10,2) #0到2，通过等比创建2个元素\narray([  1.00000000e+00,   1.00000000e+10])\n>>> \n\n>>> \n>>> s='1111'\n>>> np.fromstring(s, dtype=np.int8)  #把string变成int8\narray([49, 49, 49, 49], dtype=int8)\n>>> \n>>> \n\n\n\n>>> def func(i):\n...     return i%4+1\n... \n>>> np.fromfunction(func,(10,)) #注意这里是（10，）会认为是数组，(10)会err\narray([ 1.,  2.,  3.,  4.,  1.,  2.,  3.,  4.,  1.,  2.])\n>>> \n>>> def func(i):\n...     return i, i%4+1\n... \n>>> np.fromfunction(func,(10,))\n(array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.]), array([ 1.,  2.,  3.,  4.,  1.,  2.,  3.,  4.,  1.,  2.]))\n>>> \n>>> \n>>>\n>>> a = np.arange(10)\n>>> a\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n>>> a[3:5]\narray([3, 4])\n>>> a[3:5]\narray([3, 4])\n>>> a[3:5]#第[3,5)元素，包括第3个元素，不包括5\narray([3, 4])\n>>> a\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n>>> a\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n>>> a[3:5]\narray([3, 4])\n>>> a[2:4] = 100,101  #修改a[2]=100,a[3]=101\n>>> a\narray([  0,   1, 100, 101,   4,   5,   6,   7,   8,   9])\n\na[:-1]#表示到倒数第1个元素，但是不包括   和redis有一点点差别\narray([  0,   1, 100, 101,   4,   5,   6,   7,   8])\n\n\n\n>>> a[::2]  #  %2==0取出来\narray([  0, 100,   4,   6,   8])\n>>> a[1:-1:2] # 限制了一个范围\narray([  1, 101,   5,   7])\n>>> a[1:-1]\narray([  1, 100, 101,   4,   5,   6,   7,   8])\n>>> \n\n\n>>> \n>>> \n>>> x = np.arange(10,1,-1)\n>>> x\narray([10,  9,  8,  7,  6,  5,  4,  3,  2])\n>>> x[[3, 3, 1, 8]]  #靠，还可使用数组小标取\narray([7, 7, 9, 2])\n>>> \n\n\n\n>>> x = np.arange(10,1,-1)\n>>> x\narray([10,  9,  8,  7,  6,  5,  4,  3,  2])\n>>> x[[3, 3, 1, 8]]\narray([7, 7, 9, 2])\n>>> b = x[np.array([3,3,-3,8])]   #索引还能为负\n>>> b\narray([7, 7, 4, 2])\n>>> x\narray([10,  9,  8,  7,  6,  5,  4,  3,  2])\n>>> x[-1]  倒数第一个元素\n2\n>>>  \n>>> \n>>> x[[3,5,1]] = -1, -2, -3 # 整数序列下标也可以用来修改元素的值\n>>> x\narray([10, -3,  8, -1,  6, -2,  4,  3,  2])\n>>> \n\n\n\n>>> x=np.random.rand(10)\n>>> x\narray([ 0.64988185,  0.82156594,  0.50822433,  0.70013378,  0.78289356,\n        0.17419819,  0.11904243,  0.89411913,  0.21694376,  0.19730514])\n>>> \n>>> x>0.5  # 是每一个比较  666666\narray([ True,  True,  True,  True,  True, False, False,  True, False, False], dtype=bool)\n>>>  x[x>0.5] # 只有元素大于0.5的才返回  666\narray([ 0.64988185,  0.82156594,  0.50822433,  0.70013378,  0.78289356,\n        0.89411913])\n>>> \n\n\n多维数组\n>>> np.arange(0,60,10)\narray([ 0, 10, 20, 30, 40, 50])\n>>> np.arange(0,60,10).reshape(-1,1)\narray([[ 0],\n       [10],\n       [20],\n       [30],\n       [40],\n       [50]])\n>>> np.arange(0,6)\narray([0, 1, 2, 3, 4, 5])\n>>> np.arange(0,60,10).reshape(-1,1)+np.arange(0,6)#不同维度数组相加\narray([[ 0,  1,  2,  3,  4,  5],\n       [10, 11, 12, 13, 14, 15],\n       [20, 21, 22, 23, 24, 25],\n       [30, 31, 32, 33, 34, 35],\n       [40, 41, 42, 43, 44, 45],\n       [50, 51, 52, 53, 54, 55]])\n\n>>>\n\n\n自定义结构类型\n>>> persontype = np.dtype({\n    'names':['name', 'age', 'weight'],\n    'formats':['S32','i', 'f']})\n>>> a = np.array([(\"Zhang\",32,75.5),(\"Wang\",24,65.2)],\n    dtype=persontype)\n>>> a\narray([(b'Zhang', 32,  75.5       ), (b'Wang', 24,  65.19999695)],\n      dtype=[('name', 'S32'), ('age', '<i4'), ('weight', '<f4')])\n>>> a[0]['name']\nb'Zhang'\n>>> a[0]['age']\n32\n\n\n\nformats定义：\n\n * S32 : 32个字节的字符串类型，由于结构中的每个元素的大小必须固定，因此需要指定字符串的长度\n * i : 32bit的整数类型，相当于np.int32\n * f : 32bit的单精度浮点数类型，相当于np.float32\n\n类型描述：\n\n * | : 忽视字节顺序\n * < : 低位字节在前\n * > : 高位字节在前\n\n>>> b=a[:][\"age\"]#获取所有数组的'age'\n>>> b\narray([32, 24], dtype=int32)\n>>> a[0]\n(b'Zhang', 32,  75.5)\n>>> b[0]=1 #修改器年级  因为内存共享所以会相互影响\n>>> a[0]\n(b'Zhang', 1,  75.5)\n\n\n内存结构\n\n\n>>> c = np.array([[0,1,2],[3,4,5],[6,7,8]], dtype=np.float32, order=\"F\")\n>>> c.strides\n(4, 12)  # 4表示一维增加1时候，需要4字节，12表第二维增加一需要增加12字节\n\n\n元素在数据存储区中的排列格式有两种：C语言格式和Fortan语言格式。在C语言中，多维数组的第0轴是最上位的，即第0轴的下标增加1时，元素的地址增加的字节数最多；而Fortan语言的多维数组的第0轴是最下位的，即第0轴的下标增加1时，地址只增加一个元素的字节数。在NumPy中，元素在内存中的排列缺省是以C语言格式存储的，如果你希望改为Fortan格式的话，只需要给数组传递order=\"F\"参数：\n\n>>> c = np.array([[0,1,2],[3,4,5],[6,7,8]], dtype=np.float32, order=\"F\")\n>>> c.strides\n(4, 12)\n\n\nufunc 运算\n定义说明ufunc\n\nufunc是universal\nfunction的缩写，它是一种能对数组的每个元素进行操作的函数。NumPy内置的许多ufunc函数都是在C语言级别实现的，因此它们的计算速度非常快\n\n\nimport time\nimport math\nimport numpy as np\n\nx = [i * 0.001 for i in range(1000000)]\nstart = time.clock()\nfor i, t in enumerate(x):\n    x[i] = math.sin(t)\n\nprint (\"math.sin:\", time.clock() - start)\n\nx = [i * 0.001 for i in range(1000000)]\nx = np.array(x)\nstart = time.clock()\nnp.sin(x,x)\nprint (\"numpy.sin:\", time.clock() - start)\n\n\n\nmath.sin: 0.35176099999999977\nnumpy.sin: 0.01918600000000037\n\n注意对数组计算 np快很多，但是对当个元素计算math则更快一些\n\n另外 注意 正常功能函数 例如\nnp.sin(params,params2)  np.add(p1,p2,p3)  最后一个参数表示指定计算结果所要写入的数组\n\n>>> a = np.arange(0,4)\n>>> a\narray([0, 1, 2, 3])\n>>> b = np.arange(1,5)\n>>> b\narray([1, 2, 3, 4])\n>>> np.add(a,b)\narray([1, 3, 5, 7])\n>>> np.add(a,b,a)\narray([1, 3, 5, 7])\n>>> a\narray([1, 3, 5, 7])\n\n\nbroadcosting处理\n当我们使用ufunc函数对两个数组进行计算时，ufunc函数会对这两个数组的对应元素进行计算，因此它要求这两个数组有相同的大小(shape相同)。如果两个数组的shape不同的话，会进行如下的广播(broadcasting)处理：\n\n 1. 让所有输入数组都向其中shape最长的数组看齐，shape中不足的部分都通过在前面加1补齐\n 2. 输出数组的shape是输入数组shape的各个轴上的最大值\n 3. 如果输入数组的某个轴和输出数组的对应轴的长度相同或者其长度为1时，这个数组能够用来计算，否则出错\n 4. 当输入数组的某个轴的长度为1时，沿着此轴运算时都用此轴上的第一组值\n\n>>> \n>>> a = np.arange(0, 60, 10).reshape(-1, 1)\n>>> a\narray([[ 0],\n       [10],\n       [20],\n       [30],\n       [40],\n       [50]])\n>>> a.shape\n(6, 1)\n>>> b = np.arange(0, 5)\n>>> b\narray([0, 1, 2, 3, 4])\n>>> c=a+b  # a和b所有的元素相加\n>>> c\narray([[ 0,  1,  2,  3,  4],\n       [10, 11, 12, 13, 14],\n       [20, 21, 22, 23, 24],\n       [30, 31, 32, 33, 34],\n       [40, 41, 42, 43, 44],\n       [50, 51, 52, 53, 54]])\n>>>\n\n\n\n>>> a = a.repeat(5, axis=1)\n>>> a\narray([[ 0,  0,  0,  0,  0],\n       [10, 10, 10, 10, 10],\n       [20, 20, 20, 20, 20],\n       [30, 30, 30, 30, 30],\n       [40, 40, 40, 40, 40],\n       [50, 50, 50, 50, 50]])\n>>> \n>>> b = np.arange(0, 5)\n>>> b.shape=1,5\n>>> b\narray([[0, 1, 2, 3, 4]])\n>>> b = b.repeat(6,axis=0)\n>>> b\narray([[0, 1, 2, 3, 4],\n       [0, 1, 2, 3, 4],\n       [0, 1, 2, 3, 4],\n       [0, 1, 2, 3, 4],\n       [0, 1, 2, 3, 4],\n       [0, 1, 2, 3, 4]])\n>>> a\narray([[ 0,  0,  0,  0,  0],\n       [10, 10, 10, 10, 10],\n       [20, 20, 20, 20, 20],\n       [30, 30, 30, 30, 30],\n       [40, 40, 40, 40, 40],\n       [50, 50, 50, 50, 50]])\n>>>","feature_image":null,"featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2017-08-16 02:47:18","created_by":"1","updated_at":"2017-08-16 08:01:46","updated_by":"1","published_at":"2017-08-16 07:57:53","published_by":"1","custom_excerpt":null,"codeinjection_head":"","codeinjection_foot":"","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null},{"id":"599407bbf36c876ae083d89c","uuid":"93740957-50c8-42e4-a2cd-e60b0b3d9a2f","title":"tensorflow笔记","slug":"tensorflowbi-ji","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"####  sess = tf.Session()运行出现下面warn\\n\\n `>>> sess = tf.Session()\\n2017-08-16 16:48:59.727286: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\\n2017-08-16 16:48:59.727333: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\\n2017-08-16 16:48:59.727344: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\\n2017-08-16 16:48:59.727352: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.`\\n\\n设置`os.environ['TF_CPP_MIN_LOG_LEVEL']='2'` 即可 \\n个人感觉这这是表面解决了，本质没有变，只是把log级别调整了一下而已\\n###  [tf.reduce_mean ](https://www.tensorflow.org/api_docs/python/tf/reduce_mean)\\n\\n     \\n` Computes the mean of elements across dimensions of a tensor` 也就是计算张量平均值。\\n```\\ntf.reduce_mean \\nreduce_mean(\\n    input_tensor,# \\n    axis=None,\\n    keep_dims=False,\\n    name=None,\\n    reduction_indices=None\\n)\\n```\\n\\n### [tf.random_uniform([1], -1.0, 1.0)](https://www.tensorflow.org/api_docs/python/tf/random_uniform)\\n\\n表示随机取\\\"shape=[1]\\\"一维数组，取值范围[-1,0)\\n\\n\"}]],\"sections\":[[10,0]]}","html":"<div class=\"kg-card-markdown\"><h4 id=\"sesstfsessionwarn\">sess = tf.Session()运行出现下面warn</h4>\n<p><code>&gt;&gt;&gt; sess = tf.Session() 2017-08-16 16:48:59.727286: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations. 2017-08-16 16:48:59.727333: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations. 2017-08-16 16:48:59.727344: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations. 2017-08-16 16:48:59.727352: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.</code></p>\n<p>设置<code>os.environ['TF_CPP_MIN_LOG_LEVEL']='2'</code> 即可<br>\n个人感觉这这是表面解决了，本质没有变，只是把log级别调整了一下而已</p>\n<h3 id=\"tfreduce_mean\"><a href=\"https://www.tensorflow.org/api_docs/python/tf/reduce_mean\">tf.reduce_mean </a></h3>\n<p><code>Computes the mean of elements across dimensions of a tensor</code> 也就是计算张量平均值。</p>\n<pre><code>tf.reduce_mean \nreduce_mean(\n    input_tensor,# \n    axis=None,\n    keep_dims=False,\n    name=None,\n    reduction_indices=None\n)\n</code></pre>\n<h3 id=\"tfrandom_uniform11010\"><a href=\"https://www.tensorflow.org/api_docs/python/tf/random_uniform\">tf.random_uniform([1], -1.0, 1.0)</a></h3>\n<p>表示随机取&quot;shape=[1]&quot;一维数组，取值范围[-1,0)</p>\n</div>","amp":null,"plaintext":"sess = tf.Session()运行出现下面warn\n>>> sess = tf.Session() 2017-08-16 16:48:59.727286: W\ntensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't\ncompiled to use SSE4.2 instructions, but these are available on your machine and\ncould speed up CPU computations. 2017-08-16 16:48:59.727333: W\ntensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't\ncompiled to use AVX instructions, but these are available on your machine and\ncould speed up CPU computations. 2017-08-16 16:48:59.727344: W\ntensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't\ncompiled to use AVX2 instructions, but these are available on your machine and\ncould speed up CPU computations. 2017-08-16 16:48:59.727352: W\ntensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't\ncompiled to use FMA instructions, but these are available on your machine and\ncould speed up CPU computations.\n\n设置os.environ['TF_CPP_MIN_LOG_LEVEL']='2'  即可\n个人感觉这这是表面解决了，本质没有变，只是把log级别调整了一下而已\n\ntf.reduce_mean [https://www.tensorflow.org/api_docs/python/tf/reduce_mean]\nComputes the mean of elements across dimensions of a tensor  也就是计算张量平均值。\n\ntf.reduce_mean \nreduce_mean(\n    input_tensor,# \n    axis=None,\n    keep_dims=False,\n    name=None,\n    reduction_indices=None\n)\n\n\ntf.random_uniform([1], -1.0, 1.0)\n[https://www.tensorflow.org/api_docs/python/tf/random_uniform]\n表示随机取\"shape=[1]\"一维数组，取值范围[-1,0)","feature_image":null,"featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2017-08-16 08:52:11","created_by":"1","updated_at":"2017-09-04 05:53:54","updated_by":"1","published_at":"2017-09-04 05:53:54","published_by":"1","custom_excerpt":null,"codeinjection_head":"","codeinjection_foot":"","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null},{"id":"59953c71f36c876ae083d8a0","uuid":"8c9f680f-e179-40e8-97a6-bd421bbea217","title":"机器深度学习 图片相关","slug":"tu-pian-chu-li","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"\\n|项目|简介|\\n|-|-|\\n|[DCGAN-tensorflow](https://github.com/carpedm20/DCGAN-tensorflow) |脸部|\\n|[deep-photo-styletransfer-tf](https://github.com/LouieYang/deep-photo-styletransfer-tf)|不同的图片风格合成|\\n|[domain-transfer-network](https://github.com/yunjey/domain-transfer-network)| |\\n|[neural-style](https://github.com/anishathalye/neural-style)| 梵高画风|\\n|[image-analogies](https://github.com/awentzonline/image-analogies)| 改变画风|\\n|[Face-Aging-CAAE](https://github.com/ZZUTK/Face-Aging-CAAE) |人脸年纪变化|\\n|[fast-style-transfer](https://github.com/lengstrom/fast-style-transfer) |画风|\\n|[image_stylization](https://github.com/tensorflow/magenta/tree/master/magenta/models/image_stylization)|谷歌出的画风|\\n|https://github.com/alexjc/neural-enhance|提高分辨率|\\n\\n\\n\\n\\n\\n#### 留言\\n本来自己想收集相关的项目，发现有大神已经收集了很多 @ http://www.toutiao.com/a6456913007157969421/?tt_from=weixin&utm_campaign=client_share&app=news_article&utm_source=weixin&iid=13812579348&utm_medium=toutiao_ios&wxshare_count=1\\n\\n```\\n1、 图像生成\\n\\n1.1 绘画风格到图片的转换：Neural Style\\n\\n1.2 图像类比转换：image-analogies\\n\\n1.3 根据涂鸦生成图片：Neural Doodle\\n\\n1.4 匹根据涂鸦类比图片：Sketchy\\n\\n1.5 根据图片生成铅笔画：Pencil\\n\\n1.6 手写文字模拟：rnnlib\\n\\n1.7 转换风景图片：Transient Attributes for High-Level Understanding and Editing of Outdoor Scenes\\n\\n1.8 图片变Emojis表情：What emojis will the Emojini 3000 grant your photos?\\n\\n1.9 增加图片分辨率：srez\\n\\n1.10 图片自动上色：Colornet\\n\\n1.11 生成可爱的动漫头像：AnimeGAN\\n\\n1.12 骡子变斑马：CycleGAN and pix2pix in PyTorch\\n\\n1.13 强大的图像生成器：DiscoGAN in PyTorch\\n\\n1.14 使用RNN生成手写数字：DRAW implmentation\\n\\n1.15 使用CNN来放大图片：waifu2x\\n\\n2、 看图说话\\n\\n2.1 根据图片生成一段描述：Show and Tell\\n\\n2.2 根据图片讲故事：neural-storyteller\\n\\n2.3 根据图片将故事2:NeuralTalk2\\n\\n2.4 识别图片中的文字：CRNN for image-based sequence recognition\\n\\n3、 图像识别\\n\\n3.1 用于物体识别的全卷积网络：PyTorch-FCN\\n\\n3.2 引入注意力的卷积网络：Attention Transfer\\n\\n3.3 物体识别实例：Deep-Learning\\n\\n3.4 物体识别API：Tensorflow Object Detection API\\n\\n3.5 推理场景结构：SfMLearner\\n\\n3.6 用于分辨色情图像的open_nsfw\\n\\n3.7 人脸识别：Open Face\\n\\n3.8 易用人脸识别：Face_recognition\\n\\n3.9 快速人脸识别：MobileID\\n\\n3.10 图像识别框架1：AlexNet & VGG Net & GoogleNet & ResNet\\n\\n3.11 图像识别框架2：ResNeXt & RCNN & YOLO & SqueezeNet & SegNet\\n\\n3.12 预训练的图像识别模型：functional-zoo\\n\\n3.13 预定义的CNN过滤器： PyScatWave\\n\\n3.14 计算图片中物体的相似度：Conditional Similarity Networks (CSNs)\\n\\n3.15 量子化学中的神经信息传递(?_?;Neural Message Passing for Quantum Chemistry\\n\\n4 、图像理解\\n\\n4.1 Visual Question Answering in Pytorch\\n\\n4.2 Facebook看图答题：Clevr-IEP\\n\\n1\\n\\n图像生成\\n\\n绘画风格到图片的转换：Neural Style\\n\\nhttps://github.com/jcjohnson/neural-style\\n\\n这个项目是用 Torch 对 Leon A. Gatys, Alexander S. Ecker, 和 Matthias Bethge 等人的论文“A Neural Algorithm of Artistic Style”的一个实现。论文中提出一种算法，用卷积神经网络将一幅图像的内容与另一幅图像的风格进行组合。\\n\\n图像类比转换：image-analogies\\n\\nhttps://github.com/awentzonline/image-analogies\\n\\n“神经图像类比”（neural image analogies）这个项目基本上是 A. Hertzmann et. al（2001）的论文“Image Analogies”的一个实现。在这个项目中，我们使用了 VGG16 的特征，利用 Chuan Li, Michael Wand (2016) 的论文“Combining Markov Random Fields and Convolutional Neural Networks for Image Synthesis”中描述的方法进行patch的匹配和混合。初始代码改编自 Keras 的“神经风格迁移”示例。\\n\\n根据涂鸦生成图片：Neural Doodle\\n\\nhttps://github.com/alexjc/neural-doodle\\n\\n使用深度神经网络把你的二流涂鸦变成艺术一般的作品！这个项目是 Champandard（2016）的论文 “Semantic Style Transfer and Turning Two-Bit Doodles into Fine Artworks”的一个实现，基于 Chuan Li 和 Michael Wand（2016）在论文“Combining Markov Random Fields and Convolutional Neural Networks for Image Synthesis”中提出的 Neural Patches 算法。\\n\\n根据涂鸦类比图片：Sketchy\\n\\nhttps://github.com/janesjanes/sketchy\\n\\n这个项目可以根据用户手绘的涂鸦，匹配出类似的图片。\\n\\n根据图片生成铅笔画：Pencil\\n\\nhttps://github.com/fumin/pencil\\n\\n把一副图像变成铅笔水粉画。\\n\\n手写文字模拟：rnnlib\\n\\nhttps://github.com/szcom/rnnlib\\n\\n这个项目可以做到手写文字模拟。\\n\\n转换风景图片：Transient Attributes for High-Level Understanding and Editing of Outdoor Scenes\\n\\nhttp://transattr.cs.brown.edu\\n\\n这个项目可以识别和理解图片中的风景，并且可以根据用户提出的条件，定向改变原风景画中的环境（比如more night）\\n\\n图片变Emojis表情：What emojis will the Emojini 3000 grant your photos?\\n\\nhttp://engineering.curalate.com/2016/01/20/emojinet.html\\n\\n将用户提供的图片转化成相关的表情图标\\n\\n增加图片分辨率：srez\\n\\nhttps://github.com/david-gpu/srez\\n\\nsrez（super-resolution through deep learning），即通过深度学习实现图像超分辨率。这个项目是利用深度学习将 16x16 的图像分辨率增加 4 倍，基于用来训练神经网络的数据集，所得到的图像具有鲜明的特征。\\n\\n图片自动上色：Colornet\\n\\nhttps://github.com/pavelgonchar/colornet\\n\\nColornet 是一个给灰度图像自动上色的神经网络。\\n\\n生成可爱的动漫头像：AnimeGAN\\n\\nhttps://github.com/jayleicn/animeGAN\\n\\n使用PyTorch实现的GAN，可以自定义生成漂亮的动漫妹子头像，附带训练数据集哦！\\n\\n骡子变斑马：CycleGAN and pix2pix in PyTorch\\n\\nhttps://github.com/junyanz/pytorch-CycleGAN-and-pix2pix.git\\n\\n图到图的翻译，著名的 CycleGAN 以及 pix2pix 的PyTorch 实现。\\n\\n强大的图像生成器：DiscoGAN in PyTorch\\n\\nhttps://github.com/carpedm20/DiscoGAN-pytorch.git\\n\\n《Learning to Discover Cross-Domain Relations with Generative Adversarial Networks》的 PyTorch 实现。\\n\\n使用RNN生成手写数字：DRAW implmentation\\n\\nhttps://github.com/skaae/lasagne-draw\\n\\n使用RNN生成手写体数字。\\n\\n使用CNN来放大图片：waifu2x\\n\\nhttps://github.com/nagadomi/waifu2x\\n\\n使用CNN来放大图片，与普通图片放大不同的是，使用CNN“生成”放大，使低分辨率的图片在放大后也不会出现像素锯齿。\\n\\n2\\n\\n看图说话\\n\\n根据图片生成一段描述：Show and Tell\\n\\nhttps://github.com/tensorflow/models/tree/master/im2txt\\n\\n这是 Oriol Vinyals et. al.（2016）的论文“Show and Tell: Lessons learned from the 2015 MSCOCO Image Captioning Challenge”的用TensorFlow实现的 image-to-text 图片说明生成模型。\\n\\n根据图片讲故事：neural-storyteller\\n\\nhttps://github.com/ryankiros/neural-storyteller\\n\\nNeural-storyteller 是一个能够根据图像内容生成一个小故事的循环神经网络。这个 GitHub 库里包含了使用任意图像生成故事的代码，以及用于训练新模型的说明。\\n\\n根据图片将故事2:NeuralTalk2\\n\\nhttps://github.com/karpathy/neuraltalk2\\n\\n循环神经网络（RNN）可以用于给图像取标题。NeuralTalk2 比原始版本的 NeuralTalk 更快而且性能更好。与原来的 NeuralTalk 相比，NeuralTalk2 的实现是批量的，可以使用 Torch 在 GPU上运行，并且支持 CNN 微调。这些都使得语言模型（~100x）的训练速度大大加快，但由于我们还有一个 VGGNet，因此总体上的提升没有很多。但是这仍然是个好模型，可以在 2~3 天里训练好，而且表现出的性能非常好。\\n\\n识别图片中的文字：CRNN for image-based sequence recognition\\n\\nhttps://github.com/bgshih/crnn.git\\n\\n这个是 Convolutional Recurrent Neural Network (CRNN) 的 PyTorch 实现。CRNN 由一些CNN，RNN和CTC组成，常用于基于图像的序列识别任务，例如场景文本识别和OCR。\\n\\n3\\n\\n图像识别\\n\\n用于物体识别的全卷积网络：PyTorch-FCN\\n\\nhttps://github.com/wkentaro/pytorch-fcn.git\\n\\n一个性能出众的物体识别全卷积神经网络，使用PyTorch实现。\\n\\n引入注意力的卷积网络：Attention Transfer\\n\\nhttps://github.com/szagoruyko/attention-transfer.git\\n\\n论文 \\\"Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer\\\" 的PyTorch实现。\\n\\n物体识别实例：Deep-Learning\\n\\nhttps://github.com/priya-dwivedi/Deep-Learning/blob/master/Object_Detection_Tensorflow_API.ipynb\\n\\n一个基于Ipython Notebook的物体识别实例，使用了Tensorflow Object Dectection API\\n\\n物体识别API：Tensorflow Object Detection API\\n\\nhttps://github.com/tensorflow/models/tree/master/object_detection\\n\\nGoogle Tensorflow Object Dectection API 的开源代码。\\n\\n推理场景结构：SfMLearner\\n\\nhttps://github.com/tinghuiz/SfMLearner\\n\\n用单张图片推理场景结构：UC Berkeley提出3D景深联合学习方法\\n\\n用于分辨色情图像的open_nsfw\\n\\nhttps://github.com/yahoo/open_nsfw\\n\\n这是雅虎构建的用于检测图片是否包含不适宜工作场所（NSFW）内容的深度神经网络项目，GitHub 库中包含了网络的 Caffe 模型的代码。检测具有攻击性或成人内容的图像是研究人员进行了几十年的一个难题。随着计算机视觉技术和深度学习的发展，算法已经成熟，雅虎的这个模型能以更高的精度分辨色情图像。 由于 NSFW 界定其实是很主观的，有的人反感的东西可能其他人并不觉得如何。雅虎的这个深度神经网络只关注NSFW内容的一种类型，即色情图片，所以该模型不适用于检测素描、文字、动画、暴力图片等内容。\\n\\n人脸识别：Open Face\\n\\nhttps://github.com/cmusatyalab/openface\\n\\nOpenFace 是一个使用深度神经网络，用 Python 和 Torch 实现人脸识别的项目。神经网络模型基于 Google Florian Schroff 等人的 CVPR 2015 论文“FaceNet: A Unified Embedding for Face Recognition and Clustering” ，Torch 让网络可以在 CPU 或 CUDA 上运行。\\n\\n易用人脸识别：Face_recognition\\n\\nhttps://github.com/ageitgey/face_recognition#face-recognition\\n\\n这也提供了一个简单的 face_recognition 命令行工具，你可以打开命令行中任意图像文件夹，进行人脸识别！\\n\\n快速人脸识别：MobileID\\n\\nhttps://github.com/liuziwei7/mobile-id\\n\\n据说是个超级快速的人脸识别程序，可以用在手机上\\n\\n图像识别框架1：AlexNet & VGG Net & GoogleNet & ResNet\\n\\nAlexNet\\n\\nhttps://gist.github.com/JBed/c2fb3ce8ed299f197eff\\n\\nVGG Ne\\n\\nhttps://github.com/fchollet/keras/blob/master/keras/applications/vgg16.py\\n\\nGoogleNet\\n\\nhttps://github.com/fchollet/keras/blob/master/keras/applications/inception_v3.py\\n\\nResNet\\n\\nhttps://github.com/fchollet/keras/blob/master/keras/applications/resnet50.py\\n\\n图像识别框架2：ResNeXt & RCNN & YOLO & SqueezeNet & SegNet\\n\\nResNeXt\\n\\nhttps://github.com/titu1994/Keras-ResNeXt\\n\\nRCNN (基于区域的 CNN)\\n\\nhttps://github.com/yhenon/keras-frcnn\\n\\nYOLO (You Only Look once)\\n\\nhttps://github.com/allanzelener/YAD2K\\n\\nSqueezeNet\\n\\nhttps://github.com/rcmalli/keras-squeezenet\\n\\nSegNet\\n\\nhttps://github.com/imlab-uiip/keras-segnet\\n\\n预训练的图像识别模型：functional-zoo\\n\\nhttps://github.com/szagoruyko/functional-zoo.git\\n\\n由PyTorch和Tensorflow实现的常用图像识别模型包含预训练参数。\\n\\n预定义的CNN过滤器： PyScatWave\\n\\nhttps://github.com/edouardoyallon/pyscatwave\\n\\n一套预定义的filter，用于增强图像识别的效果。\\n\\n计算图片中物体的相似度：Conditional Similarity Networks (CSNs)\\n\\nhttps://github.com/andreasveit/conditional-similarity-networks.git\\n\\n《Conditional Similarity Networks》的PyTorch实现，可以根据不同的条件计算图片中物体的相似度。\\n\\n量子化学中的神经信息传递(Neural Message Passing for Quantum Chemistry)\\n\\nhttps://github.com/priba/nmp_qc.git\\n\\n论文《Neural Message Passing for Quantum Chemistry》的PyTorch实现，讲的是量子化学里的神经信息传递！听起来碉堡了。\\n\\n4\\n\\n图像理解\\n\\nVisual Question Answering in Pytorch\\n\\nhttps://github.com/Cadene/vqa.pytorch.git\\n\\n一个PyTorch实现的优秀视觉推理问答系统，是基于论文《MUTAN: Multimodal Tucker Fusion for Visual Question Answering》实现的。项目中有详细的配置使用方法说明。\\n\\nFacebook看图答题：Clevr-IEP\\n\\nhttps://github.com/facebookresearch/clevr-iep.git\\n\\nFacebook Research 论文《Inferring and Executing Programs for Visual Reasoning》的PyTorch实现，讲的是一个可以基于图片进行关系推理问答的网络。\\n```\\n\\n\\n \"}]],\"sections\":[[10,0]]}","html":"<div class=\"kg-card-markdown\"><table>\n<thead>\n<tr>\n<th>项目</th>\n<th>简介</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><a href=\"https://github.com/carpedm20/DCGAN-tensorflow\">DCGAN-tensorflow</a></td>\n<td>脸部</td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/LouieYang/deep-photo-styletransfer-tf\">deep-photo-styletransfer-tf</a></td>\n<td>不同的图片风格合成</td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/yunjey/domain-transfer-network\">domain-transfer-network</a></td>\n<td></td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/anishathalye/neural-style\">neural-style</a></td>\n<td>梵高画风</td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/awentzonline/image-analogies\">image-analogies</a></td>\n<td>改变画风</td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/ZZUTK/Face-Aging-CAAE\">Face-Aging-CAAE</a></td>\n<td>人脸年纪变化</td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/lengstrom/fast-style-transfer\">fast-style-transfer</a></td>\n<td>画风</td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/tensorflow/magenta/tree/master/magenta/models/image_stylization\">image_stylization</a></td>\n<td>谷歌出的画风</td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/alexjc/neural-enhance\">https://github.com/alexjc/neural-enhance</a></td>\n<td>提高分辨率</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"\">留言</h4>\n<p>本来自己想收集相关的项目，发现有大神已经收集了很多 @ <a href=\"http://www.toutiao.com/a6456913007157969421/?tt_from=weixin&amp;utm_campaign=client_share&amp;app=news_article&amp;utm_source=weixin&amp;iid=13812579348&amp;utm_medium=toutiao_ios&amp;wxshare_count=1\">http://www.toutiao.com/a6456913007157969421/?tt_from=weixin&amp;utm_campaign=client_share&amp;app=news_article&amp;utm_source=weixin&amp;iid=13812579348&amp;utm_medium=toutiao_ios&amp;wxshare_count=1</a></p>\n<pre><code>1、 图像生成\n\n1.1 绘画风格到图片的转换：Neural Style\n\n1.2 图像类比转换：image-analogies\n\n1.3 根据涂鸦生成图片：Neural Doodle\n\n1.4 匹根据涂鸦类比图片：Sketchy\n\n1.5 根据图片生成铅笔画：Pencil\n\n1.6 手写文字模拟：rnnlib\n\n1.7 转换风景图片：Transient Attributes for High-Level Understanding and Editing of Outdoor Scenes\n\n1.8 图片变Emojis表情：What emojis will the Emojini 3000 grant your photos?\n\n1.9 增加图片分辨率：srez\n\n1.10 图片自动上色：Colornet\n\n1.11 生成可爱的动漫头像：AnimeGAN\n\n1.12 骡子变斑马：CycleGAN and pix2pix in PyTorch\n\n1.13 强大的图像生成器：DiscoGAN in PyTorch\n\n1.14 使用RNN生成手写数字：DRAW implmentation\n\n1.15 使用CNN来放大图片：waifu2x\n\n2、 看图说话\n\n2.1 根据图片生成一段描述：Show and Tell\n\n2.2 根据图片讲故事：neural-storyteller\n\n2.3 根据图片将故事2:NeuralTalk2\n\n2.4 识别图片中的文字：CRNN for image-based sequence recognition\n\n3、 图像识别\n\n3.1 用于物体识别的全卷积网络：PyTorch-FCN\n\n3.2 引入注意力的卷积网络：Attention Transfer\n\n3.3 物体识别实例：Deep-Learning\n\n3.4 物体识别API：Tensorflow Object Detection API\n\n3.5 推理场景结构：SfMLearner\n\n3.6 用于分辨色情图像的open_nsfw\n\n3.7 人脸识别：Open Face\n\n3.8 易用人脸识别：Face_recognition\n\n3.9 快速人脸识别：MobileID\n\n3.10 图像识别框架1：AlexNet &amp; VGG Net &amp; GoogleNet &amp; ResNet\n\n3.11 图像识别框架2：ResNeXt &amp; RCNN &amp; YOLO &amp; SqueezeNet &amp; SegNet\n\n3.12 预训练的图像识别模型：functional-zoo\n\n3.13 预定义的CNN过滤器： PyScatWave\n\n3.14 计算图片中物体的相似度：Conditional Similarity Networks (CSNs)\n\n3.15 量子化学中的神经信息传递(?_?;Neural Message Passing for Quantum Chemistry\n\n4 、图像理解\n\n4.1 Visual Question Answering in Pytorch\n\n4.2 Facebook看图答题：Clevr-IEP\n\n1\n\n图像生成\n\n绘画风格到图片的转换：Neural Style\n\nhttps://github.com/jcjohnson/neural-style\n\n这个项目是用 Torch 对 Leon A. Gatys, Alexander S. Ecker, 和 Matthias Bethge 等人的论文“A Neural Algorithm of Artistic Style”的一个实现。论文中提出一种算法，用卷积神经网络将一幅图像的内容与另一幅图像的风格进行组合。\n\n图像类比转换：image-analogies\n\nhttps://github.com/awentzonline/image-analogies\n\n“神经图像类比”（neural image analogies）这个项目基本上是 A. Hertzmann et. al（2001）的论文“Image Analogies”的一个实现。在这个项目中，我们使用了 VGG16 的特征，利用 Chuan Li, Michael Wand (2016) 的论文“Combining Markov Random Fields and Convolutional Neural Networks for Image Synthesis”中描述的方法进行patch的匹配和混合。初始代码改编自 Keras 的“神经风格迁移”示例。\n\n根据涂鸦生成图片：Neural Doodle\n\nhttps://github.com/alexjc/neural-doodle\n\n使用深度神经网络把你的二流涂鸦变成艺术一般的作品！这个项目是 Champandard（2016）的论文 “Semantic Style Transfer and Turning Two-Bit Doodles into Fine Artworks”的一个实现，基于 Chuan Li 和 Michael Wand（2016）在论文“Combining Markov Random Fields and Convolutional Neural Networks for Image Synthesis”中提出的 Neural Patches 算法。\n\n根据涂鸦类比图片：Sketchy\n\nhttps://github.com/janesjanes/sketchy\n\n这个项目可以根据用户手绘的涂鸦，匹配出类似的图片。\n\n根据图片生成铅笔画：Pencil\n\nhttps://github.com/fumin/pencil\n\n把一副图像变成铅笔水粉画。\n\n手写文字模拟：rnnlib\n\nhttps://github.com/szcom/rnnlib\n\n这个项目可以做到手写文字模拟。\n\n转换风景图片：Transient Attributes for High-Level Understanding and Editing of Outdoor Scenes\n\nhttp://transattr.cs.brown.edu\n\n这个项目可以识别和理解图片中的风景，并且可以根据用户提出的条件，定向改变原风景画中的环境（比如more night）\n\n图片变Emojis表情：What emojis will the Emojini 3000 grant your photos?\n\nhttp://engineering.curalate.com/2016/01/20/emojinet.html\n\n将用户提供的图片转化成相关的表情图标\n\n增加图片分辨率：srez\n\nhttps://github.com/david-gpu/srez\n\nsrez（super-resolution through deep learning），即通过深度学习实现图像超分辨率。这个项目是利用深度学习将 16x16 的图像分辨率增加 4 倍，基于用来训练神经网络的数据集，所得到的图像具有鲜明的特征。\n\n图片自动上色：Colornet\n\nhttps://github.com/pavelgonchar/colornet\n\nColornet 是一个给灰度图像自动上色的神经网络。\n\n生成可爱的动漫头像：AnimeGAN\n\nhttps://github.com/jayleicn/animeGAN\n\n使用PyTorch实现的GAN，可以自定义生成漂亮的动漫妹子头像，附带训练数据集哦！\n\n骡子变斑马：CycleGAN and pix2pix in PyTorch\n\nhttps://github.com/junyanz/pytorch-CycleGAN-and-pix2pix.git\n\n图到图的翻译，著名的 CycleGAN 以及 pix2pix 的PyTorch 实现。\n\n强大的图像生成器：DiscoGAN in PyTorch\n\nhttps://github.com/carpedm20/DiscoGAN-pytorch.git\n\n《Learning to Discover Cross-Domain Relations with Generative Adversarial Networks》的 PyTorch 实现。\n\n使用RNN生成手写数字：DRAW implmentation\n\nhttps://github.com/skaae/lasagne-draw\n\n使用RNN生成手写体数字。\n\n使用CNN来放大图片：waifu2x\n\nhttps://github.com/nagadomi/waifu2x\n\n使用CNN来放大图片，与普通图片放大不同的是，使用CNN“生成”放大，使低分辨率的图片在放大后也不会出现像素锯齿。\n\n2\n\n看图说话\n\n根据图片生成一段描述：Show and Tell\n\nhttps://github.com/tensorflow/models/tree/master/im2txt\n\n这是 Oriol Vinyals et. al.（2016）的论文“Show and Tell: Lessons learned from the 2015 MSCOCO Image Captioning Challenge”的用TensorFlow实现的 image-to-text 图片说明生成模型。\n\n根据图片讲故事：neural-storyteller\n\nhttps://github.com/ryankiros/neural-storyteller\n\nNeural-storyteller 是一个能够根据图像内容生成一个小故事的循环神经网络。这个 GitHub 库里包含了使用任意图像生成故事的代码，以及用于训练新模型的说明。\n\n根据图片将故事2:NeuralTalk2\n\nhttps://github.com/karpathy/neuraltalk2\n\n循环神经网络（RNN）可以用于给图像取标题。NeuralTalk2 比原始版本的 NeuralTalk 更快而且性能更好。与原来的 NeuralTalk 相比，NeuralTalk2 的实现是批量的，可以使用 Torch 在 GPU上运行，并且支持 CNN 微调。这些都使得语言模型（~100x）的训练速度大大加快，但由于我们还有一个 VGGNet，因此总体上的提升没有很多。但是这仍然是个好模型，可以在 2~3 天里训练好，而且表现出的性能非常好。\n\n识别图片中的文字：CRNN for image-based sequence recognition\n\nhttps://github.com/bgshih/crnn.git\n\n这个是 Convolutional Recurrent Neural Network (CRNN) 的 PyTorch 实现。CRNN 由一些CNN，RNN和CTC组成，常用于基于图像的序列识别任务，例如场景文本识别和OCR。\n\n3\n\n图像识别\n\n用于物体识别的全卷积网络：PyTorch-FCN\n\nhttps://github.com/wkentaro/pytorch-fcn.git\n\n一个性能出众的物体识别全卷积神经网络，使用PyTorch实现。\n\n引入注意力的卷积网络：Attention Transfer\n\nhttps://github.com/szagoruyko/attention-transfer.git\n\n论文 &quot;Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer&quot; 的PyTorch实现。\n\n物体识别实例：Deep-Learning\n\nhttps://github.com/priya-dwivedi/Deep-Learning/blob/master/Object_Detection_Tensorflow_API.ipynb\n\n一个基于Ipython Notebook的物体识别实例，使用了Tensorflow Object Dectection API\n\n物体识别API：Tensorflow Object Detection API\n\nhttps://github.com/tensorflow/models/tree/master/object_detection\n\nGoogle Tensorflow Object Dectection API 的开源代码。\n\n推理场景结构：SfMLearner\n\nhttps://github.com/tinghuiz/SfMLearner\n\n用单张图片推理场景结构：UC Berkeley提出3D景深联合学习方法\n\n用于分辨色情图像的open_nsfw\n\nhttps://github.com/yahoo/open_nsfw\n\n这是雅虎构建的用于检测图片是否包含不适宜工作场所（NSFW）内容的深度神经网络项目，GitHub 库中包含了网络的 Caffe 模型的代码。检测具有攻击性或成人内容的图像是研究人员进行了几十年的一个难题。随着计算机视觉技术和深度学习的发展，算法已经成熟，雅虎的这个模型能以更高的精度分辨色情图像。 由于 NSFW 界定其实是很主观的，有的人反感的东西可能其他人并不觉得如何。雅虎的这个深度神经网络只关注NSFW内容的一种类型，即色情图片，所以该模型不适用于检测素描、文字、动画、暴力图片等内容。\n\n人脸识别：Open Face\n\nhttps://github.com/cmusatyalab/openface\n\nOpenFace 是一个使用深度神经网络，用 Python 和 Torch 实现人脸识别的项目。神经网络模型基于 Google Florian Schroff 等人的 CVPR 2015 论文“FaceNet: A Unified Embedding for Face Recognition and Clustering” ，Torch 让网络可以在 CPU 或 CUDA 上运行。\n\n易用人脸识别：Face_recognition\n\nhttps://github.com/ageitgey/face_recognition#face-recognition\n\n这也提供了一个简单的 face_recognition 命令行工具，你可以打开命令行中任意图像文件夹，进行人脸识别！\n\n快速人脸识别：MobileID\n\nhttps://github.com/liuziwei7/mobile-id\n\n据说是个超级快速的人脸识别程序，可以用在手机上\n\n图像识别框架1：AlexNet &amp; VGG Net &amp; GoogleNet &amp; ResNet\n\nAlexNet\n\nhttps://gist.github.com/JBed/c2fb3ce8ed299f197eff\n\nVGG Ne\n\nhttps://github.com/fchollet/keras/blob/master/keras/applications/vgg16.py\n\nGoogleNet\n\nhttps://github.com/fchollet/keras/blob/master/keras/applications/inception_v3.py\n\nResNet\n\nhttps://github.com/fchollet/keras/blob/master/keras/applications/resnet50.py\n\n图像识别框架2：ResNeXt &amp; RCNN &amp; YOLO &amp; SqueezeNet &amp; SegNet\n\nResNeXt\n\nhttps://github.com/titu1994/Keras-ResNeXt\n\nRCNN (基于区域的 CNN)\n\nhttps://github.com/yhenon/keras-frcnn\n\nYOLO (You Only Look once)\n\nhttps://github.com/allanzelener/YAD2K\n\nSqueezeNet\n\nhttps://github.com/rcmalli/keras-squeezenet\n\nSegNet\n\nhttps://github.com/imlab-uiip/keras-segnet\n\n预训练的图像识别模型：functional-zoo\n\nhttps://github.com/szagoruyko/functional-zoo.git\n\n由PyTorch和Tensorflow实现的常用图像识别模型包含预训练参数。\n\n预定义的CNN过滤器： PyScatWave\n\nhttps://github.com/edouardoyallon/pyscatwave\n\n一套预定义的filter，用于增强图像识别的效果。\n\n计算图片中物体的相似度：Conditional Similarity Networks (CSNs)\n\nhttps://github.com/andreasveit/conditional-similarity-networks.git\n\n《Conditional Similarity Networks》的PyTorch实现，可以根据不同的条件计算图片中物体的相似度。\n\n量子化学中的神经信息传递(Neural Message Passing for Quantum Chemistry)\n\nhttps://github.com/priba/nmp_qc.git\n\n论文《Neural Message Passing for Quantum Chemistry》的PyTorch实现，讲的是量子化学里的神经信息传递！听起来碉堡了。\n\n4\n\n图像理解\n\nVisual Question Answering in Pytorch\n\nhttps://github.com/Cadene/vqa.pytorch.git\n\n一个PyTorch实现的优秀视觉推理问答系统，是基于论文《MUTAN: Multimodal Tucker Fusion for Visual Question Answering》实现的。项目中有详细的配置使用方法说明。\n\nFacebook看图答题：Clevr-IEP\n\nhttps://github.com/facebookresearch/clevr-iep.git\n\nFacebook Research 论文《Inferring and Executing Programs for Visual Reasoning》的PyTorch实现，讲的是一个可以基于图片进行关系推理问答的网络。\n</code></pre>\n</div>","amp":null,"plaintext":"项目简介DCGAN-tensorflow [https://github.com/carpedm20/DCGAN-tensorflow]脸部\ndeep-photo-styletransfer-tf\n[https://github.com/LouieYang/deep-photo-styletransfer-tf]不同的图片风格合成\ndomain-transfer-network [https://github.com/yunjey/domain-transfer-network]\nneural-style [https://github.com/anishathalye/neural-style]梵高画风image-analogies\n[https://github.com/awentzonline/image-analogies]改变画风Face-Aging-CAAE\n[https://github.com/ZZUTK/Face-Aging-CAAE]人脸年纪变化fast-style-transfer\n[https://github.com/lengstrom/fast-style-transfer]画风image_stylization\n[https://github.com/tensorflow/magenta/tree/master/magenta/models/image_stylization]\n谷歌出的画风https://github.com/alexjc/neural-enhance提高分辨率留言\n本来自己想收集相关的项目，发现有大神已经收集了很多 @ \nhttp://www.toutiao.com/a6456913007157969421/?tt_from=weixin&utm_campaign=client_share&app=news_article&utm_source=weixin&iid=13812579348&utm_medium=toutiao_ios&wxshare_count=1\n[http://www.toutiao.com/a6456913007157969421/?tt_from=weixin&utm_campaign=client_share&app=news_article&utm_source=weixin&iid=13812579348&utm_medium=toutiao_ios&wxshare_count=1]\n\n1、 图像生成\n\n1.1 绘画风格到图片的转换：Neural Style\n\n1.2 图像类比转换：image-analogies\n\n1.3 根据涂鸦生成图片：Neural Doodle\n\n1.4 匹根据涂鸦类比图片：Sketchy\n\n1.5 根据图片生成铅笔画：Pencil\n\n1.6 手写文字模拟：rnnlib\n\n1.7 转换风景图片：Transient Attributes for High-Level Understanding and Editing of Outdoor Scenes\n\n1.8 图片变Emojis表情：What emojis will the Emojini 3000 grant your photos?\n\n1.9 增加图片分辨率：srez\n\n1.10 图片自动上色：Colornet\n\n1.11 生成可爱的动漫头像：AnimeGAN\n\n1.12 骡子变斑马：CycleGAN and pix2pix in PyTorch\n\n1.13 强大的图像生成器：DiscoGAN in PyTorch\n\n1.14 使用RNN生成手写数字：DRAW implmentation\n\n1.15 使用CNN来放大图片：waifu2x\n\n2、 看图说话\n\n2.1 根据图片生成一段描述：Show and Tell\n\n2.2 根据图片讲故事：neural-storyteller\n\n2.3 根据图片将故事2:NeuralTalk2\n\n2.4 识别图片中的文字：CRNN for image-based sequence recognition\n\n3、 图像识别\n\n3.1 用于物体识别的全卷积网络：PyTorch-FCN\n\n3.2 引入注意力的卷积网络：Attention Transfer\n\n3.3 物体识别实例：Deep-Learning\n\n3.4 物体识别API：Tensorflow Object Detection API\n\n3.5 推理场景结构：SfMLearner\n\n3.6 用于分辨色情图像的open_nsfw\n\n3.7 人脸识别：Open Face\n\n3.8 易用人脸识别：Face_recognition\n\n3.9 快速人脸识别：MobileID\n\n3.10 图像识别框架1：AlexNet & VGG Net & GoogleNet & ResNet\n\n3.11 图像识别框架2：ResNeXt & RCNN & YOLO & SqueezeNet & SegNet\n\n3.12 预训练的图像识别模型：functional-zoo\n\n3.13 预定义的CNN过滤器： PyScatWave\n\n3.14 计算图片中物体的相似度：Conditional Similarity Networks (CSNs)\n\n3.15 量子化学中的神经信息传递(?_?;Neural Message Passing for Quantum Chemistry\n\n4 、图像理解\n\n4.1 Visual Question Answering in Pytorch\n\n4.2 Facebook看图答题：Clevr-IEP\n\n1\n\n图像生成\n\n绘画风格到图片的转换：Neural Style\n\nhttps://github.com/jcjohnson/neural-style\n\n这个项目是用 Torch 对 Leon A. Gatys, Alexander S. Ecker, 和 Matthias Bethge 等人的论文“A Neural Algorithm of Artistic Style”的一个实现。论文中提出一种算法，用卷积神经网络将一幅图像的内容与另一幅图像的风格进行组合。\n\n图像类比转换：image-analogies\n\nhttps://github.com/awentzonline/image-analogies\n\n“神经图像类比”（neural image analogies）这个项目基本上是 A. Hertzmann et. al（2001）的论文“Image Analogies”的一个实现。在这个项目中，我们使用了 VGG16 的特征，利用 Chuan Li, Michael Wand (2016) 的论文“Combining Markov Random Fields and Convolutional Neural Networks for Image Synthesis”中描述的方法进行patch的匹配和混合。初始代码改编自 Keras 的“神经风格迁移”示例。\n\n根据涂鸦生成图片：Neural Doodle\n\nhttps://github.com/alexjc/neural-doodle\n\n使用深度神经网络把你的二流涂鸦变成艺术一般的作品！这个项目是 Champandard（2016）的论文 “Semantic Style Transfer and Turning Two-Bit Doodles into Fine Artworks”的一个实现，基于 Chuan Li 和 Michael Wand（2016）在论文“Combining Markov Random Fields and Convolutional Neural Networks for Image Synthesis”中提出的 Neural Patches 算法。\n\n根据涂鸦类比图片：Sketchy\n\nhttps://github.com/janesjanes/sketchy\n\n这个项目可以根据用户手绘的涂鸦，匹配出类似的图片。\n\n根据图片生成铅笔画：Pencil\n\nhttps://github.com/fumin/pencil\n\n把一副图像变成铅笔水粉画。\n\n手写文字模拟：rnnlib\n\nhttps://github.com/szcom/rnnlib\n\n这个项目可以做到手写文字模拟。\n\n转换风景图片：Transient Attributes for High-Level Understanding and Editing of Outdoor Scenes\n\nhttp://transattr.cs.brown.edu\n\n这个项目可以识别和理解图片中的风景，并且可以根据用户提出的条件，定向改变原风景画中的环境（比如more night）\n\n图片变Emojis表情：What emojis will the Emojini 3000 grant your photos?\n\nhttp://engineering.curalate.com/2016/01/20/emojinet.html\n\n将用户提供的图片转化成相关的表情图标\n\n增加图片分辨率：srez\n\nhttps://github.com/david-gpu/srez\n\nsrez（super-resolution through deep learning），即通过深度学习实现图像超分辨率。这个项目是利用深度学习将 16x16 的图像分辨率增加 4 倍，基于用来训练神经网络的数据集，所得到的图像具有鲜明的特征。\n\n图片自动上色：Colornet\n\nhttps://github.com/pavelgonchar/colornet\n\nColornet 是一个给灰度图像自动上色的神经网络。\n\n生成可爱的动漫头像：AnimeGAN\n\nhttps://github.com/jayleicn/animeGAN\n\n使用PyTorch实现的GAN，可以自定义生成漂亮的动漫妹子头像，附带训练数据集哦！\n\n骡子变斑马：CycleGAN and pix2pix in PyTorch\n\nhttps://github.com/junyanz/pytorch-CycleGAN-and-pix2pix.git\n\n图到图的翻译，著名的 CycleGAN 以及 pix2pix 的PyTorch 实现。\n\n强大的图像生成器：DiscoGAN in PyTorch\n\nhttps://github.com/carpedm20/DiscoGAN-pytorch.git\n\n《Learning to Discover Cross-Domain Relations with Generative Adversarial Networks》的 PyTorch 实现。\n\n使用RNN生成手写数字：DRAW implmentation\n\nhttps://github.com/skaae/lasagne-draw\n\n使用RNN生成手写体数字。\n\n使用CNN来放大图片：waifu2x\n\nhttps://github.com/nagadomi/waifu2x\n\n使用CNN来放大图片，与普通图片放大不同的是，使用CNN“生成”放大，使低分辨率的图片在放大后也不会出现像素锯齿。\n\n2\n\n看图说话\n\n根据图片生成一段描述：Show and Tell\n\nhttps://github.com/tensorflow/models/tree/master/im2txt\n\n这是 Oriol Vinyals et. al.（2016）的论文“Show and Tell: Lessons learned from the 2015 MSCOCO Image Captioning Challenge”的用TensorFlow实现的 image-to-text 图片说明生成模型。\n\n根据图片讲故事：neural-storyteller\n\nhttps://github.com/ryankiros/neural-storyteller\n\nNeural-storyteller 是一个能够根据图像内容生成一个小故事的循环神经网络。这个 GitHub 库里包含了使用任意图像生成故事的代码，以及用于训练新模型的说明。\n\n根据图片将故事2:NeuralTalk2\n\nhttps://github.com/karpathy/neuraltalk2\n\n循环神经网络（RNN）可以用于给图像取标题。NeuralTalk2 比原始版本的 NeuralTalk 更快而且性能更好。与原来的 NeuralTalk 相比，NeuralTalk2 的实现是批量的，可以使用 Torch 在 GPU上运行，并且支持 CNN 微调。这些都使得语言模型（~100x）的训练速度大大加快，但由于我们还有一个 VGGNet，因此总体上的提升没有很多。但是这仍然是个好模型，可以在 2~3 天里训练好，而且表现出的性能非常好。\n\n识别图片中的文字：CRNN for image-based sequence recognition\n\nhttps://github.com/bgshih/crnn.git\n\n这个是 Convolutional Recurrent Neural Network (CRNN) 的 PyTorch 实现。CRNN 由一些CNN，RNN和CTC组成，常用于基于图像的序列识别任务，例如场景文本识别和OCR。\n\n3\n\n图像识别\n\n用于物体识别的全卷积网络：PyTorch-FCN\n\nhttps://github.com/wkentaro/pytorch-fcn.git\n\n一个性能出众的物体识别全卷积神经网络，使用PyTorch实现。\n\n引入注意力的卷积网络：Attention Transfer\n\nhttps://github.com/szagoruyko/attention-transfer.git\n\n论文 \"Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer\" 的PyTorch实现。\n\n物体识别实例：Deep-Learning\n\nhttps://github.com/priya-dwivedi/Deep-Learning/blob/master/Object_Detection_Tensorflow_API.ipynb\n\n一个基于Ipython Notebook的物体识别实例，使用了Tensorflow Object Dectection API\n\n物体识别API：Tensorflow Object Detection API\n\nhttps://github.com/tensorflow/models/tree/master/object_detection\n\nGoogle Tensorflow Object Dectection API 的开源代码。\n\n推理场景结构：SfMLearner\n\nhttps://github.com/tinghuiz/SfMLearner\n\n用单张图片推理场景结构：UC Berkeley提出3D景深联合学习方法\n\n用于分辨色情图像的open_nsfw\n\nhttps://github.com/yahoo/open_nsfw\n\n这是雅虎构建的用于检测图片是否包含不适宜工作场所（NSFW）内容的深度神经网络项目，GitHub 库中包含了网络的 Caffe 模型的代码。检测具有攻击性或成人内容的图像是研究人员进行了几十年的一个难题。随着计算机视觉技术和深度学习的发展，算法已经成熟，雅虎的这个模型能以更高的精度分辨色情图像。 由于 NSFW 界定其实是很主观的，有的人反感的东西可能其他人并不觉得如何。雅虎的这个深度神经网络只关注NSFW内容的一种类型，即色情图片，所以该模型不适用于检测素描、文字、动画、暴力图片等内容。\n\n人脸识别：Open Face\n\nhttps://github.com/cmusatyalab/openface\n\nOpenFace 是一个使用深度神经网络，用 Python 和 Torch 实现人脸识别的项目。神经网络模型基于 Google Florian Schroff 等人的 CVPR 2015 论文“FaceNet: A Unified Embedding for Face Recognition and Clustering” ，Torch 让网络可以在 CPU 或 CUDA 上运行。\n\n易用人脸识别：Face_recognition\n\nhttps://github.com/ageitgey/face_recognition#face-recognition\n\n这也提供了一个简单的 face_recognition 命令行工具，你可以打开命令行中任意图像文件夹，进行人脸识别！\n\n快速人脸识别：MobileID\n\nhttps://github.com/liuziwei7/mobile-id\n\n据说是个超级快速的人脸识别程序，可以用在手机上\n\n图像识别框架1：AlexNet & VGG Net & GoogleNet & ResNet\n\nAlexNet\n\nhttps://gist.github.com/JBed/c2fb3ce8ed299f197eff\n\nVGG Ne\n\nhttps://github.com/fchollet/keras/blob/master/keras/applications/vgg16.py\n\nGoogleNet\n\nhttps://github.com/fchollet/keras/blob/master/keras/applications/inception_v3.py\n\nResNet\n\nhttps://github.com/fchollet/keras/blob/master/keras/applications/resnet50.py\n\n图像识别框架2：ResNeXt & RCNN & YOLO & SqueezeNet & SegNet\n\nResNeXt\n\nhttps://github.com/titu1994/Keras-ResNeXt\n\nRCNN (基于区域的 CNN)\n\nhttps://github.com/yhenon/keras-frcnn\n\nYOLO (You Only Look once)\n\nhttps://github.com/allanzelener/YAD2K\n\nSqueezeNet\n\nhttps://github.com/rcmalli/keras-squeezenet\n\nSegNet\n\nhttps://github.com/imlab-uiip/keras-segnet\n\n预训练的图像识别模型：functional-zoo\n\nhttps://github.com/szagoruyko/functional-zoo.git\n\n由PyTorch和Tensorflow实现的常用图像识别模型包含预训练参数。\n\n预定义的CNN过滤器： PyScatWave\n\nhttps://github.com/edouardoyallon/pyscatwave\n\n一套预定义的filter，用于增强图像识别的效果。\n\n计算图片中物体的相似度：Conditional Similarity Networks (CSNs)\n\nhttps://github.com/andreasveit/conditional-similarity-networks.git\n\n《Conditional Similarity Networks》的PyTorch实现，可以根据不同的条件计算图片中物体的相似度。\n\n量子化学中的神经信息传递(Neural Message Passing for Quantum Chemistry)\n\nhttps://github.com/priba/nmp_qc.git\n\n论文《Neural Message Passing for Quantum Chemistry》的PyTorch实现，讲的是量子化学里的神经信息传递！听起来碉堡了。\n\n4\n\n图像理解\n\nVisual Question Answering in Pytorch\n\nhttps://github.com/Cadene/vqa.pytorch.git\n\n一个PyTorch实现的优秀视觉推理问答系统，是基于论文《MUTAN: Multimodal Tucker Fusion for Visual Question Answering》实现的。项目中有详细的配置使用方法说明。\n\nFacebook看图答题：Clevr-IEP\n\nhttps://github.com/facebookresearch/clevr-iep.git\n\nFacebook Research 论文《Inferring and Executing Programs for Visual Reasoning》的PyTorch实现，讲的是一个可以基于图片进行关系推理问答的网络。","feature_image":null,"featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2017-08-17 06:49:21","created_by":"1","updated_at":"2017-08-23 07:00:42","updated_by":"1","published_at":"2017-08-17 09:04:01","published_by":"1","custom_excerpt":null,"codeinjection_head":"","codeinjection_foot":"","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null},{"id":"599ab24cf36c876ae083d8a8","uuid":"402e40c2-07cd-4f9b-89f2-fcbfc29044f0","title":"tensorflow magenta","slug":"tensorflow-magenta","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"## 安装\\n### 说明\\n使用tensorflow 1.0以上版本 执行`image_stylization_transform`会出现图片黑屏问题\\n解决办法 @ https://github.com/tensorflow/magenta/issues/570\\n\\n\\n\\n\\n### 自己重新编译步骤 \\n```\\n git clone https://github.com/tensorflow/magenta.git\\n git checkout v0.1.15\\n bazel-bin/magenta/tools/pip/build_pip_package /data/magenta_pkg\\n pip install -U /data/magenta_pkg/magenta-0.1.15-py2-none-any.whl\\n```\\nhttps://magenta.tensorflow.org/2016/11/01/multistyle-pastiche-generator\\n\\n## 训练自己模型\\n\\nFirst, you need to prepare your style images:\\n```\\nbazel-bin/magenta/models/image_stylization/image_stylization_create_dataset --vgg_checkpoint=/Users/haizhu/Downloads/ml/vgg_16.ckpt --style_files=/Users/haizhu/Desktop/jiemo/style/\\\\*.jpg  --output_file=out/style_images.tfrecord\\n```\\n\\n\\nThen, to train a model:\\n```\\nbazel-bin/magenta/models/image_stylization/image_stylization_train --train_dir=out/train --style_dataset_file=out/style_images.tfrecord --num_styles=3 --vgg_checkpoint=/Users/haizhu/Downloads/ml/vgg_16.ckpt --imagenet_data_dir=out/imagenet-tfrecord\\n```\"}]],\"sections\":[[10,0]]}","html":"<div class=\"kg-card-markdown\"><h2 id=\"\">安装</h2>\n<h3 id=\"\">说明</h3>\n<p>使用tensorflow 1.0以上版本 执行<code>image_stylization_transform</code>会出现图片黑屏问题<br>\n解决办法 @ <a href=\"https://github.com/tensorflow/magenta/issues/570\">https://github.com/tensorflow/magenta/issues/570</a></p>\n<h3 id=\"\">自己重新编译步骤</h3>\n<pre><code> git clone https://github.com/tensorflow/magenta.git\n git checkout v0.1.15\n bazel-bin/magenta/tools/pip/build_pip_package /data/magenta_pkg\n pip install -U /data/magenta_pkg/magenta-0.1.15-py2-none-any.whl\n</code></pre>\n<p><a href=\"https://magenta.tensorflow.org/2016/11/01/multistyle-pastiche-generator\">https://magenta.tensorflow.org/2016/11/01/multistyle-pastiche-generator</a></p>\n<h2 id=\"\">训练自己模型</h2>\n<p>First, you need to prepare your style images:</p>\n<pre><code>bazel-bin/magenta/models/image_stylization/image_stylization_create_dataset --vgg_checkpoint=/Users/haizhu/Downloads/ml/vgg_16.ckpt --style_files=/Users/haizhu/Desktop/jiemo/style/\\*.jpg  --output_file=out/style_images.tfrecord\n</code></pre>\n<p>Then, to train a model:</p>\n<pre><code>bazel-bin/magenta/models/image_stylization/image_stylization_train --train_dir=out/train --style_dataset_file=out/style_images.tfrecord --num_styles=3 --vgg_checkpoint=/Users/haizhu/Downloads/ml/vgg_16.ckpt --imagenet_data_dir=out/imagenet-tfrecord\n</code></pre>\n</div>","amp":null,"plaintext":"安装\n说明\n使用tensorflow 1.0以上版本 执行image_stylization_transform会出现图片黑屏问题\n解决办法 @ https://github.com/tensorflow/magenta/issues/570\n\n自己重新编译步骤\n git clone https://github.com/tensorflow/magenta.git\n git checkout v0.1.15\n bazel-bin/magenta/tools/pip/build_pip_package /data/magenta_pkg\n pip install -U /data/magenta_pkg/magenta-0.1.15-py2-none-any.whl\n\n\nhttps://magenta.tensorflow.org/2016/11/01/multistyle-pastiche-generator\n\n训练自己模型\nFirst, you need to prepare your style images:\n\nbazel-bin/magenta/models/image_stylization/image_stylization_create_dataset --vgg_checkpoint=/Users/haizhu/Downloads/ml/vgg_16.ckpt --style_files=/Users/haizhu/Desktop/jiemo/style/\\*.jpg  --output_file=out/style_images.tfrecord\n\n\nThen, to train a model:\n\nbazel-bin/magenta/models/image_stylization/image_stylization_train --train_dir=out/train --style_dataset_file=out/style_images.tfrecord --num_styles=3 --vgg_checkpoint=/Users/haizhu/Downloads/ml/vgg_16.ckpt --imagenet_data_dir=out/imagenet-tfrecord","feature_image":null,"featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2017-08-21 10:13:32","created_by":"1","updated_at":"2017-09-04 05:54:16","updated_by":"1","published_at":"2017-09-04 05:54:16","published_by":"1","custom_excerpt":null,"codeinjection_head":"","codeinjection_foot":"","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null},{"id":"59a7c9c9f36c876ae083d8b4","uuid":"5fa7f031-5213-452b-9ac4-ebe231bcb826","title":"java 编译时注解","slug":"java-bian-yi-shi-zhu-ru","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"- 自定义注解\\n```\\n@Target({ElementType.METHOD})\\n@Retention(RetentionPolicy.CLASS)\\npublic @interface MyAnnotation {\\n\\tString name() default \\\"\\\";\\n}\\n\\n```\\n\\n- 处理自定义注解\\n需要继承``实现自己的Processor\\n```java\\n@SupportedSourceVersion(SourceVersion.RELEASE_8)\\n@SupportedAnnotationTypes(\\\"com.hai046.inject.MyAnnotation\\\")//自定义注解的 package\\npublic class Hai046Processor extends AbstractProcessor {\\n\\n\\tprivate Messager messager;\\n\\n\\t@Override\\n\\tpublic synchronized void init(ProcessingEnvironment processingEnv) {\\n\\t\\tsuper.init(processingEnv);\\n\\t\\tmessager = processingEnv.getMessager();\\n\\t}\\n\\n\\t/**\\n\\t * 打印\\n\\t *\\n\\t * @param hello\\n\\t */\\n\\tprivate void print(String hello) {\\n\\t\\tmessager.printMessage(Diagnostic.Kind.NOTE, hello);\\n\\t}\\n\\n\\t@Override\\n\\tpublic Set<String> getSupportedAnnotationTypes() {\\n\\t\\tprint(\\\"getSupportedAnnotationTypes\\\");\\n\\t\\treturn Collections.singleton(MyAnnotation.class.getCanonicalName());\\n\\t}\\n\\n\\t@Override\\n\\tpublic boolean process(Set<? extends TypeElement> annotations, RoundEnvironment roundEnv) {\\n\\n\\t\\tSet<? extends Element> elementsAnnotatedWith = roundEnv.getElementsAnnotatedWith(MyAnnotation.class);\\n\\t\\tprint(\\\"获取所有符合自己注解的 elements:\\\" + elementsAnnotatedWith);\\n\\t\\tfor (Element element : elementsAnnotatedWith) {\\n\\n\\t\\t\\tprint(element + \\\" getEnclosingElement=\\\" + element.getEnclosingElement() + \\\" getAnnotationMirrors=\\\"\\n\\t\\t\\t\\t\\t+ element.getAnnotationMirrors() + \\\"  getEnclosedElements=\\\" + element.getEnclosedElements() + \\\" getKind=\\\"\\n\\t\\t\\t\\t\\t+ element.getKind() + \\\"  asType=\\\" + element.asType() + \\\" getModifiers=\\\" + element.getModifiers());\\n\\t\\t}\\n\\t\\treturn false;\\n\\t}\\n\\n\\n}\\n\\n```\\n\\n\\n- 配置信息\\njava在编译时候需要编译，需要配置到 `resources/META-INF/services/javax.annotation.processing.Processor`文件\\n每一行都是自定义processor的package\\n- idea调试\\n需要新建工程，在另外一个工程调试，信息显示在message里面，如果本工程调试配置很麻烦\"}]],\"sections\":[[10,0]]}","html":"<div class=\"kg-card-markdown\"><ul>\n<li>自定义注解</li>\n</ul>\n<pre><code>@Target({ElementType.METHOD})\n@Retention(RetentionPolicy.CLASS)\npublic @interface MyAnnotation {\n\tString name() default &quot;&quot;;\n}\n\n</code></pre>\n<ul>\n<li>处理自定义注解<br>\n需要继承``实现自己的Processor</li>\n</ul>\n<pre><code class=\"language-java\">@SupportedSourceVersion(SourceVersion.RELEASE_8)\n@SupportedAnnotationTypes(&quot;com.hai046.inject.MyAnnotation&quot;)//自定义注解的 package\npublic class Hai046Processor extends AbstractProcessor {\n\n\tprivate Messager messager;\n\n\t@Override\n\tpublic synchronized void init(ProcessingEnvironment processingEnv) {\n\t\tsuper.init(processingEnv);\n\t\tmessager = processingEnv.getMessager();\n\t}\n\n\t/**\n\t * 打印\n\t *\n\t * @param hello\n\t */\n\tprivate void print(String hello) {\n\t\tmessager.printMessage(Diagnostic.Kind.NOTE, hello);\n\t}\n\n\t@Override\n\tpublic Set&lt;String&gt; getSupportedAnnotationTypes() {\n\t\tprint(&quot;getSupportedAnnotationTypes&quot;);\n\t\treturn Collections.singleton(MyAnnotation.class.getCanonicalName());\n\t}\n\n\t@Override\n\tpublic boolean process(Set&lt;? extends TypeElement&gt; annotations, RoundEnvironment roundEnv) {\n\n\t\tSet&lt;? extends Element&gt; elementsAnnotatedWith = roundEnv.getElementsAnnotatedWith(MyAnnotation.class);\n\t\tprint(&quot;获取所有符合自己注解的 elements:&quot; + elementsAnnotatedWith);\n\t\tfor (Element element : elementsAnnotatedWith) {\n\n\t\t\tprint(element + &quot; getEnclosingElement=&quot; + element.getEnclosingElement() + &quot; getAnnotationMirrors=&quot;\n\t\t\t\t\t+ element.getAnnotationMirrors() + &quot;  getEnclosedElements=&quot; + element.getEnclosedElements() + &quot; getKind=&quot;\n\t\t\t\t\t+ element.getKind() + &quot;  asType=&quot; + element.asType() + &quot; getModifiers=&quot; + element.getModifiers());\n\t\t}\n\t\treturn false;\n\t}\n\n\n}\n\n</code></pre>\n<ul>\n<li>配置信息<br>\njava在编译时候需要编译，需要配置到 <code>resources/META-INF/services/javax.annotation.processing.Processor</code>文件<br>\n每一行都是自定义processor的package</li>\n<li>idea调试<br>\n需要新建工程，在另外一个工程调试，信息显示在message里面，如果本工程调试配置很麻烦</li>\n</ul>\n</div>","amp":null,"plaintext":"* 自定义注解\n\n@Target({ElementType.METHOD})\n@Retention(RetentionPolicy.CLASS)\npublic @interface MyAnnotation {\n\tString name() default \"\";\n}\n\n\n\n * 处理自定义注解\n   需要继承``实现自己的Processor\n\n@SupportedSourceVersion(SourceVersion.RELEASE_8)\n@SupportedAnnotationTypes(\"com.hai046.inject.MyAnnotation\")//自定义注解的 package\npublic class Hai046Processor extends AbstractProcessor {\n\n\tprivate Messager messager;\n\n\t@Override\n\tpublic synchronized void init(ProcessingEnvironment processingEnv) {\n\t\tsuper.init(processingEnv);\n\t\tmessager = processingEnv.getMessager();\n\t}\n\n\t/**\n\t * 打印\n\t *\n\t * @param hello\n\t */\n\tprivate void print(String hello) {\n\t\tmessager.printMessage(Diagnostic.Kind.NOTE, hello);\n\t}\n\n\t@Override\n\tpublic Set<String> getSupportedAnnotationTypes() {\n\t\tprint(\"getSupportedAnnotationTypes\");\n\t\treturn Collections.singleton(MyAnnotation.class.getCanonicalName());\n\t}\n\n\t@Override\n\tpublic boolean process(Set<? extends TypeElement> annotations, RoundEnvironment roundEnv) {\n\n\t\tSet<? extends Element> elementsAnnotatedWith = roundEnv.getElementsAnnotatedWith(MyAnnotation.class);\n\t\tprint(\"获取所有符合自己注解的 elements:\" + elementsAnnotatedWith);\n\t\tfor (Element element : elementsAnnotatedWith) {\n\n\t\t\tprint(element + \" getEnclosingElement=\" + element.getEnclosingElement() + \" getAnnotationMirrors=\"\n\t\t\t\t\t+ element.getAnnotationMirrors() + \"  getEnclosedElements=\" + element.getEnclosedElements() + \" getKind=\"\n\t\t\t\t\t+ element.getKind() + \"  asType=\" + element.asType() + \" getModifiers=\" + element.getModifiers());\n\t\t}\n\t\treturn false;\n\t}\n\n\n}\n\n\n\n * 配置信息\n   java在编译时候需要编译，需要配置到 \n   resources/META-INF/services/javax.annotation.processing.Processor文件\n   每一行都是自定义processor的package\n * idea调试\n   需要新建工程，在另外一个工程调试，信息显示在message里面，如果本工程调试配置很麻烦","feature_image":null,"featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2017-08-31 08:33:13","created_by":"1","updated_at":"2017-08-31 08:45:23","updated_by":"1","published_at":"2017-08-31 08:45:23","published_by":"1","custom_excerpt":null,"codeinjection_head":"","codeinjection_foot":"","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null},{"id":"59a7ccc6f36c876ae083d8b9","uuid":"981846e9-fdce-464c-b438-aabfe386d140","title":"spring HandlerMethodReturnValueHandler 配置","slug":"spring","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"- 声明\\n在xml里面声明\\n```\\n    <bean class=\\\"org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter\\\">\\n        <property name=\\\"customReturnValueHandlers\\\">\\n            <list>\\n                <bean class=\\\"xx.xx.xxHandlerMethodReturnValueHandler\\\"/>\\n            </list>\\n\\n        </property>\\n    </bean>\\n```\\n配置`customReturnValueHandlers`接口\\n- 实现类\\n```\\npublic class xxHandlerMethodReturnValueHandler implements HandlerMethodReturnValueHandler {\\n  private static Logger logger = LoggerFactory.getLogger(xxHandlerMethodReturnValueHandler.class);\\n\\n  @Override\\n  public boolean supportsReturnType(MethodParameter returnType) {\\n    //返回true才回拦截\\n    return returnType.getMethodAnnotation(XXAnnotation.class) != null;\\n  }\\n\\n  @Override\\n  public void handleReturnValue(\\n      Object returnValue,\\n      MethodParameter returnType,\\n      ModelAndViewContainer mavContainer,\\n      NativeWebRequest webRequest)\\n      throws Exception {\\n    logger.info(\\n        \\\"==========================returnValue={} returnType={} mavContainer={} webRequest={}\\\",\\n       \\n        webRequest);\\n  }\\n}\\n\\n```\\n- 坑\\n注意不能拦截spring已有的model，因为查看源码可知，每个model只能有一个handler拦截，用完立刻return了， 不用想一个model拦截几次，然后分步处理\"}]],\"sections\":[[10,0]]}","html":"<div class=\"kg-card-markdown\"><ul>\n<li>声明<br>\n在xml里面声明</li>\n</ul>\n<pre><code>    &lt;bean class=&quot;org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter&quot;&gt;\n        &lt;property name=&quot;customReturnValueHandlers&quot;&gt;\n            &lt;list&gt;\n                &lt;bean class=&quot;xx.xx.xxHandlerMethodReturnValueHandler&quot;/&gt;\n            &lt;/list&gt;\n\n        &lt;/property&gt;\n    &lt;/bean&gt;\n</code></pre>\n<p>配置<code>customReturnValueHandlers</code>接口</p>\n<ul>\n<li>实现类</li>\n</ul>\n<pre><code>public class xxHandlerMethodReturnValueHandler implements HandlerMethodReturnValueHandler {\n  private static Logger logger = LoggerFactory.getLogger(xxHandlerMethodReturnValueHandler.class);\n\n  @Override\n  public boolean supportsReturnType(MethodParameter returnType) {\n    //返回true才回拦截\n    return returnType.getMethodAnnotation(XXAnnotation.class) != null;\n  }\n\n  @Override\n  public void handleReturnValue(\n      Object returnValue,\n      MethodParameter returnType,\n      ModelAndViewContainer mavContainer,\n      NativeWebRequest webRequest)\n      throws Exception {\n    logger.info(\n        &quot;==========================returnValue={} returnType={} mavContainer={} webRequest={}&quot;,\n       \n        webRequest);\n  }\n}\n\n</code></pre>\n<ul>\n<li>坑<br>\n注意不能拦截spring已有的model，因为查看源码可知，每个model只能有一个handler拦截，用完立刻return了， 不用想一个model拦截几次，然后分步处理</li>\n</ul>\n</div>","amp":null,"plaintext":"* 声明\n   在xml里面声明\n\n    <bean class=\"org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter\">\n        <property name=\"customReturnValueHandlers\">\n            <list>\n                <bean class=\"xx.xx.xxHandlerMethodReturnValueHandler\"/>\n            </list>\n\n        </property>\n    </bean>\n\n\n配置customReturnValueHandlers接口\n\n * 实现类\n\npublic class xxHandlerMethodReturnValueHandler implements HandlerMethodReturnValueHandler {\n  private static Logger logger = LoggerFactory.getLogger(xxHandlerMethodReturnValueHandler.class);\n\n  @Override\n  public boolean supportsReturnType(MethodParameter returnType) {\n    //返回true才回拦截\n    return returnType.getMethodAnnotation(XXAnnotation.class) != null;\n  }\n\n  @Override\n  public void handleReturnValue(\n      Object returnValue,\n      MethodParameter returnType,\n      ModelAndViewContainer mavContainer,\n      NativeWebRequest webRequest)\n      throws Exception {\n    logger.info(\n        \"==========================returnValue={} returnType={} mavContainer={} webRequest={}\",\n       \n        webRequest);\n  }\n}\n\n\n\n * 坑\n   注意不能拦截spring已有的model，因为查看源码可知，每个model只能有一个handler拦截，用完立刻return了，\n   不用想一个model拦截几次，然后分步处理","feature_image":null,"featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2017-08-31 08:45:58","created_by":"1","updated_at":"2017-08-31 08:52:33","updated_by":"1","published_at":"2017-08-31 08:52:33","published_by":"1","custom_excerpt":null,"codeinjection_head":"","codeinjection_foot":"","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null},{"id":"59afbb28ea7269021be3e701","uuid":"8acb4572-bd6a-4929-b839-819c1f0ad6e8","title":"golang 实现企业微信管理API","slug":"golang-shi-xian","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"### 说明\\n[本项目对应code](https://github.com/hai046/workweixin-go)\\n\\n[企业微信api doc](https://work.weixin.qq.com/api/doc)\\n\\n### 实现\\n1. 实现了部门相关api\\n2. 实现了tag相关api\\n3. 实现了获取用户相关api\\n4. 实现发送聊天相关api\\n5. 实现了手机号对应user转换\\n\\n注意：因为企业微信不同的功能对应不同的应用，不同的应用agentId 和secert是不一样的，故调用api时候请按照官方说明调用对应方法即可\\n\\n\\n\"}]],\"sections\":[[10,0]]}","html":"<div class=\"kg-card-markdown\"><h3 id=\"\">说明</h3>\n<p><a href=\"https://github.com/hai046/workweixin-go\">本项目对应code</a></p>\n<p><a href=\"https://work.weixin.qq.com/api/doc\">企业微信api doc</a></p>\n<h3 id=\"\">实现</h3>\n<ol>\n<li>实现了部门相关api</li>\n<li>实现了tag相关api</li>\n<li>实现了获取用户相关api</li>\n<li>实现发送聊天相关api</li>\n<li>实现了手机号对应user转换</li>\n</ol>\n<p>注意：因为企业微信不同的功能对应不同的应用，不同的应用agentId 和secert是不一样的，故调用api时候请按照官方说明调用对应方法即可</p>\n</div>","amp":null,"plaintext":"说明\n本项目对应code [https://github.com/hai046/workweixin-go]\n\n企业微信api doc [https://work.weixin.qq.com/api/doc]\n\n实现\n 1. 实现了部门相关api\n 2. 实现了tag相关api\n 3. 实现了获取用户相关api\n 4. 实现发送聊天相关api\n 5. 实现了手机号对应user转换\n\n注意：因为企业微信不同的功能对应不同的应用，不同的应用agentId 和secert是不一样的，故调用api时候请按照官方说明调用对应方法即可","feature_image":null,"featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2017-09-06 09:08:56","created_by":"1","updated_at":"2017-09-06 09:13:14","updated_by":"1","published_at":"2017-09-06 09:13:14","published_by":"1","custom_excerpt":null,"codeinjection_head":"","codeinjection_foot":"","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null},{"id":"59b22fe8ea7269021be3e708","uuid":"6eca9b49-489d-4045-bfda-2b4508150189","title":"leetcode","slug":"leetcode","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"## 说明\\n此为刷题记录，是自己写的测试过的，不是官方给的答案啊\\n\\n### two_sum\\n\\thttps://leetcode.com/problems/two-sum/description/\\n\\n```\\nclass Solution {\\n\\tpublic int[] twoSum(int[] nums, int target) {\\n\\t\\tMap<Integer, Integer> map = new HashMap<>(nums.length);\\n\\n\\t\\tInteger halfTarget = null;\\n\\t\\tif (target % 2 == 0) {\\n\\t\\t\\thalfTarget = target >> 1;\\n\\t\\t}\\n\\n\\t\\tint max = 0;\\n\\t\\tint min = 0;\\n\\n\\t\\tfor (int i = nums.length - 1; i >= 0; i--) {\\n\\t\\t\\tint v = nums[i];\\n\\t\\t\\tif (halfTarget != null && halfTarget == v && map.containsKey(v)) {\\n\\t\\t\\t\\treturn new int[]{i, map.get(v)};\\n\\t\\t\\t}\\n\\t\\t\\tmap.put(v, i);\\n\\t\\t\\tif (v > max) {\\n\\t\\t\\t\\tmax = v;\\n\\t\\t\\t}\\n\\t\\t\\tif (v < min) {\\n\\t\\t\\t\\tmin = v;\\n\\t\\t\\t}\\n\\t\\t}\\n\\n\\t\\tif (max > target / 2) {\\n\\t\\t\\tmax = target / 2;\\n\\t\\t}\\n\\n\\t\\tfor (int i = min; i < max; i++) {\\n\\t\\t\\tInteger n1 = map.get(i);\\n\\t\\t\\tInteger n2 = map.get(target - i);\\n\\n\\t\\t\\tif (n1 != null && n2 != null) {\\n\\t\\t\\t\\treturn new int[]{n1, n2};\\n\\t\\t\\t}\\n\\t\\t}\\n\\t\\treturn null;\\n\\t}\\n```\\n总结：超过63.3%提交者 虽然通过，但是还是简单，其实一个循环就好，不过我认为\\n### add_two_numbers\\nhttps://leetcode.com/problems/add-two-numbers/description/\\n题目难理解，其他还好\\n```\\npublic class ListNode {\\n\\t\\tint val;\\n\\t\\tListNode next;\\n\\n\\t\\tListNode(int x) {\\n\\t\\t\\tval = x;\\n\\t\\t}\\n\\t}\\n\\n\\tclass Solution {\\n\\t\\tpublic ListNode addTwoNumbers(ListNode l1, ListNode l2) {\\n\\n\\t\\t\\tListNode tmp;\\n\\t\\t\\tListNode firstNode = null;\\n\\n\\t\\t\\tListNode currentNode = null;\\n\\t\\t\\tint count = 0;\\n\\n\\t\\t\\tif (l1 != null || l2 != null) {\\n\\t\\t\\t\\tcount = (l1 != null ? l1.val : 0) + (l2 != null ? l2.val : 0);\\n\\t\\t\\t\\tfirstNode = new ListNode(count % 10);\\n\\t\\t\\t\\tcount = count / 10;\\n\\t\\t\\t\\tcurrentNode = firstNode;\\n\\t\\t\\t\\tl1 = l1 != null ? l1.next : null;\\n\\t\\t\\t\\tl2 = l2 != null ? l2.next : null;\\n\\t\\t\\t}\\n\\n\\t\\t\\twhile (l1 != null || l2 != null) {\\n\\t\\t\\t\\tcount += count + (l1 != null ? l1.val : 0) + (l2 != null ? l2.val : 0);\\n\\t\\t\\t\\ttmp = new ListNode(count % 10);\\n\\t\\t\\t\\tcount = count / 10;\\n\\t\\t\\t\\tcurrentNode.next = tmp;\\n\\t\\t\\t\\tl1 = l1 != null ? l1.next : null;\\n\\t\\t\\t\\tl2 = l2 != null ? l2.next : null;\\n\\t\\t\\t\\tcurrentNode = tmp;\\n\\t\\t\\t}\\n\\n\\t\\t\\tif (count > 0) {\\n\\t\\t\\t\\ttmp = new ListNode(count);\\n\\t\\t\\t\\tcurrentNode.next = tmp;\\n\\t\\t\\t}\\n\\n\\t\\t\\treturn firstNode;\\n\\t\\t}\\n\\t}\\n\\n```\\n\\n总结：超过72.37%提交者  答案是第一值为0 莫名其妙\\n\\n### Longest Substring Without Repeating Characters\\n\\n\\tpublic int lengthOfLongestSubstring(String s) {\\n\\t\\tString answer = null;\\n\\n\\t\\tif (s == null) {\\n\\t\\t\\tSystem.out.println(answer);\\n\\t\\t\\treturn 0;\\n\\t\\t}\\n\\n\\t\\tchar[] chars = s.toCharArray();\\n\\t\\tif (chars.length == 1) {\\n\\t\\t\\tanswer = s;\\n\\t\\t\\tSystem.out.println(answer);\\n\\t\\t\\treturn 1;\\n\\t\\t}\\n\\t\\tMap<Character, Integer> map = new HashMap<>(chars.length);\\n\\n\\t\\tint startIndex = 0;\\n\\t\\tint max = 0;\\n\\t\\tint endIndex = 0;\\n\\t\\tfor (int i = 0; i < chars.length; i++) {\\n\\t\\t\\tchar c = chars[i];\\n\\t\\t\\tInteger index = map.get(c);\\n\\t\\t\\tif (index != null) {\\n\\t\\t\\t\\tif (startIndex < index + 1) {//这里可能漏掉\\n\\t\\t\\t\\t\\tstartIndex = index + 1;\\n\\t\\t\\t\\t}\\n\\t\\t\\t\\tendIndex = i + (index < startIndex ? 1 : 0);//如果\\\"tmmzuxt\\\"\\n\\t\\t\\t} else {\\n\\t\\t\\t\\tendIndex = i + 1;\\n\\t\\t\\t}\\n\\t\\t\\tif (endIndex - startIndex > max) {\\n\\t\\t\\t\\tmax = endIndex - startIndex;\\n\\t\\t\\t\\tanswer = s.substring(startIndex, endIndex);\\n\\t\\t\\t}\\n\\n\\t\\t\\tmap.put(c, i);\\n\\t\\t}\\n\\t\\tSystem.out.println(answer);\\n\\t\\treturn max;\\n\\t}\\n    \\n  总结：超过13%提交者  我靠漏掉了很多情况开始，还有点没理解他的意思，如果不输出结果的话，可以优化很多\\n  \\n \\n### Median of Two Sorted Arrays\\n\\n```\\n\\n```\\n\\n总结：超过13%提交者  我靠漏掉了很多情况开始，还有点没理解他的意思，如果不输出结果的话，可以优化很多\\n \"}]],\"sections\":[[10,0]]}","html":"<div class=\"kg-card-markdown\"><h2 id=\"\">说明</h2>\n<p>此为刷题记录，是自己写的测试过的，不是官方给的答案啊</p>\n<h3 id=\"two_sum\">two_sum</h3>\n<pre><code>https://leetcode.com/problems/two-sum/description/\n</code></pre>\n<pre><code>class Solution {\n\tpublic int[] twoSum(int[] nums, int target) {\n\t\tMap&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(nums.length);\n\n\t\tInteger halfTarget = null;\n\t\tif (target % 2 == 0) {\n\t\t\thalfTarget = target &gt;&gt; 1;\n\t\t}\n\n\t\tint max = 0;\n\t\tint min = 0;\n\n\t\tfor (int i = nums.length - 1; i &gt;= 0; i--) {\n\t\t\tint v = nums[i];\n\t\t\tif (halfTarget != null &amp;&amp; halfTarget == v &amp;&amp; map.containsKey(v)) {\n\t\t\t\treturn new int[]{i, map.get(v)};\n\t\t\t}\n\t\t\tmap.put(v, i);\n\t\t\tif (v &gt; max) {\n\t\t\t\tmax = v;\n\t\t\t}\n\t\t\tif (v &lt; min) {\n\t\t\t\tmin = v;\n\t\t\t}\n\t\t}\n\n\t\tif (max &gt; target / 2) {\n\t\t\tmax = target / 2;\n\t\t}\n\n\t\tfor (int i = min; i &lt; max; i++) {\n\t\t\tInteger n1 = map.get(i);\n\t\t\tInteger n2 = map.get(target - i);\n\n\t\t\tif (n1 != null &amp;&amp; n2 != null) {\n\t\t\t\treturn new int[]{n1, n2};\n\t\t\t}\n\t\t}\n\t\treturn null;\n\t}\n</code></pre>\n<p>总结：超过63.3%提交者 虽然通过，但是还是简单，其实一个循环就好，不过我认为</p>\n<h3 id=\"add_two_numbers\">add_two_numbers</h3>\n<p><a href=\"https://leetcode.com/problems/add-two-numbers/description/\">https://leetcode.com/problems/add-two-numbers/description/</a><br>\n题目难理解，其他还好</p>\n<pre><code>public class ListNode {\n\t\tint val;\n\t\tListNode next;\n\n\t\tListNode(int x) {\n\t\t\tval = x;\n\t\t}\n\t}\n\n\tclass Solution {\n\t\tpublic ListNode addTwoNumbers(ListNode l1, ListNode l2) {\n\n\t\t\tListNode tmp;\n\t\t\tListNode firstNode = null;\n\n\t\t\tListNode currentNode = null;\n\t\t\tint count = 0;\n\n\t\t\tif (l1 != null || l2 != null) {\n\t\t\t\tcount = (l1 != null ? l1.val : 0) + (l2 != null ? l2.val : 0);\n\t\t\t\tfirstNode = new ListNode(count % 10);\n\t\t\t\tcount = count / 10;\n\t\t\t\tcurrentNode = firstNode;\n\t\t\t\tl1 = l1 != null ? l1.next : null;\n\t\t\t\tl2 = l2 != null ? l2.next : null;\n\t\t\t}\n\n\t\t\twhile (l1 != null || l2 != null) {\n\t\t\t\tcount += count + (l1 != null ? l1.val : 0) + (l2 != null ? l2.val : 0);\n\t\t\t\ttmp = new ListNode(count % 10);\n\t\t\t\tcount = count / 10;\n\t\t\t\tcurrentNode.next = tmp;\n\t\t\t\tl1 = l1 != null ? l1.next : null;\n\t\t\t\tl2 = l2 != null ? l2.next : null;\n\t\t\t\tcurrentNode = tmp;\n\t\t\t}\n\n\t\t\tif (count &gt; 0) {\n\t\t\t\ttmp = new ListNode(count);\n\t\t\t\tcurrentNode.next = tmp;\n\t\t\t}\n\n\t\t\treturn firstNode;\n\t\t}\n\t}\n\n</code></pre>\n<p>总结：超过72.37%提交者  答案是第一值为0 莫名其妙</p>\n<h3 id=\"longestsubstringwithoutrepeatingcharacters\">Longest Substring Without Repeating Characters</h3>\n<pre><code>public int lengthOfLongestSubstring(String s) {\n\tString answer = null;\n\n\tif (s == null) {\n\t\tSystem.out.println(answer);\n\t\treturn 0;\n\t}\n\n\tchar[] chars = s.toCharArray();\n\tif (chars.length == 1) {\n\t\tanswer = s;\n\t\tSystem.out.println(answer);\n\t\treturn 1;\n\t}\n\tMap&lt;Character, Integer&gt; map = new HashMap&lt;&gt;(chars.length);\n\n\tint startIndex = 0;\n\tint max = 0;\n\tint endIndex = 0;\n\tfor (int i = 0; i &lt; chars.length; i++) {\n\t\tchar c = chars[i];\n\t\tInteger index = map.get(c);\n\t\tif (index != null) {\n\t\t\tif (startIndex &lt; index + 1) {//这里可能漏掉\n\t\t\t\tstartIndex = index + 1;\n\t\t\t}\n\t\t\tendIndex = i + (index &lt; startIndex ? 1 : 0);//如果&quot;tmmzuxt&quot;\n\t\t} else {\n\t\t\tendIndex = i + 1;\n\t\t}\n\t\tif (endIndex - startIndex &gt; max) {\n\t\t\tmax = endIndex - startIndex;\n\t\t\tanswer = s.substring(startIndex, endIndex);\n\t\t}\n\n\t\tmap.put(c, i);\n\t}\n\tSystem.out.println(answer);\n\treturn max;\n}\n</code></pre>\n<p>总结：超过13%提交者  我靠漏掉了很多情况开始，还有点没理解他的意思，如果不输出结果的话，可以优化很多</p>\n<h3 id=\"medianoftwosortedarrays\">Median of Two Sorted Arrays</h3>\n<pre><code>\n</code></pre>\n<p>总结：超过13%提交者  我靠漏掉了很多情况开始，还有点没理解他的意思，如果不输出结果的话，可以优化很多</p>\n</div>","amp":null,"plaintext":"说明\n此为刷题记录，是自己写的测试过的，不是官方给的答案啊\n\ntwo_sum\nhttps://leetcode.com/problems/two-sum/description/\n\n\nclass Solution {\n\tpublic int[] twoSum(int[] nums, int target) {\n\t\tMap<Integer, Integer> map = new HashMap<>(nums.length);\n\n\t\tInteger halfTarget = null;\n\t\tif (target % 2 == 0) {\n\t\t\thalfTarget = target >> 1;\n\t\t}\n\n\t\tint max = 0;\n\t\tint min = 0;\n\n\t\tfor (int i = nums.length - 1; i >= 0; i--) {\n\t\t\tint v = nums[i];\n\t\t\tif (halfTarget != null && halfTarget == v && map.containsKey(v)) {\n\t\t\t\treturn new int[]{i, map.get(v)};\n\t\t\t}\n\t\t\tmap.put(v, i);\n\t\t\tif (v > max) {\n\t\t\t\tmax = v;\n\t\t\t}\n\t\t\tif (v < min) {\n\t\t\t\tmin = v;\n\t\t\t}\n\t\t}\n\n\t\tif (max > target / 2) {\n\t\t\tmax = target / 2;\n\t\t}\n\n\t\tfor (int i = min; i < max; i++) {\n\t\t\tInteger n1 = map.get(i);\n\t\t\tInteger n2 = map.get(target - i);\n\n\t\t\tif (n1 != null && n2 != null) {\n\t\t\t\treturn new int[]{n1, n2};\n\t\t\t}\n\t\t}\n\t\treturn null;\n\t}\n\n\n总结：超过63.3%提交者 虽然通过，但是还是简单，其实一个循环就好，不过我认为\n\nadd_two_numbers\nhttps://leetcode.com/problems/add-two-numbers/description/\n题目难理解，其他还好\n\npublic class ListNode {\n\t\tint val;\n\t\tListNode next;\n\n\t\tListNode(int x) {\n\t\t\tval = x;\n\t\t}\n\t}\n\n\tclass Solution {\n\t\tpublic ListNode addTwoNumbers(ListNode l1, ListNode l2) {\n\n\t\t\tListNode tmp;\n\t\t\tListNode firstNode = null;\n\n\t\t\tListNode currentNode = null;\n\t\t\tint count = 0;\n\n\t\t\tif (l1 != null || l2 != null) {\n\t\t\t\tcount = (l1 != null ? l1.val : 0) + (l2 != null ? l2.val : 0);\n\t\t\t\tfirstNode = new ListNode(count % 10);\n\t\t\t\tcount = count / 10;\n\t\t\t\tcurrentNode = firstNode;\n\t\t\t\tl1 = l1 != null ? l1.next : null;\n\t\t\t\tl2 = l2 != null ? l2.next : null;\n\t\t\t}\n\n\t\t\twhile (l1 != null || l2 != null) {\n\t\t\t\tcount += count + (l1 != null ? l1.val : 0) + (l2 != null ? l2.val : 0);\n\t\t\t\ttmp = new ListNode(count % 10);\n\t\t\t\tcount = count / 10;\n\t\t\t\tcurrentNode.next = tmp;\n\t\t\t\tl1 = l1 != null ? l1.next : null;\n\t\t\t\tl2 = l2 != null ? l2.next : null;\n\t\t\t\tcurrentNode = tmp;\n\t\t\t}\n\n\t\t\tif (count > 0) {\n\t\t\t\ttmp = new ListNode(count);\n\t\t\t\tcurrentNode.next = tmp;\n\t\t\t}\n\n\t\t\treturn firstNode;\n\t\t}\n\t}\n\n\n\n总结：超过72.37%提交者 答案是第一值为0 莫名其妙\n\nLongest Substring Without Repeating Characters\npublic int lengthOfLongestSubstring(String s) {\n\tString answer = null;\n\n\tif (s == null) {\n\t\tSystem.out.println(answer);\n\t\treturn 0;\n\t}\n\n\tchar[] chars = s.toCharArray();\n\tif (chars.length == 1) {\n\t\tanswer = s;\n\t\tSystem.out.println(answer);\n\t\treturn 1;\n\t}\n\tMap<Character, Integer> map = new HashMap<>(chars.length);\n\n\tint startIndex = 0;\n\tint max = 0;\n\tint endIndex = 0;\n\tfor (int i = 0; i < chars.length; i++) {\n\t\tchar c = chars[i];\n\t\tInteger index = map.get(c);\n\t\tif (index != null) {\n\t\t\tif (startIndex < index + 1) {//这里可能漏掉\n\t\t\t\tstartIndex = index + 1;\n\t\t\t}\n\t\t\tendIndex = i + (index < startIndex ? 1 : 0);//如果\"tmmzuxt\"\n\t\t} else {\n\t\t\tendIndex = i + 1;\n\t\t}\n\t\tif (endIndex - startIndex > max) {\n\t\t\tmax = endIndex - startIndex;\n\t\t\tanswer = s.substring(startIndex, endIndex);\n\t\t}\n\n\t\tmap.put(c, i);\n\t}\n\tSystem.out.println(answer);\n\treturn max;\n}\n\n\n总结：超过13%提交者 我靠漏掉了很多情况开始，还有点没理解他的意思，如果不输出结果的话，可以优化很多\n\nMedian of Two Sorted Arrays\n\n\n\n总结：超过13%提交者 我靠漏掉了很多情况开始，还有点没理解他的意思，如果不输出结果的话，可以优化很多","feature_image":null,"featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2017-09-08 05:51:36","created_by":"1","updated_at":"2017-10-09 03:15:27","updated_by":"1","published_at":"2017-10-09 03:15:25","published_by":"1","custom_excerpt":null,"codeinjection_head":"","codeinjection_foot":"","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null}],"users":[{"id":"1","name":"hai046","slug":"hai046","ghost_auth_access_token":null,"ghost_auth_id":null,"password":"$2a$10$.eFhR.Bh9IoRD21xblaU2uHcCIQUrQtO.aiC85dIsgHNPwsB/cbYm","email":"haizhu12345@gmail.com","profile_image":"/content/images/2017/08/1.png","cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"accessibility":"{\"nightShift\":false}","status":"active","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"tour":"[\"getting-started\",\"using-the-editor\",\"static-post\",\"featured-post\",\"upload-a-theme\"]","last_seen":"2017-10-09 03:26:06","created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-10-09 03:26:06","updated_by":"1"},{"id":"5951f5fca366002ebd5dbef7","name":"Ghost","slug":"ghost","ghost_auth_access_token":null,"ghost_auth_id":null,"password":"$2a$10$xE08vsqeDuZxoK5wXbZJWOw4jWw8VG3vNlT7YDQTOeTt4UQcY7AtO","email":"ghost-author@example.com","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"accessibility":null,"status":"active","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"tour":null,"last_seen":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59829a58616dac5789b9fa19","name":"scoop","slug":"scoop","ghost_auth_access_token":null,"ghost_auth_id":null,"password":"$2a$10$Yh2s74TKOCxNQYATZoUGeO3JFVrk.Y0995zsvvZvx2IxQ1UdQEr32","email":"longscoop@gmail.com","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"accessibility":null,"status":"active","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"tour":null,"last_seen":"2017-08-03 03:36:56","created_at":"2017-08-03 03:36:56","created_by":"1","updated_at":"2017-08-03 03:36:56","updated_by":"59829a58616dac5789b9fa19"},{"id":"59829ac7616dac5789b9fa1d","name":"Mr's Ma","slug":"mrs","ghost_auth_access_token":null,"ghost_auth_id":null,"password":"$2a$10$oDCYSireND.WmnxBXTPpB.ergAJ7hObOY.NHdnlA0iPcFm2Ywqw96","email":"xiaomapds@163.com","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"accessibility":null,"status":"active","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"tour":null,"last_seen":"2017-08-03 03:38:48","created_at":"2017-08-03 03:38:47","created_by":"1","updated_at":"2017-08-03 03:38:48","updated_by":"59829ac7616dac5789b9fa1d"}],"roles":[{"id":"59805314cc08c852733d222d","name":"Administrator","description":"Administrators","created_at":"2017-08-01 10:08:20","created_by":"1","updated_at":"2017-08-01 10:08:20","updated_by":"1"},{"id":"59805314cc08c852733d222e","name":"Editor","description":"Editors","created_at":"2017-08-01 10:08:20","created_by":"1","updated_at":"2017-08-01 10:08:20","updated_by":"1"},{"id":"59805314cc08c852733d222f","name":"Author","description":"Authors","created_at":"2017-08-01 10:08:20","created_by":"1","updated_at":"2017-08-01 10:08:20","updated_by":"1"},{"id":"59805314cc08c852733d2230","name":"Owner","description":"Blog Owner","created_at":"2017-08-01 10:08:20","created_by":"1","updated_at":"2017-08-01 10:08:20","updated_by":"1"}],"roles_users":[{"id":"59805315cc08c852733d2262","role_id":"59805314cc08c852733d222f","user_id":"5951f5fca366002ebd5dbef7"},{"id":"59805316cc08c852733d22cc","role_id":"59805314cc08c852733d2230","user_id":"1"},{"id":"59829a58616dac5789b9fa1a","role_id":"59805314cc08c852733d222e","user_id":"59829a58616dac5789b9fa19"},{"id":"59829ac8616dac5789b9fa1e","role_id":"59805314cc08c852733d222e","user_id":"59829ac7616dac5789b9fa1d"}],"permissions":[{"id":"59805314cc08c852733d2231","name":"Export database","object_type":"db","action_type":"exportContent","object_id":null,"created_at":"2017-08-01 10:08:20","created_by":"1","updated_at":"2017-08-01 10:08:20","updated_by":"1"},{"id":"59805314cc08c852733d2232","name":"Import database","object_type":"db","action_type":"importContent","object_id":null,"created_at":"2017-08-01 10:08:20","created_by":"1","updated_at":"2017-08-01 10:08:20","updated_by":"1"},{"id":"59805314cc08c852733d2233","name":"Delete all content","object_type":"db","action_type":"deleteAllContent","object_id":null,"created_at":"2017-08-01 10:08:20","created_by":"1","updated_at":"2017-08-01 10:08:20","updated_by":"1"},{"id":"59805314cc08c852733d2234","name":"Send mail","object_type":"mail","action_type":"send","object_id":null,"created_at":"2017-08-01 10:08:20","created_by":"1","updated_at":"2017-08-01 10:08:20","updated_by":"1"},{"id":"59805315cc08c852733d2235","name":"Browse notifications","object_type":"notification","action_type":"browse","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d2236","name":"Add notifications","object_type":"notification","action_type":"add","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d2237","name":"Delete notifications","object_type":"notification","action_type":"destroy","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d2238","name":"Browse posts","object_type":"post","action_type":"browse","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d2239","name":"Read posts","object_type":"post","action_type":"read","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d223a","name":"Edit posts","object_type":"post","action_type":"edit","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d223b","name":"Add posts","object_type":"post","action_type":"add","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d223c","name":"Delete posts","object_type":"post","action_type":"destroy","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d223d","name":"Browse settings","object_type":"setting","action_type":"browse","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d223e","name":"Read settings","object_type":"setting","action_type":"read","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d223f","name":"Edit settings","object_type":"setting","action_type":"edit","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d2240","name":"Generate slugs","object_type":"slug","action_type":"generate","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d2241","name":"Browse tags","object_type":"tag","action_type":"browse","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d2242","name":"Read tags","object_type":"tag","action_type":"read","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d2243","name":"Edit tags","object_type":"tag","action_type":"edit","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d2244","name":"Add tags","object_type":"tag","action_type":"add","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d2245","name":"Delete tags","object_type":"tag","action_type":"destroy","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d2246","name":"Browse themes","object_type":"theme","action_type":"browse","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d2247","name":"Edit themes","object_type":"theme","action_type":"edit","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d2248","name":"Activate themes","object_type":"theme","action_type":"activate","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d2249","name":"Upload themes","object_type":"theme","action_type":"add","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d224a","name":"Download themes","object_type":"theme","action_type":"read","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d224b","name":"Delete themes","object_type":"theme","action_type":"destroy","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d224c","name":"Browse users","object_type":"user","action_type":"browse","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d224d","name":"Read users","object_type":"user","action_type":"read","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d224e","name":"Edit users","object_type":"user","action_type":"edit","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d224f","name":"Add users","object_type":"user","action_type":"add","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d2250","name":"Delete users","object_type":"user","action_type":"destroy","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d2251","name":"Assign a role","object_type":"role","action_type":"assign","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d2252","name":"Browse roles","object_type":"role","action_type":"browse","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d2253","name":"Browse clients","object_type":"client","action_type":"browse","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d2254","name":"Read clients","object_type":"client","action_type":"read","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d2255","name":"Edit clients","object_type":"client","action_type":"edit","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d2256","name":"Add clients","object_type":"client","action_type":"add","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d2257","name":"Delete clients","object_type":"client","action_type":"destroy","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d2258","name":"Browse subscribers","object_type":"subscriber","action_type":"browse","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d2259","name":"Read subscribers","object_type":"subscriber","action_type":"read","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d225a","name":"Edit subscribers","object_type":"subscriber","action_type":"edit","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d225b","name":"Add subscribers","object_type":"subscriber","action_type":"add","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d225c","name":"Delete subscribers","object_type":"subscriber","action_type":"destroy","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d225d","name":"Browse invites","object_type":"invite","action_type":"browse","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d225e","name":"Read invites","object_type":"invite","action_type":"read","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d225f","name":"Edit invites","object_type":"invite","action_type":"edit","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d2260","name":"Add invites","object_type":"invite","action_type":"add","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"},{"id":"59805315cc08c852733d2261","name":"Delete invites","object_type":"invite","action_type":"destroy","object_id":null,"created_at":"2017-08-01 10:08:21","created_by":"1","updated_at":"2017-08-01 10:08:21","updated_by":"1"}],"permissions_users":[],"permissions_roles":[{"id":"59805315cc08c852733d2263","role_id":"59805314cc08c852733d222d","permission_id":"59805314cc08c852733d2231"},{"id":"59805315cc08c852733d2264","role_id":"59805314cc08c852733d222d","permission_id":"59805314cc08c852733d2232"},{"id":"59805315cc08c852733d2265","role_id":"59805314cc08c852733d222d","permission_id":"59805314cc08c852733d2233"},{"id":"59805315cc08c852733d2266","role_id":"59805314cc08c852733d222d","permission_id":"59805314cc08c852733d2234"},{"id":"59805315cc08c852733d2267","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d2235"},{"id":"59805315cc08c852733d2268","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d2236"},{"id":"59805315cc08c852733d2269","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d2237"},{"id":"59805315cc08c852733d226a","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d2238"},{"id":"59805315cc08c852733d226b","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d2239"},{"id":"59805315cc08c852733d226c","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d223a"},{"id":"59805315cc08c852733d226d","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d223b"},{"id":"59805315cc08c852733d226e","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d223c"},{"id":"59805315cc08c852733d226f","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d223d"},{"id":"59805315cc08c852733d2270","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d223e"},{"id":"59805315cc08c852733d2271","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d223f"},{"id":"59805315cc08c852733d2272","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d2240"},{"id":"59805315cc08c852733d2273","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d2241"},{"id":"59805315cc08c852733d2274","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d2242"},{"id":"59805315cc08c852733d2275","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d2243"},{"id":"59805315cc08c852733d2276","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d2244"},{"id":"59805315cc08c852733d2277","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d2245"},{"id":"59805315cc08c852733d2278","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d2246"},{"id":"59805315cc08c852733d2279","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d2247"},{"id":"59805315cc08c852733d227a","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d2248"},{"id":"59805315cc08c852733d227b","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d2249"},{"id":"59805315cc08c852733d227c","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d224a"},{"id":"59805315cc08c852733d227d","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d224b"},{"id":"59805315cc08c852733d227e","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d224c"},{"id":"59805315cc08c852733d227f","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d224d"},{"id":"59805315cc08c852733d2280","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d224e"},{"id":"59805315cc08c852733d2281","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d224f"},{"id":"59805315cc08c852733d2282","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d2250"},{"id":"59805315cc08c852733d2283","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d2251"},{"id":"59805315cc08c852733d2284","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d2252"},{"id":"59805315cc08c852733d2285","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d2253"},{"id":"59805315cc08c852733d2286","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d2254"},{"id":"59805315cc08c852733d2287","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d2255"},{"id":"59805315cc08c852733d2288","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d2256"},{"id":"59805315cc08c852733d2289","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d2257"},{"id":"59805315cc08c852733d228a","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d2258"},{"id":"59805315cc08c852733d228b","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d2259"},{"id":"59805315cc08c852733d228c","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d225a"},{"id":"59805315cc08c852733d228d","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d225b"},{"id":"59805315cc08c852733d228e","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d225c"},{"id":"59805315cc08c852733d228f","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d225d"},{"id":"59805315cc08c852733d2290","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d225e"},{"id":"59805315cc08c852733d2291","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d225f"},{"id":"59805315cc08c852733d2292","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d2260"},{"id":"59805315cc08c852733d2293","role_id":"59805314cc08c852733d222d","permission_id":"59805315cc08c852733d2261"},{"id":"59805315cc08c852733d2294","role_id":"59805314cc08c852733d222e","permission_id":"59805315cc08c852733d2238"},{"id":"59805315cc08c852733d2295","role_id":"59805314cc08c852733d222e","permission_id":"59805315cc08c852733d2239"},{"id":"59805315cc08c852733d2296","role_id":"59805314cc08c852733d222e","permission_id":"59805315cc08c852733d223a"},{"id":"59805315cc08c852733d2297","role_id":"59805314cc08c852733d222e","permission_id":"59805315cc08c852733d223b"},{"id":"59805315cc08c852733d2298","role_id":"59805314cc08c852733d222e","permission_id":"59805315cc08c852733d223c"},{"id":"59805315cc08c852733d2299","role_id":"59805314cc08c852733d222e","permission_id":"59805315cc08c852733d223d"},{"id":"59805315cc08c852733d229a","role_id":"59805314cc08c852733d222e","permission_id":"59805315cc08c852733d223e"},{"id":"59805315cc08c852733d229b","role_id":"59805314cc08c852733d222e","permission_id":"59805315cc08c852733d2240"},{"id":"59805315cc08c852733d229c","role_id":"59805314cc08c852733d222e","permission_id":"59805315cc08c852733d2241"},{"id":"59805315cc08c852733d229d","role_id":"59805314cc08c852733d222e","permission_id":"59805315cc08c852733d2242"},{"id":"59805315cc08c852733d229e","role_id":"59805314cc08c852733d222e","permission_id":"59805315cc08c852733d2243"},{"id":"59805315cc08c852733d229f","role_id":"59805314cc08c852733d222e","permission_id":"59805315cc08c852733d2244"},{"id":"59805315cc08c852733d22a0","role_id":"59805314cc08c852733d222e","permission_id":"59805315cc08c852733d2245"},{"id":"59805315cc08c852733d22a1","role_id":"59805314cc08c852733d222e","permission_id":"59805315cc08c852733d224c"},{"id":"59805315cc08c852733d22a2","role_id":"59805314cc08c852733d222e","permission_id":"59805315cc08c852733d224d"},{"id":"59805315cc08c852733d22a3","role_id":"59805314cc08c852733d222e","permission_id":"59805315cc08c852733d224e"},{"id":"59805315cc08c852733d22a4","role_id":"59805314cc08c852733d222e","permission_id":"59805315cc08c852733d224f"},{"id":"59805315cc08c852733d22a5","role_id":"59805314cc08c852733d222e","permission_id":"59805315cc08c852733d2250"},{"id":"59805315cc08c852733d22a6","role_id":"59805314cc08c852733d222e","permission_id":"59805315cc08c852733d2251"},{"id":"59805315cc08c852733d22a7","role_id":"59805314cc08c852733d222e","permission_id":"59805315cc08c852733d2252"},{"id":"59805315cc08c852733d22a8","role_id":"59805314cc08c852733d222e","permission_id":"59805315cc08c852733d2253"},{"id":"59805315cc08c852733d22a9","role_id":"59805314cc08c852733d222e","permission_id":"59805315cc08c852733d2254"},{"id":"59805315cc08c852733d22aa","role_id":"59805314cc08c852733d222e","permission_id":"59805315cc08c852733d2255"},{"id":"59805315cc08c852733d22ab","role_id":"59805314cc08c852733d222e","permission_id":"59805315cc08c852733d2256"},{"id":"59805315cc08c852733d22ac","role_id":"59805314cc08c852733d222e","permission_id":"59805315cc08c852733d2257"},{"id":"59805315cc08c852733d22ad","role_id":"59805314cc08c852733d222e","permission_id":"59805315cc08c852733d225b"},{"id":"59805315cc08c852733d22ae","role_id":"59805314cc08c852733d222e","permission_id":"59805315cc08c852733d225d"},{"id":"59805315cc08c852733d22af","role_id":"59805314cc08c852733d222e","permission_id":"59805315cc08c852733d225e"},{"id":"59805315cc08c852733d22b0","role_id":"59805314cc08c852733d222e","permission_id":"59805315cc08c852733d225f"},{"id":"59805315cc08c852733d22b1","role_id":"59805314cc08c852733d222e","permission_id":"59805315cc08c852733d2260"},{"id":"59805315cc08c852733d22b2","role_id":"59805314cc08c852733d222e","permission_id":"59805315cc08c852733d2261"},{"id":"59805315cc08c852733d22b3","role_id":"59805314cc08c852733d222f","permission_id":"59805315cc08c852733d2238"},{"id":"59805315cc08c852733d22b4","role_id":"59805314cc08c852733d222f","permission_id":"59805315cc08c852733d2239"},{"id":"59805315cc08c852733d22b5","role_id":"59805314cc08c852733d222f","permission_id":"59805315cc08c852733d223b"},{"id":"59805316cc08c852733d22b6","role_id":"59805314cc08c852733d222f","permission_id":"59805315cc08c852733d223d"},{"id":"59805316cc08c852733d22b7","role_id":"59805314cc08c852733d222f","permission_id":"59805315cc08c852733d223e"},{"id":"59805316cc08c852733d22b8","role_id":"59805314cc08c852733d222f","permission_id":"59805315cc08c852733d2240"},{"id":"59805316cc08c852733d22b9","role_id":"59805314cc08c852733d222f","permission_id":"59805315cc08c852733d2241"},{"id":"59805316cc08c852733d22ba","role_id":"59805314cc08c852733d222f","permission_id":"59805315cc08c852733d2242"},{"id":"59805316cc08c852733d22bb","role_id":"59805314cc08c852733d222f","permission_id":"59805315cc08c852733d2244"},{"id":"59805316cc08c852733d22bc","role_id":"59805314cc08c852733d222f","permission_id":"59805315cc08c852733d224c"},{"id":"59805316cc08c852733d22bd","role_id":"59805314cc08c852733d222f","permission_id":"59805315cc08c852733d224d"},{"id":"59805316cc08c852733d22be","role_id":"59805314cc08c852733d222f","permission_id":"59805315cc08c852733d2252"},{"id":"59805316cc08c852733d22bf","role_id":"59805314cc08c852733d222f","permission_id":"59805315cc08c852733d2253"},{"id":"59805316cc08c852733d22c0","role_id":"59805314cc08c852733d222f","permission_id":"59805315cc08c852733d2254"},{"id":"59805316cc08c852733d22c1","role_id":"59805314cc08c852733d222f","permission_id":"59805315cc08c852733d2255"},{"id":"59805316cc08c852733d22c2","role_id":"59805314cc08c852733d222f","permission_id":"59805315cc08c852733d2256"},{"id":"59805316cc08c852733d22c3","role_id":"59805314cc08c852733d222f","permission_id":"59805315cc08c852733d2257"},{"id":"59805316cc08c852733d22c4","role_id":"59805314cc08c852733d222f","permission_id":"59805315cc08c852733d225b"}],"permissions_apps":[],"settings":[{"id":"598053188b6b9f5294dd27a0","key":"db_hash","value":"5648e0c9-a7e0-4b23-b93f-d64a8444bafe","type":"core","created_at":"2017-08-01 10:08:24","created_by":"1","updated_at":"2017-08-01 10:08:24","updated_by":"1"},{"id":"598053188b6b9f5294dd27a1","key":"next_update_check","value":"1507605268","type":"core","created_at":"2017-08-01 10:08:24","created_by":"1","updated_at":"2017-10-09 03:14:26","updated_by":"1"},{"id":"598053188b6b9f5294dd27a2","key":"display_update_notification","value":"1.12.1","type":"core","created_at":"2017-08-01 10:08:24","created_by":"1","updated_at":"2017-10-09 03:14:26","updated_by":"1"},{"id":"598053188b6b9f5294dd27a3","key":"seen_notifications","value":"[]","type":"core","created_at":"2017-08-01 10:08:24","created_by":"1","updated_at":"2017-08-01 10:08:24","updated_by":"1"},{"id":"598053188b6b9f5294dd27a4","key":"title","value":"小撸怡情","type":"blog","created_at":"2017-08-01 10:08:24","created_by":"1","updated_at":"2017-08-15 02:42:36","updated_by":"1"},{"id":"598053188b6b9f5294dd27a5","key":"description","value":"记录学习生活的点滴，留住我们前进的足迹","type":"blog","created_at":"2017-08-01 10:08:24","created_by":"1","updated_at":"2017-08-15 02:42:36","updated_by":"1"},{"id":"598053188b6b9f5294dd27a6","key":"logo","value":"","type":"blog","created_at":"2017-08-01 10:08:24","created_by":"1","updated_at":"2017-08-15 02:42:36","updated_by":"1"},{"id":"598053188b6b9f5294dd27a7","key":"cover_image","value":"/content/images/2017/08/bg-1.jpeg","type":"blog","created_at":"2017-08-01 10:08:24","created_by":"1","updated_at":"2017-08-15 02:42:36","updated_by":"1"},{"id":"598053188b6b9f5294dd27a8","key":"icon","value":"","type":"blog","created_at":"2017-08-01 10:08:24","created_by":"1","updated_at":"2017-08-15 02:42:36","updated_by":"1"},{"id":"598053188b6b9f5294dd27a9","key":"default_locale","value":"en","type":"blog","created_at":"2017-08-01 10:08:24","created_by":"1","updated_at":"2017-08-15 02:42:36","updated_by":"1"},{"id":"598053188b6b9f5294dd27aa","key":"active_timezone","value":"Asia/Hong_Kong","type":"blog","created_at":"2017-08-01 10:08:24","created_by":"1","updated_at":"2017-08-15 02:42:36","updated_by":"1"},{"id":"598053188b6b9f5294dd27ab","key":"force_i18n","value":"true","type":"blog","created_at":"2017-08-01 10:08:24","created_by":"1","updated_at":"2017-08-15 02:42:36","updated_by":"1"},{"id":"598053188b6b9f5294dd27ac","key":"permalinks","value":"/:year/:month/:day/:slug/","type":"blog","created_at":"2017-08-01 10:08:24","created_by":"1","updated_at":"2017-08-15 02:42:36","updated_by":"1"},{"id":"598053188b6b9f5294dd27ad","key":"amp","value":"true","type":"blog","created_at":"2017-08-01 10:08:24","created_by":"1","updated_at":"2017-08-15 02:42:36","updated_by":"1"},{"id":"598053188b6b9f5294dd27ae","key":"ghost_head","value":"","type":"blog","created_at":"2017-08-01 10:08:24","created_by":"1","updated_at":"2017-08-15 02:42:36","updated_by":"1"},{"id":"598053188b6b9f5294dd27af","key":"ghost_foot","value":"","type":"blog","created_at":"2017-08-01 10:08:24","created_by":"1","updated_at":"2017-08-15 02:42:36","updated_by":"1"},{"id":"598053188b6b9f5294dd27b0","key":"facebook","value":"","type":"blog","created_at":"2017-08-01 10:08:24","created_by":"1","updated_at":"2017-08-15 02:42:36","updated_by":"1"},{"id":"598053188b6b9f5294dd27b1","key":"twitter","value":"","type":"blog","created_at":"2017-08-01 10:08:24","created_by":"1","updated_at":"2017-08-15 02:42:36","updated_by":"1"},{"id":"598053188b6b9f5294dd27b2","key":"labs","value":"{\"publicAPI\":true}","type":"blog","created_at":"2017-08-01 10:08:24","created_by":"1","updated_at":"2017-08-15 02:42:36","updated_by":"1"},{"id":"598053188b6b9f5294dd27b3","key":"navigation","value":"[]","type":"blog","created_at":"2017-08-01 10:08:24","created_by":"1","updated_at":"2017-08-15 02:42:36","updated_by":"1"},{"id":"598053188b6b9f5294dd27b4","key":"slack","value":"[{\"url\":\"\"}]","type":"blog","created_at":"2017-08-01 10:08:24","created_by":"1","updated_at":"2017-08-15 02:42:36","updated_by":"1"},{"id":"598053188b6b9f5294dd27b5","key":"active_theme","value":"cusca-0.0.2","type":"theme","created_at":"2017-08-01 10:08:24","created_by":"1","updated_at":"2017-08-15 01:56:20","updated_by":"1"},{"id":"598053188b6b9f5294dd27b6","key":"active_apps","value":"[]","type":"app","created_at":"2017-08-01 10:08:24","created_by":"1","updated_at":"2017-08-01 10:08:24","updated_by":"1"},{"id":"598053188b6b9f5294dd27b7","key":"installed_apps","value":"[]","type":"app","created_at":"2017-08-01 10:08:24","created_by":"1","updated_at":"2017-09-01 07:55:11","updated_by":"1"},{"id":"598053188b6b9f5294dd27b8","key":"is_private","value":"false","type":"private","created_at":"2017-08-01 10:08:24","created_by":"1","updated_at":"2017-08-15 02:42:36","updated_by":"1"},{"id":"598053188b6b9f5294dd27b9","key":"password","value":"","type":"private","created_at":"2017-08-01 10:08:24","created_by":"1","updated_at":"2017-08-15 02:42:36","updated_by":"1"}],"tags":[{"id":"59805314cc08c852733d2229","name":"Getting Started","slug":"getting-started","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2017-08-01 10:08:20","created_by":"1","updated_at":"2017-08-01 10:08:20","updated_by":"1"},{"id":"5980662d8b6b9f5294dd27bf","name":"phone","slug":"phone","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2017-08-01 11:29:49","created_by":"1","updated_at":"2017-08-01 11:29:49","updated_by":"1"},{"id":"5980662d8b6b9f5294dd27c1","name":"encryption","slug":"encryption","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2017-08-01 11:29:49","created_by":"1","updated_at":"2017-08-01 11:29:49","updated_by":"1"},{"id":"59813829d62a9854962c9408","name":"mysql","slug":"mysql","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2017-08-02 02:25:45","created_by":"1","updated_at":"2017-08-02 02:25:45","updated_by":"1"},{"id":"59813b03d62a9854962c940c","name":"tensorflow","slug":"tensorflow","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2017-08-02 02:37:55","created_by":"1","updated_at":"2017-08-02 02:37:55","updated_by":"1"},{"id":"59813b03d62a9854962c940e","name":"学习笔记","slug":"mark","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2017-08-02 02:37:55","created_by":"1","updated_at":"2017-08-15 01:41:39","updated_by":"1"},{"id":"5982c265616dac5789b9fa26","name":"json","slug":"json","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2017-08-03 06:27:49","created_by":"1","updated_at":"2017-08-03 06:27:49","updated_by":"1"},{"id":"5982c265616dac5789b9fa28","name":"golang","slug":"golang","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2017-08-03 06:27:49","created_by":"1","updated_at":"2017-08-03 06:27:49","updated_by":"1"},{"id":"5982c265616dac5789b9fa2a","name":"python","slug":"python","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2017-08-03 06:27:49","created_by":"1","updated_at":"2017-08-03 06:27:49","updated_by":"1"},{"id":"5982cd1a616dac5789b9fa2e","name":"thrift","slug":"thrift","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2017-08-03 07:13:30","created_by":"1","updated_at":"2017-08-03 07:13:30","updated_by":"1"},{"id":"5982d195616dac5789b9fa32","name":"gif","slug":"gif","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2017-08-03 07:32:37","created_by":"1","updated_at":"2017-08-03 07:32:37","updated_by":"1"},{"id":"5982d195616dac5789b9fa34","name":"image","slug":"image","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2017-08-03 07:32:37","created_by":"1","updated_at":"2017-08-03 07:32:37","updated_by":"1"},{"id":"598d1c7a5eddf6628687dabd","name":"颜值打分","slug":"yan-zhi-da-fen","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2017-08-11 02:54:50","created_by":"1","updated_at":"2017-08-11 02:54:50","updated_by":"1"},{"id":"5993fb8df36c876ae083d899","name":"numpy","slug":"numpy","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2017-08-16 08:00:13","created_by":"1","updated_at":"2017-08-16 08:00:13","updated_by":"1"},{"id":"59a7cca3f36c876ae083d8b5","name":"java","slug":"java","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2017-08-31 08:45:23","created_by":"1","updated_at":"2017-08-31 08:45:23","updated_by":"1"},{"id":"59a7cca3f36c876ae083d8b7","name":"注解","slug":"zhu-jie","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2017-08-31 08:45:23","created_by":"1","updated_at":"2017-08-31 08:45:23","updated_by":"1"},{"id":"59a7ce51f36c876ae083d8ba","name":"spring","slug":"spring","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2017-08-31 08:52:33","created_by":"1","updated_at":"2017-08-31 08:52:33","updated_by":"1"},{"id":"59a7ce51f36c876ae083d8bc","name":"ReturnValueHandler","slug":"returnvaluehandler","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2017-08-31 08:52:33","created_by":"1","updated_at":"2017-08-31 08:52:33","updated_by":"1"},{"id":"59afbc2aea7269021be3e703","name":"微信","slug":"wei-xin","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2017-09-06 09:13:14","created_by":"1","updated_at":"2017-09-06 09:13:14","updated_by":"1"}],"posts_tags":[{"id":"5980662d8b6b9f5294dd27c0","post_id":"5980610f8b6b9f5294dd27be","tag_id":"5980662d8b6b9f5294dd27bf","sort_order":0},{"id":"5980662d8b6b9f5294dd27c2","post_id":"5980610f8b6b9f5294dd27be","tag_id":"5980662d8b6b9f5294dd27c1","sort_order":1},{"id":"59813829d62a9854962c9409","post_id":"59806b3a43d7fc53ddfd277a","tag_id":"59813829d62a9854962c9408","sort_order":0},{"id":"59813b03d62a9854962c940d","post_id":"59813996d62a9854962c940b","tag_id":"59813b03d62a9854962c940c","sort_order":0},{"id":"59813b03d62a9854962c940f","post_id":"59813996d62a9854962c940b","tag_id":"59813b03d62a9854962c940e","sort_order":1},{"id":"5982bcb9616dac5789b9fa22","post_id":"5982b8d9616dac5789b9fa21","tag_id":"59813829d62a9854962c9408","sort_order":0},{"id":"5982c265616dac5789b9fa27","post_id":"5982c1c1616dac5789b9fa25","tag_id":"5982c265616dac5789b9fa26","sort_order":0},{"id":"5982c265616dac5789b9fa29","post_id":"5982c1c1616dac5789b9fa25","tag_id":"5982c265616dac5789b9fa28","sort_order":1},{"id":"5982c265616dac5789b9fa2b","post_id":"5982c1c1616dac5789b9fa25","tag_id":"5982c265616dac5789b9fa2a","sort_order":2},{"id":"5982cd1a616dac5789b9fa2d","post_id":"5982cb8b616dac5789b9fa2c","tag_id":"5982c265616dac5789b9fa28","sort_order":0},{"id":"5982cd1a616dac5789b9fa2f","post_id":"5982cb8b616dac5789b9fa2c","tag_id":"5982cd1a616dac5789b9fa2e","sort_order":1},{"id":"5982d195616dac5789b9fa31","post_id":"5982cded616dac5789b9fa30","tag_id":"5982c265616dac5789b9fa28","sort_order":0},{"id":"5982d195616dac5789b9fa33","post_id":"5982cded616dac5789b9fa30","tag_id":"5982d195616dac5789b9fa32","sort_order":1},{"id":"5982d195616dac5789b9fa35","post_id":"5982cded616dac5789b9fa30","tag_id":"5982d195616dac5789b9fa34","sort_order":2},{"id":"598d1c7a5eddf6628687dabe","post_id":"598d16ee5eddf6628687dabc","tag_id":"598d1c7a5eddf6628687dabd","sort_order":1},{"id":"598d1c7a5eddf6628687dabf","post_id":"598d16ee5eddf6628687dabc","tag_id":"59813b03d62a9854962c940c","sort_order":0},{"id":"599170fa5eddf6628687dac3","post_id":"599170605eddf6628687dac2","tag_id":"5982c265616dac5789b9fa2a","sort_order":0},{"id":"599172475eddf6628687dac6","post_id":"5982dcd9616dac5789b9fa36","tag_id":"59813b03d62a9854962c940c","sort_order":0},{"id":"5993fb8df36c876ae083d89a","post_id":"5993b236f36c876ae083d898","tag_id":"5993fb8df36c876ae083d899","sort_order":1},{"id":"5993fb8df36c876ae083d89b","post_id":"5993b236f36c876ae083d898","tag_id":"5982c265616dac5789b9fa2a","sort_order":0},{"id":"59a7cca3f36c876ae083d8b6","post_id":"59a7c9c9f36c876ae083d8b4","tag_id":"59a7cca3f36c876ae083d8b5","sort_order":0},{"id":"59a7cca3f36c876ae083d8b8","post_id":"59a7c9c9f36c876ae083d8b4","tag_id":"59a7cca3f36c876ae083d8b7","sort_order":1},{"id":"59a7ce51f36c876ae083d8bb","post_id":"59a7ccc6f36c876ae083d8b9","tag_id":"59a7ce51f36c876ae083d8ba","sort_order":0},{"id":"59a7ce51f36c876ae083d8bd","post_id":"59a7ccc6f36c876ae083d8b9","tag_id":"59a7ce51f36c876ae083d8bc","sort_order":1},{"id":"59afbc2aea7269021be3e702","post_id":"59afbb28ea7269021be3e701","tag_id":"5982c265616dac5789b9fa28","sort_order":0},{"id":"59afbc2aea7269021be3e704","post_id":"59afbb28ea7269021be3e701","tag_id":"59afbc2aea7269021be3e703","sort_order":1}],"apps":[],"app_settings":[],"app_fields":[],"subscribers":[],"invites":[{"id":"598299ef616dac5789b9fa15","role_id":"59805314cc08c852733d222e","status":"sent","token":"MTUwMjMzNjExMTI1M3x4eXFqYXlraW5nQGdtYWlsLmNvbXxBdjIvV3BxWUt4MDVVUWdjclNsdGpBOVl0YnFkYStDaTRWaVhKUEQ1M20wPQ==","email":"xyqjayking@gmail.com","expires":1502336111253,"created_at":"2017-08-03 03:35:11","created_by":"1","updated_at":"2017-08-03 03:35:13","updated_by":"1"},{"id":"59829a10616dac5789b9fa18","role_id":"59805314cc08c852733d222e","status":"sent","token":"MTUwMjMzNjE0NDA0MXxsaXV5b3VzaGVuMTk5MEAxNjMuY29tfHRVU0lJdzZBaVoySEh1d0VxZnFRQ04vL3FKWXhkNjVjcjZKTk80eWNJWUk9","email":"liuyoushen1990@163.com","expires":1502336144041,"created_at":"2017-08-03 03:35:44","created_by":"1","updated_at":"2017-08-03 03:35:47","updated_by":"1"}],"brute":[{"key":"s6MfyedHwKGxOSjxTXyIpicYgy4xmSV2tmdaHpo22+Y=","firstRequest":1507518871957,"lastRequest":1507519566320,"lifetime":1507523166324,"count":4},{"key":"faCNkAt30pd5jYi4ClWFJNb/tPapSYEMsV3R5JVPO5M=","firstRequest":1507518871978,"lastRequest":1507518871978,"lifetime":1520219671981,"count":1},{"key":"fiw1K6ou1qS92n28XHxENWEr+YHn6ftlRPxvuzTW+JY=","firstRequest":1507519552155,"lastRequest":1507519552155,"lifetime":1520220352159,"count":1}]}}